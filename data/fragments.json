{
  "boolean-stone": {
    "title": "A Gateway to Dualities: Mirror Symmetry between Space and Structure",
    "date": "2021-07-21",
    "content": "## Overview\r\n\r\nIt was July 2021, a sweltering month, when an image quietly dropped into our Geek College chat group. It was Dr. Keyao Peng, our mentor at the time, who shared a simple yet profound screenshot labeled **\"Table 3: Some dualities.\"** At first glance, it appeared to be merely a list of mathematical objects, but upon closer inspection, it revealed a fundamental philosophical structure that governs modern mathematics: the mirror symmetry between *Geometry* (Space) and *Algebra* (Structure).\r\n\r\n![TABLE](/fragments/boolean-stone/table.jpg)\r\n\r\nThat specific image acted as a catalyst. It was the spark that ignited my intense curiosity regarding the relationship between Boolean logic and topological spaces. I spent the subsequent weeks diving into the literature, attempting to decode the first row of that table: **Stone spaces** and **Boolean algebras**. This intellectual journey culminated in August 2021, when I published an explanatory article on the *Chaoli Forum* titled \"An Introduction to Boolean Algebra\" (available at [chaoli.club](https://chaoli.club/index.php/6589), DOI: [10.6084/M9.FIGSHARE.20310033](https://doi.org/10.6084/M9.FIGSHARE.20310033)).\r\n\r\nHowever, looking back at that note, I realize it remained incomplete. I successfully navigated the algebraic structures, but I never fully articulated the geometric side—the *Stone Space*—as I had originally intended. Furthermore, influenced by Dr. Peng’s deeper interests, I began scratching the surface of **Topos Theory** and **Logos**, concepts that reside at the bottom of the table.\r\n\r\nWhat follows is a reconstruction of my learning notes from that period. It is an attempt to finally provide the \"missing half\" of my August 2021 note, to decode the table that Dr. Peng sent, and to rigorously define the concept of **Duality** that binds these disparate worlds together.\r\n\r\n---\r\n\r\n## 1. Decoding the Table: An Architectural View\r\n\r\nThe table Dr. Peng shared is not just a collection of examples; it is a manifestation of **Isbell Duality** (or general concrete duality). It presents three distinct columns that narrate a specific story about mathematical translation.\r\n\r\n### The Columns\r\n\r\n1.  **Geometry (The Spatial):** The first column lists objects that possess \"spatial\" intuition. These are sets equipped with topology, loci of points, or generalized spaces where \"position\" and \"convergence\" are the primary notions.\r\n2.  **Algebra (The Formal):** The second column lists algebraic structures. These are defined by operations, equations, and axioms. They represent the \"functions\" or the \"logic\" living on the spaces in the first column.\r\n3.  **Dualizing Object (Gauge Space $\\mathbf{A}$):** The third column is the most critical. It represents the \"bridge\" or the \"gauge\" used to translate between the two worlds. The duality usually arises by considering morphisms from the geometric object to $\\mathbf{A}$, or morphisms from the algebraic object to $\\mathbf{A}$.\r\n\r\n### The Fundamental Philosophy\r\nThe table asserts a profound meta-theorem: **Algebra is the dual of Geometry.**\r\n*   To study a space $X$, we study the algebra of functions on $X$ taking values in the gauge object $\\mathbf{A}$.\r\n*   To study an algebra $B$, we study the \"spectrum\" of that algebra—the geometric space formed by the homomorphisms from $B$ into $\\mathbf{A}$.\r\n\r\nBelow, I will detail the specific dualities I researched during that summer, starting with the one that captivated me the most.\r\n\r\n---\r\n\r\n## 2. The First Row: Stone Duality\r\n**Geometry:** Stone Spaces $\\longleftrightarrow$ **Algebra:** Boolean Algebras\r\n**Dualizing Object:** $\\mathbf{2} = \\{0, 1\\}$\r\n\r\nThis was the primary focus of my research in July and August 2021. While my Chaoli Forum paper covered the algebraic definitions, the \"Stone\" side requires a rigorous topological treatment.\r\n\r\n### 2.1 The Algebraic Side: Boolean Algebras\r\nTo understand the duality, we must first strictly define the object of interest. A **Boolean Algebra** is a structure $\\langle B, \\lor, \\land, \\neg, 0, 1 \\rangle$ that serves as the mathematical model of classical propositional logic.\r\n\r\n**Definition (Boolean Algebra):**\r\nA Boolean algebra is a complemented distributive lattice. That is, for all $x, y, z \\in B$:\r\n1.  **Associativity & Commutativity:** The operations $\\lor$ (join) and $\\land$ (meet) are associative and commutative.\r\n2.  **Absorption:** $x \\lor (x \\land y) = x$ and $x \\land (x \\lor y) = x$.\r\n3.  **Distributivity:**\r\n    $$x \\land (y \\lor z) = (x \\land y) \\lor (x \\land z)$$\r\n    $$x \\lor (y \\land z) = (x \\lor y) \\land (x \\lor z)$$\r\n4.  **Complementation:** For every $x$, there exists a unique $\\neg x$ such that $x \\lor \\neg x = 1$ and $x \\land \\neg x = 0$.\r\n\r\nIn my previous writings, I explored how this structure abstracts the set operations of intersection and union. However, the question posed by the duality table is: *Can every Boolean algebra be visualized as a collection of sets?* This leads us to the geometric side.\r\n\r\n### 2.2 The Geometric Side: Stone Spaces\r\nThe table lists \"Stone spaces\" as the geometric dual.\r\n\r\n**Definition (Stone Space):**\r\nA topological space $X$ is called a **Stone space** (or a Boolean space) if it satisfies three conditions:\r\n1.  **Compact:** Every open cover has a finite subcover.\r\n2.  **Hausdorff:** Distinct points can be separated by disjoint open neighborhoods.\r\n3.  **Totally Disconnected:** The only connected subsets of $X$ are singleton sets (or empty). Equivalently, the logical basis consists of **clopen** (closed and open) sets.\r\n\r\n**The Construction (The Bridge):**\r\nHow do we turn an algebra $B$ into a space $X$? We use the concept of **Ultrafilters**.\r\n*   A **Filter** $F$ on $B$ is a subset such that $1 \\in F$, it is closed under meet ($a,b \\in F \\implies a \\land b \\in F$), and it is upward closed ($a \\in F, a \\le b \\implies b \\in F$).\r\n*   An **Ultrafilter** is a maximal proper filter. Crucially, for any element $x \\in B$, an ultrafilter contains either $x$ or $\\neg x$, but never both.\r\n\r\nLet $S(B)$ be the set of all ultrafilters of $B$. We define a topology on $S(B)$ using the **Stone Topology**. For every $a \\in B$, let:\r\n$$N_a = \\{ U \\in S(B) \\mid a \\in U \\}$$\r\nThe collection $\\{ N_a \\mid a \\in B \\}$ forms a basis for the topology.\r\n\r\n**Theorem (Stone's Representation Theorem):**\r\nEvery Boolean algebra $B$ is isomorphic to the field of clopen sets of its Stone space $S(B)$.\r\n$$B \\cong \\text{Clopen}(S(B))$$\r\n\r\nThis confirms the first row of the table. The \"Dualizing object\" is $\\mathbf{2} = \\{0, 1\\}$.\r\n*   From Space to Algebra: Consider continuous functions $C(X, \\mathbf{2})$, where $\\mathbf{2}$ has the discrete topology. Since $\\mathbf{2}$ is discrete, the inverse image of $\\{1\\}$ must be a clopen set. Thus, maps to $\\mathbf{2}$ correspond to clopen sets.\r\n*   From Algebra to Space: Consider homomorphisms $Hom(B, \\mathbf{2})$. A homomorphism $\\phi: B \\to \\mathbf{2}$ is essentially the characteristic function of an ultrafilter (the set of elements mapped to 1).\r\n\r\nThis duality perfectly encapsulates the idea that logic (Boolean algebra) is simply the \"continuous functions\" on a specific kind of disconnected space.\r\n\r\n---\r\n\r\n## 3. The Second Row: Gelfand Duality\r\n**Geometry:** Compact Hausdorff Spaces $\\longleftrightarrow$ **Algebra:** Commutative C*-algebras\r\n**Dualizing Object:** $\\mathbb{C}$ (The Complex Numbers)\r\n\r\nAlthough I did not write about this in 2021, the table highlights it immediately below Stone Duality for a reason: it is the \"continuous\" version of the \"discrete\" Stone duality.\r\n\r\nWhile Stone spaces are totally disconnected, **Compact Hausdorff spaces** describe standard geometric continua (like spheres or tori). The algebra that describes them is not Boolean, but functional analysis based.\r\n\r\n**Definition (Commutative C*-algebra):**\r\nA complex algebra $A$ equipped with a norm $\\| \\cdot \\|$ and an involution $*$, complete under the norm, satisfying $\\|xy\\| \\le \\|x\\|\\|y\\|$ and the C* identity $\\|x^*x\\| = \\|x\\|^2$.\r\n\r\n**The Theorem (Gelfand-Naimark):**\r\nFor any commutative unital C*-algebra $A$, there exists a compact Hausdorff space $X$ (the \"spectrum\" of $A$, denoted $\\text{Spec}(A)$) such that $A$ is isometrically isomorphic to the algebra of continuous complex-valued functions on $X$:\r\n$$A \\cong C(X)$$\r\n\r\nHere, the dualizing object is $\\mathbb{C}$.\r\n*   Geometry to Algebra: Take a space $X$, look at $f: X \\to \\mathbb{C}$.\r\n*   Algebra to Geometry: Take the algebra $A$, look at the \"characters\" (non-zero homomorphisms $\\chi: A \\to \\mathbb{C}$). The set of these characters forms the space $X$.\r\n\r\nThis row reinforced to me that \"points\" in a space are equivalent to \"maximal ideals\" or \"homomorphisms\" in an algebra.\r\n\r\n---\r\n\r\n## 4. The Lower Rows: Topos and Logos\r\n**Geometry:** Topoi $\\longleftrightarrow$ **Algebra:** Logoi\r\n**Dualizing Object:** The topos $\\mathbf{A}$ of Sets\r\n\r\nThis section of the table was heavily influenced by Dr. Peng's area of expertise. During that summer, I attempted to grapple with the definition of a **Topos**, often described as \"a place where mathematics happens.\"\r\n\r\n### 4.1 What is a Topos?\r\nIn the context of this table, a Topos (specifically a Grothendieck Topos) generalizes the concept of a topological space.\r\n\r\n**Definition (Grothendieck Topos):**\r\nA category $\\mathcal{E}$ is a Grothendieck topos if it is equivalent to the category of sheaves on a site (a small category equipped with a Grothendieck topology), denoted $Sh(\\mathcal{C}, J)$.\r\n\r\nWhy is this in the \"Geometry\" column? Because a topos behaves like a \"generalized space.\" Just as we can define sheaves on a topological space $X$, we can define a topos as the category of sheaves itself. The \"points\" of this generalized space are geometric morphisms from the category of Sets into the Topos.\r\n\r\n### 4.2 What is a Logos?\r\nThe term \"Logos\" (in the sense of Freyd) appears in the Algebra column. A logos refers to a specific type of category that has enough structure to support internal logic—specifically, geometric logic.\r\n\r\n**Definition (Logos / Geometric Category):**\r\nA category is a logos if it has finite limits, arbitrary small colimits, and colimits are stable under pullback.\r\n\r\n### 4.3 The Duality\r\nThe duality here is between the \"spatial\" view (the Topos as a place) and the \"logical\" view (the Logos as a theory).\r\n*   **Geometric Theories:** We can define a logical theory $T$ (syntactic).\r\n*   **Classifying Topos:** From $T$, we can construct a topos $\\mathcal{E}[T]$ (semantic) such that models of $T$ in any other topos $\\mathcal{F}$ correspond to geometric morphisms $\\mathcal{F} \\to \\mathcal{E}[T]$.\r\n\r\nThe dualizing object here is the **Topos of Sets**. It serves as the standard background universe against which other \"universes\" (topoi) are measured.\r\n\r\n---\r\n\r\n## 5. The Synthesis: The Concept of Duality\r\n\r\nReflecting on this table years later, I can now articulate the formal definition of Duality that I was grasping for in 2021.\r\n\r\nIn Category Theory, a **Duality** between two categories $\\mathcal{C}$ and $\\mathcal{D}$ is an equivalence of categories between $\\mathcal{C}$ and the opposite category $\\mathcal{D}^{op}$.\r\n$$\\mathcal{C} \\cong \\mathcal{D}^{op}$$\r\nThis means there exist contravariant functors $F: \\mathcal{C} \\to \\mathcal{D}$ and $G: \\mathcal{D} \\to \\mathcal{C}$ such that $FG \\cong Id_{\\mathcal{D}}$ and $GF \\cong Id_{\\mathcal{C}}$.\r\n\r\n### The Role of the Dualizing Object\r\nIn Table 3, all the dualities are **Representable Dualities**. This means the functors $F$ and $G$ are defined by homming into a specific object $\\omega$ (the dualizing object) that lives in *both* categories (or admits structures from both).\r\n\r\nLet $\\omega$ be the dualizing object.\r\n1.  If $X$ is a geometric object in $\\mathcal{C}$, its dual algebra is $Hom_{\\mathcal{C}}(X, \\omega)$.\r\n    *   *Example:* If $X$ is a Stone Space, $Hom(X, \\mathbf{2})$ is the Boolean algebra of clopen sets.\r\n2.  If $A$ is an algebraic object in $\\mathcal{D}$, its dual space is $Hom_{\\mathcal{D}}(A, \\omega)$.\r\n    *   *Example:* If $A$ is a Boolean algebra, $Hom(A, \\mathbf{2})$ is the set of ultrafilters (points).\r\n\r\n### Why this matters\r\nThe table Dr. Peng shared is a roadmap of **Isbell Duality**. It teaches us that \"Syntax\" (Algebra) and \"Semantics\" (Geometry) are not separate entities.\r\n*   **Algebra** is the manipulation of symbols according to rules. It gives us the language.\r\n*   **Geometry** is the manifestation of those rules in a spatial context. It gives us the shape.\r\n\r\nThe \"Dualizing Object\" is the interpreter.\r\n*   In row 1, the interpreter is **Truth** ($\\{0,1\\}$).\r\n*   In row 2, the interpreter is **Measurement** ($\\mathbb{C}$).\r\n*   In row 3, the interpreter is the **Line** ($\\mathbb{A}^1$).\r\n*   In row 5, the interpreter is **Set Theory** itself.\r\n\r\n## Conclusion\r\n\r\nBack in August 2021, when I wrote my article for the Chaoli Forum, I barely scratched the surface of the first row. I understood the axioms of Boolean algebra, but I missed the beauty of the Stone Space—the idea that logic has a topology, that truth values can form a space that is compact and totally disconnected."
  },
  "chunpinative": {
    "title": "Initial Construction and Preliminary Properties of Chunpinative Geometry",
    "date": "2020-12-07",
    "content": "## Overview\n\nThis content takes the form of a systematic constructive record of a geometric theory, formally proposing the core axiom of \"Chunpinative Geometry\" and establishing a set of foundational concepts—including \"Chunpinative Space\" and \"Chunpinatively Measurable Space\"—on the basis of this axiom. Additionally, it deduces preliminary properties of the space and presents a key lemma proposed by a collaborator. From the perspective of mainstream geometric theory (encompassing both Euclidean and non-Euclidean geometries), the core axiom of Chunpinative Geometry—asserting that \"an angle is equivalent to its supplement\"—represents a deliberate departure from the fundamental logical relationships that govern angle arithmetic in conventional geometric systems. Specifically, it abandons the well-established rule that \"the supplement of an angle is equal to \\(180^\\circ\\) minus the measure of the original angle,\" replacing it with a direct equivalence relation. It is important to acknowledge that certain preliminary property descriptions in this initial construction lack the full rigor of formal mathematical derivation, as they serve as tentative deductions to frame the theory’s structure. As indicated by contextual cues embedded in the naming and framing, this work is a playful, commemorative simulation of a mathematical theory: it adopts the rigorous framework of axiom-based geometric system construction to pay lighthearted tribute to the author’s junior high school mathematics teacher, Chunping Ding (with the term \"Chunpinative\" derived from the teacher’s given name \"Chunping\"), and to classmate CZL, who contributed the key lemma to the theory.\n\n---\n\n## 1. Core Axiom and Basic Definitions of Chunpinative Geometry\n\n### 1.1 Foundational Axiom: The Dual-Complementary Principle (D-C-P Axiom)\n\nThe core axiom of Chunpinative Geometry, formally designated the Dual-Complementary Principle (abbreviated as the D-C-P Axiom), is explicitly and rigorously stated as follows: **An angle is axiomatically equivalent to its supplement**. Within the theoretical context of this axiom, the term \"angle\" is defined as the geometric figure formed by two non-coincident, intersecting line segments or rays in a given geometric space—consistent with the standard definition of an angle in elementary geometric theory, but constrained to the specific axiomatic framework of Chunpinative Geometry. The \"supplement\" (or \"supplementary angle\") retains its conventional geometric meaning: an angle whose measure, when added to the measure of the original angle, equals \\(180^\\circ\\) (or \\(\\pi\\) radians, when using the radian system of angle measurement). This axiom constitutes a deliberate break from the traditional geometric constraint that \"the supplement of an angle is arithmetically equal to \\(180^\\circ\\) minus the measure of the original angle\"; instead, it establishes a direct, unmediated equivalence between an angle and its supplement. As the foundational axiom of the entire theory, it serves as the logical starting point for constructing all subsequent definitions, properties, and lemmas within Chunpinative Geometry.\n\n### 1.2 Definition of the Core Geometric Space: Chunpinative Space\n\n**1.2.1 Formal Definition**: A geometric space is formally defined as a **Chunpinative Space** if and only if it satisfies the D-C-P Axiom—i.e., in every region and for every possible configuration of intersecting line segments or rays within the space, the angle formed is equivalent to its supplement. The broader theoretical system that investigates the structural characteristics, algebraic properties, and measurement of general sets within such spaces is collectively termed **Chunpinative Geometry**. The naming convention for both the space and the geometric theory is dual-purpose: it emphasizes the centrality of the D-C-P Axiom to the entire framework, while also carrying contextual commemorative significance tied to the individuals honored by the theory.\n\n**1.2.2 Scope of Application and Future Extensions**: The initial definition of Chunpinative Space presented herein is formulated within a general, unrestricted geometric framework, designed to apply to the most common cases of two-dimensional and three-dimensional spaces. However, special cases of geometric spaces—including zero-dimensional spaces (isolated points), one-dimensional spaces (lines or curves), and discrete spaces (countable sets of non-continuous points)—introduce unique constraints that are not fully addressed in this preliminary construction. These special cases will require additional axiomatic supplements, restrictive conditions, and tailored definitions in subsequent extensions of the theory, which will be the focus of detailed follow-up research aimed at generalizing Chunpinative Geometry to a more comprehensive set of geometric contexts.\n\n### 1.3 Preliminary Properties of Chunpinative Spaces\n\nBy applying the D-C-P Axiom to the formal definition of Chunpinative Space, the following three preliminary properties can be deduced. These properties are not exhaustive but serve as foundational building blocks for further investigations into the structural and algebraic characteristics of Chunpinative Spaces:\n\n- **Property i (Space Carrier and Coordinate Representation)**: A general Chunpinative Space is defined over the Cartesian product \\(X \\times Y\\), where \\(X\\) and \\(Y\\) are non-empty sets. In line with conventional geometric practice, \\(X\\) and \\(Y\\) are typically number sets (such as the set of real numbers \\(\\mathbb{R}\\), the set of integers \\(\\mathbb{Z}\\), or other ordered number fields) or point sets in traditional Euclidean space. This Cartesian product structure implies that every element (referred to as a \"point\") within the Chunpinative Space can be uniquely represented by an ordered pair \\((x, y)\\) where \\(x \\in X\\) and \\(y \\in Y\\). This coordinate representation provides a critical foundation for analytical studies of the space, enabling the use of algebraic tools to investigate geometric relationships within Chunpinative Geometry. The specific forms of \\(X\\) and \\(Y\\) (e.g., whether they are continuous or discrete, finite or infinite) are not fixed universally but are determined by the specific research objectives and contextual constraints of the Chunpinative Space under investigation.\n\n- **Property ii (Algebraic Structure: Commutativity and Non-Closure Under Addition)**: All Chunpinative Spaces exhibit the structure of an Abelian (commutative) space with respect to the standard binary operation of vector or point addition. Formally, this means that for any two elements \\(a\\) and \\(b\\) within a Chunpinative Space \\(\\mathcal{C}\\), the commutative law holds: \\(a + b = b + a\\). This property aligns with the algebraic structure of many conventional geometric spaces (such as Euclidean space) and ensures consistency with basic algebraic operations. However, a distinguishing feature of Chunpinative Spaces is their non-closure under addition: unlike Euclidean space, where the sum of two vectors (or points) remains within the space, the result of adding two elements in a Chunpinative Space may not belong to the space itself. A rigorous proof of this non-closure property is reserved as an exercise for further exploration; the core strategy for such a proof involves constructing explicit counterexamples that leverage the D-C-P Axiom to demonstrate cases where the sum of two elements violates the axiomatic constraints of Chunpinative Space.\n\n- **Property iii (Rigidity and Structural Invariance)**: Every Chunpinative Space is inherently rigid, a property primarily manifested in its resistance to deformation. In traditional geometric terminology, \"rigidity\" refers to the property of a geometric figure or space wherein the distances between points (and thus the shape and size of the figure) remain unchanged when subjected to external forces or transformations that do not involve stretching or compression. In the context of Chunpinative Spaces, this rigidity is a direct consequence of the uniqueness of angle relationships imposed by the D-C-P Axiom: since an angle is equivalent to its supplement, the measure of any angle in the space is uniquely determined (for real-valued angle measures, this unique value is \\(90^\\circ\\), as \\(x = 180^\\circ - x\\) implies \\(x = 90^\\circ\\)). This unique angle constraint fixes the relative positional relationships between line segments, rays, and planes within the space, preventing arbitrary deformation or reconfiguration without violating the D-C-P Axiom. Verification of this rigidity property can be concretely achieved by constructing a specific instance of a Chunpinative Space (such as the specialized space referenced in Lemma 1.3) and analyzing its structural invariance under standard geometric transformations (e.g., translations, rotations, or shears).\n\n### 1.4 Key Lemma: The CZL Lemma\n\n**Lemma Statement (1.3 Lemma)**: There exists at least one Chunpinative Space in which a right triangle with a vertex angle of \\(100^\\circ\\) can be embedded. This lemma is proposed by classmate CZL and is formally designated the CZL Lemma in recognition of this contribution. The CZL Lemma represents a critical breakthrough in the study of the specific structural characteristics of Chunpinative Spaces, as it confirms the existence of specialized Chunpinative Spaces that diverge significantly from both Euclidean and non-Euclidean spaces—wherein a right triangle (defined as a triangle containing a \\(90^\\circ\\) angle) cannot have a vertex angle of \\(100^\\circ\\) due to the constraints of the triangle angle sum theorem.\n\n**Relationship to General Chunpinative Spaces**: The specialized Chunpinative Space described in the CZL Lemma is explicitly a special case of the general Chunpinative Space defined in Property i (1.2.1 i). While the general Chunpinative Space is defined over the unrestricted Cartesian product \\(X \\times Y\\), the space in the CZL Lemma corresponds to a specific realization of \\(X \\times Y\\) with constrained forms of \\(X\\) and \\(Y\\) (e.g., non-standard number sets or modified coordinate systems). This specialized space thus embodies the general structure of Chunpinative Spaces under particular contextual conditions, demonstrating the flexibility and diversity of the theory’s framework.\n\n### 1.5 Construction Method of Specialized Chunpinative Spaces\n\nThe construction of the specialized Chunpinative Space that satisfies the CZL Lemma—i.e., a space in which a right triangle with a \\(100^\\circ\\) vertex angle can exist—requires the application of the mathematical technique of global analytic continuation. Analytic continuation is a well-established method in mathematical analysis, typically used to extend the domain of a function beyond its original definition while preserving key analytical properties (such as holomorphy or continuity). In the context of Chunpinative Space construction, this technique is adapted to transcend the constraints of the traditional Cartesian product \\(X \\times Y\\), enabling the expansion and modification of the space’s structure to accommodate the unique geometric configuration specified by the CZL Lemma.\n\nFormally, the process of global analytic continuation transforms the original general Chunpinative Space (defined over \\(X \\times Y\\)) into a mapping from \\(X \\times Y\\) to \\(\\xi(X \\times Y)\\), where \\(\\xi(X \\times Y)\\) (abbreviated as \\(\\xi\\) for brevity when no ambiguity arises) denotes the extended, specialized Chunpinative Space post-continuation. The core of this mapping lies in the redefinition of angle measurement rules within the space: while the D-C-P Axiom is retained as the foundational constraint, the method of assigning numerical measures to angles is modified to allow for the coexistence of a right angle (consistent with the D-C-P Axiom) and a \\(100^\\circ\\) vertex angle in the same triangle. This modification breaks the traditional triangle angle sum theorem (which requires the sum of angles in a triangle to be \\(180^\\circ\\) in Euclidean space), thereby enabling the existence of the specialized right triangle specified by the CZL Lemma.\n\n### 1.6 Definition of Chunpinatively Measurable Spaces\n\n**Formal Definition (1.4 Definition)**: Let \\(\\xi\\) be a non-empty Chunpinative Space obtained via the method of global analytic continuation (i.e., \\(\\xi \\neq \\emptyset\\)), and let \\(R\\) be a \\(\\sigma\\)-algebra consisting of subsets of \\(\\xi\\). The ordered pair \\((\\xi, R)\\) is formally defined as a **Chunpinatively Measurable Space**. The \\(\\sigma\\)-algebra \\(R\\) must satisfy the three standard axioms of \\(\\sigma\\)-algebras in measure theory: 1. The entire specialized Chunpinative Space \\(\\xi\\) is an element of \\(R\\) (i.e., \\(\\xi \\in R\\)); 2. The \\(\\sigma\\)-algebra is closed under complementation: if a subset \\(A\\) of \\(\\xi\\) is an element of \\(R\\) (i.e., \\(A \\in R\\)), then the complement of \\(A\\) with respect to \\(\\xi\\) (denoted \\(\\xi \\setminus A\\)) is also an element of \\(R\\); 3. The \\(\\sigma\\)-algebra is closed under countable unions: for any countable sequence of subsets \\(A_1, A_2, \\dots, A_n, \\dots\\) where each \\(A_k \\in R\\) (for \\(k = 1, 2, 3, \\dots\\)), their union \\(\\bigcup_{k=1}^\\infty A_k\\) is also an element of \\(R\\). This definition of the \\(\\sigma\\)-algebra provides a rigorous mathematical foundation for the subsequent definition of measures on Chunpinative Spaces, serving as an essential prerequisite for the study of the measurement of general sets (such as line segments, regions, or surfaces) within the framework of Chunpinative Geometry.\n\n## 2. Supplementary Notes on Chunpinative Geometry\n\nIt is important to explicitly note that the content presented herein constitutes an initial, preliminary attempt to construct the theoretical framework of Chunpinative Geometry. As such, it may contain limitations and areas for improvement, including (but not limited to) incomplete logical derivations for certain preliminary properties, potential imprecisions in the formalization of edge-case concepts, and the absence of comprehensive proofs for all assertions. The core purpose of this initial construction is not to present a fully mature, peer-reviewed mathematical theory, but rather to convey creative ideas through a playful, commemorative adaptation of the rigorous framework of axiom-based geometric system construction. A revised, expanded, and fully self-consistent version of Chunpinative Geometry has since been refined and systematically organized in January,2025. This improved version enhances the theoretical rigor, logical consistency, and comprehensiveness of the entire system, and is accessible via the following link: [https://www.runnelzhang.com/achieved/paper-cpg](https://www.runnelzhang.com/achieved/paper-cpg)."
  },
  "geek-christmas": {
    "title": "Christmas Night at Geek College: From Free Products to Asymptotic Envelopes",
    "date": "2020-12-25",
    "content": "## Overview\r\n\r\nThis entry marks my very first participation in the **Geek College** English Salon on December 25, 2020. What began as casual holiday chatter quickly evolved into a high-density academic exchange spanning Abstract Algebra and Measure Theory.\r\n\r\nThe log captures my initial struggles with the formal notations in Paul Halmos’s *Measure Theory* and the definition of Coproducts in the category of Groups. Guided by peers **Jacky_Jnirvana** and **Nianyi**, the conversation bridged the gap between rigorous \"pathological\" definitions and intuitive geometric understandings. Below are the key fragments of that night, supplemented with the mathematical context I have since gathered.\r\n\r\n---\r\n\r\n## Fragment I: The Coproduct Conundrum\r\n**\"Why must the coproduct of two non-trivial groups be an infinite group?\"**\r\n\r\nThe session opened with **Nianyi** questioning the nature of coproducts. The confusion arose from conflating the **Category of Abelian Groups** (where the coproduct is the Direct Sum, e.g., $\\mathbb{Z} \\oplus \\mathbb{Z}$) with the **Category of Groups** (where commutativity is not assumed).\r\n\r\n**Jacky_Jnirvana** pointed out that when we leave the safety of Abelian groups, the structure changes strictly. The coproduct becomes the **Free Product**.\r\n\r\n> **Concept: The Free Product ($G * H$)**\r\n> In the Category of Groups, the coproduct of $G$ and $H$ is the Free Product. Unlike the Direct Product (where elements commute, $gh = hg$), the Free Product consists of \"reduced words\"—strings of symbols from $G$ and $H$ combined.\r\n>\r\n> If $G = \\{e, a\\}$ and $H = \\{e, b\\}$, their free product contains elements like $a$, $b$, $ab$, $ba$, $aba$, $bab$, $abab$...\r\n> Since $a$ and $b$ do not commute, these \"words\" can grow indefinitely. Thus, the coproduct of non-trivial groups is **always infinite**.\r\n\r\n### **Conceptual Link: Universal Property**\r\nThis discussion highlighted the importance of **Universal Properties**. The coproduct is the \"most general\" group that contains both $G$ and $H$. In the Abelian world, \"most general\" implies commutativity because the *universe* is commutative. In the general Group world, \"most general\" implies no relations at all between $G$ and $H$, leading to the infinite complexity of word construction.\r\n\r\n### **Further Association: Algebraic Topology**\r\nThe concept of the Free Product isn't just an algebraic curiosity; it is fundamental in Topology.\r\n*   **The Seifert-van Kampen Theorem:** This theorem states that the fundamental group of a union of two path-connected spaces (joined at a point) is the **Free Product** of their individual fundamental groups.\r\n*   *Example:* The fundamental group of a \"Figure 8\" shape (two circles touching) is the free product of two integers, $\\mathbb{Z} * \\mathbb{Z}$, which creates a massive, non-abelian structure representing all the complex ways you can loop around the two holes.\r\n\r\n---\r\n\r\n## Fragment II: The \"Complain\" vs. \"Explain\" Incident\r\n**A linguistic singularity and a poor pear.**\r\n\r\nWhile grappling with Halmos’s notation, I intended to ask **Nianyi** to clarify the definitions. However, a typo turned \"explain\" into \"complain.\"\r\n\r\n> **G.J.M:** \"can you please **complain** about it\"\r\n> **Nianyi:** \"yes... fuck a inf... mission completed\"\r\n\r\nNianyi took the request literally. To formally fulfill the request to \"complain,\" he posted a classic meme featuring a magician:\r\n\r\n> **The Meme Logic:**\r\n> The magician announces: \"And for my next trick I will **dissapear**.\"\r\n> This is a pun on **\"diss a pear\"** (to disrespect a pear).\r\n> The punchline follows with the magician verbally attacking a fruit: *\"Fuck you pear, you taste like shit.\"*\r\n\r\nI hastily corrected myself to \"explain\" (or \"caoplain,\" acknowledging the chaos), but the damage to the pear was already done. This moment served as a humorous interlude before tackling the heavy analysis concepts.\r\n\r\n---\r\n\r\n## Fragment III: Deciphering $\\limsup$ and $\\liminf$\r\n**\"We can't just find the sup of the sequence, cause we want the asymptotic one.\"**\r\n\r\nMy primary struggle was connecting the set-theoretic definition of limits in *Measure Theory* (Halmos,**GTM 18**) with the more familiar definitions from Calculus.\r\n$$ \\limsup_{n \\to \\infty} E_n = \\bigcap_{n=1}^{\\infty} \\bigcup_{k=n}^{\\infty} E_k $$\r\n\r\n**Nianyi** provided a crucial breakdown using the sequence $S_n = \\sin(n) - 1/n$. He explained that standard bounds check *all* numbers, but asymptotic bounds only care about the \"tail.\"\r\n\r\n**The Intuition:**\r\n1.  **Discard the Past:** We want to know the behavior as $n \\to \\infty$. We cannot rely on the first 10, or 100, or 1,000 terms.\r\n2.  **The Tail Sets:** The term $\\bigcup_{k=n}^{\\infty} E_k$ represents everything that can happen \"from time $n$ onwards.\"\r\n3.  **The Limit:** By taking the intersection $\\bigcap$ of these tails, we are asking: \"What elements remain possible *no matter how far* into the future we go?\"\r\n\r\n> **Concept: The Asymptotic Envelope**\r\n> $\\limsup x_n$ is essentially the \"ceiling\" of the sequence's eventual behavior. It is the lowest value $L$ such that for any $\\epsilon > 0$, the sequence eventually stays below $L + \\epsilon$ (mostly), but frequently touches near $L$.\r\n\r\n### **Conceptual Link: Probability Theory**\r\nThe set-theoretic definition discussed that night is directly equivalent to the concept of **\"Infinitely Often\" (i.o.)** in Probability:\r\n*   **$\\limsup E_n$ (The Event \"i.o.\"):** An element $x$ belongs to the $\\limsup$ if it falls into the sets $E_n$ for an infinite number of $n$'s.\r\n    *   *Translation:* \"This event keeps happening again and again, forever.\"\r\n*   **$\\liminf E_n$ (The Event \"Eventually\"):** An element $x$ belongs to the $\\liminf$ if it eventually enters the sets and never leaves.\r\n    *   *Translation:* \"From some point onward, this event happens every single time.\"\r\n\r\n### **Further Association: The Borel-Cantelli Lemmas**\r\nThis conversation lays the groundwork for the **Borel-Cantelli Lemmas**, a cornerstone of Measure Theory.\r\n*   If the sum of measures $\\sum \\mu(E_n) < \\infty$, then the measure of $\\limsup E_n$ is 0.\r\n*   *Intuition:* If the total \"probability\" of a sequence of events is finite, then it is almost certain that these events will stop happening eventually. They will not occur \"infinitely often.\""
  },
  "graph-alg": {
    "title": "Prop Presentations for Linear Algebra: The $\\mathbf{cb}_k$ Calculus",
    "date": "2021-06-21",
    "content": "## Overview\r\n\r\nI have finally traced the definitive origin of this elegant piece of graphical mathematics by Dr. Peng! The fragment I was studying belongs to the seminal work **\"Graphical Linear Algebra\"** (specifically, see **arXiv:2105.06244**). This paper provides the rigorous categorical \"source code\" for representing linear algebra not through grids of numbers, but through the topology of string diagrams.\r\n\r\nThe specific formalism identified is the theory $\\mathbf{cb}_k$ (standing for *commutative bialgebra* with *scalars* over a ring $k$). The central result is breathtaking in its simplicity and power: this diagrammatic language is a complete presentation for the prop $\\mathbf{Mat}_k$. In other words, **diagrams are matrices**, and topological manipulation is linear algebra.\r\n\r\nFor those interested in a more pedagogical entry point, the authors maintain an incredible resource at **[graphicallinearalgebra.net](https://graphicallinearalgebra.net/)**, which unfolds this theory as a narrative about the interaction between two fundamental operations: Copying and Adding. Below is a detailed academic note synthesizing the formal definition from the paper with the intuitive insights from the website.\r\n\r\n![DEMO](/fragments/graph-alg/demo.jpeg)\r\n\r\n***\r\n\r\n## Academic Note: The Prop $\\mathbf{cb}_k$ and Diagrammatic Reasoning\r\n\r\n### 1. Introduction to the Formalism\r\nThe core idea is to define a **Prop** (Product and Permutation category)—a symmetric monoidal category where objects are natural numbers representing wire counts ($n, m, \\dots$) and morphisms are diagrams mapping $n$ inputs to $m$ outputs.\r\n\r\nThe specific prop defined in the literature is $\\mathbf{cb}_k$. It models the behavior of matrices over a ring $k$ equipped with the direct sum operation.\r\n\r\n### 2. Generators: The Alphabet of Linear Algebra\r\nAccording to **Definition 1.1** (based on [34, Defn 3.4] in the source), the language is built from three distinct classes of generators.\r\n\r\n*(Note: In the diagrams below, time flows from bottom to top. Inputs are at the bottom, outputs are at the top.)*\r\n\r\n**A. The Copying Structure (The \"White\" Comonoid)**\r\nThese generators form a commutative comonoid structure.\r\n*   **The Copier ($\\Delta$):** A white node splitting 1 wire into 2.\r\n    $$\r\n    \\begin{matrix}\r\n    \\mid & \\mid \\\\\r\n    \\nwarrow & \\nearrow \\\\\r\n       & \\circ & \\\\\r\n       & \\mid &\r\n    \\end{matrix}\r\n    $$\r\n    *   *Semantics:* This represents the linear map $V \\to V \\oplus V$ given by $v \\mapsto (v, v)$. In the blog's terminology, this is the \"Crema\"—the ability to clone data.\r\n\r\n*   **The Discarder/Counit ($\\epsilon$):** A white node terminating a wire.\r\n    $$\r\n    \\begin{matrix}\r\n       \\circ \\\\\r\n       \\mid\r\n    \\end{matrix}\r\n    $$\r\n    *   *Semantics:* This is the map $V \\to \\{0\\}$, effectively \"deleting\" a variable.\r\n\r\n**B. The Adding Structure (The \"Grey\" Monoid)**\r\nThese generators form a commutative monoid structure.\r\n*   **The Adder ($\\mu$):** A grey (shaded) node merging 2 wires into 1.\r\n    $$\r\n    \\begin{matrix}\r\n       & \\mid & \\\\\r\n       & \\bullet & \\\\\r\n    \\nearrow & & \\nwarrow \\\\\r\n    \\mid & & \\mid\r\n    \\end{matrix}\r\n    $$\r\n    *   *Semantics:* This represents the linear map $V \\oplus V \\to V$ given by $(u, v) \\mapsto u + v$. The blog refers to this as \"Zucchero\"—combining resources.\r\n\r\n*   **The Zero/Unit ($\\eta$):** A grey node starting a wire from nothing.\r\n    $$\r\n    \\begin{matrix}\r\n       \\mid \\\\\r\n       \\bullet\r\n    \\end{matrix}\r\n    $$\r\n    *   *Semantics:* This injects the additive identity (0) into the wire ($k \\to V$).\r\n\r\n**C. The Scalar Structure**\r\n*   **Scalar Multiplication:** A box or bead labeled with $a \\in k$.\r\n    $$\r\n    \\begin{matrix}\r\n       \\mid \\\\\r\n       \\boxed{a} \\\\\r\n       \\mid\r\n    \\end{matrix}\r\n    $$\r\n    *   *Semantics:* Represents the map $v \\mapsto a \\cdot v$.\r\n\r\n---\r\n\r\n### 3. The Equational Theory (Relations)\r\nThe power of $\\mathbf{cb}_k$ comes from the rules governing how these nodes interact. The system is defined modulo the equations of a **Bicommutative Bialgebra**.\r\n\r\n**I. Monoid and Comonoid Laws**\r\n*   **Associativity (Grey):** Connecting two Adders in sequence is equivalent regardless of grouping.\r\n    $$\r\n    \\begin{matrix}\r\n    \\mid \\\\ \\bullet \\\\ \\nearrow \\ \\nwarrow \\\\ \\mid \\quad \\ \\bullet \\\\ \\quad \\ \\nearrow \\ \\nwarrow\r\n    \\end{matrix}\r\n    \\quad = \\quad\r\n    \\begin{matrix}\r\n    \\mid \\\\ \\bullet \\\\ \\nearrow \\ \\nwarrow \\\\ \\bullet \\quad \\ \\mid \\\\ \\nearrow \\ \\nwarrow \\quad\r\n    \\end{matrix}\r\n    $$\r\n*   **Co-associativity (White):** The same law applies to the Copying structure (upside down).\r\n*   **Commutativity:** The Adder and Copier are symmetric; swapping input/output wires changes nothing.\r\n\r\n**II. The Bialgebra Law**\r\nThis is the most critical equation in the entire system. It defines how Addition and Copying interact. It asserts that **copying the result of an addition** is the same as **adding the results of copies**.\r\n\r\n$$\r\n\\text{Diagrammatically:}\r\n$$\r\n$$\r\n\\begin{matrix}\r\n  \\mid & & \\mid \\\\\r\n  \\nwarrow & & \\nearrow \\\\\r\n   & \\circ & \\\\\r\n   & \\mid & \\\\\r\n   & \\bullet & \\\\\r\n  \\nearrow & & \\nwarrow \\\\\r\n  \\mid & & \\mid\r\n\\end{matrix}\r\n\\quad = \\quad\r\n\\begin{matrix}\r\n   & \\mid & & \\mid & \\\\\r\n   & \\bullet & & \\bullet & \\\\\r\n   \\nearrow & & \\times & & \\nwarrow \\\\\r\n   & \\circ & & \\circ & \\\\\r\n   & \\mid & & \\mid &\r\n\\end{matrix}\r\n$$\r\n\r\n*   **Left Hand Side:** Add two inputs ($\\bullet$), then Copy the result ($\\circ$).\r\n*   **Right Hand Side:** Copy both inputs first ($\\circ \\circ$), swap the inner wires ($\\times$), and Add them separately ($\\bullet \\bullet$).\r\n\r\nAlgebraically, this enforces the distributive law:\r\n$$ \\Delta(x + y) = \\Delta(x) + \\Delta(y) $$\r\n\r\n**III. Scalar Relations**\r\nThe \"Additional Equations\" ensure the scalars behave as a Ring:\r\n*   **Multiplication:** Composing box $a$ and box $b$ equals box $ab$.\r\n    $$\r\n    \\begin{matrix} \\boxed{b} \\\\ \\mid \\\\ \\boxed{a} \\end{matrix} \\quad = \\quad \\begin{matrix} \\boxed{ab} \\end{matrix}\r\n    $$\r\n*   **Additivity:** Parallel scalars summed together equal the scalar of the sum.\r\n    $$\r\n    \\begin{matrix}\r\n    \\mid \\\\ \\bullet \\\\ \\nearrow \\ \\nwarrow \\\\ \\boxed{a} \\quad \\boxed{b} \\\\ \\nwarrow \\ \\nearrow \\\\ \\circ \\\\ \\mid\r\n    \\end{matrix}\r\n    \\quad = \\quad\r\n    \\begin{matrix}\r\n    \\mid \\\\ \\boxed{a+b} \\\\ \\mid\r\n    \\end{matrix}\r\n    $$\r\n*   **Identity:** A scalar box of $1$ is just a wire. A scalar box of $0$ is equivalent to Discarding then creating a Zero unit ($\\epsilon$ followed by $\\eta$).\r\n\r\n---\r\n\r\n### 4. The Main Result: Completeness\r\n**Proposition 1.2 [34, Prop. 3.9] states:**\r\n> Given a ring $k$, $\\mathbf{cb}_k$ is a presentation for the prop $\\mathbf{Mat}_k$ of matrices over $k$ under the direct sum.\r\n\r\n**Interpretation:**\r\nThis is a **Soundness and Completeness** theorem.\r\n1.  **Soundness:** Every equation derivable in diagrams is a true statement about matrices.\r\n2.  **Completeness:** *Every* true statement about matrices can be proven using these diagrams.\r\n\r\nThere is an isomorphism of categories:\r\n$$ \\mathbf{cb}_k \\cong \\mathbf{Mat}_k $$\r\nThis transforms linear algebra from a theory of coordinates to a theory of **connectivity**.\r\n\r\n---\r\n\r\n## Commentary: Methodology and Applications\r\n\r\n### Why Graphical Linear Algebra?\r\nThe transition from classical matrix notation ($A_{ij}$) to the $\\mathbf{cb}_k$ calculus is analogous to the shift from assembly language to a high-level programming language.\r\n\r\n1.  **Basis Independence:**\r\n    Classical linear algebra forces us to choose a basis immediately to write down a matrix. In $\\mathbf{cb}_k$, we manipulate the linear maps directly via their structural properties (Copy/Add). We only \"compile\" to a matrix when absolutely necessary.\r\n\r\n2.  **Topological Insight:**\r\n    Many properties of linear maps (like the trace, transpose, or feedback) are topological.\r\n    *   **Transpose:** Corresponds to rotating the diagram 180 degrees.\r\n    *   **Trace:** Corresponds to connecting an output wire back to an input wire (a loop).\r\n    *   Standard algebraic proofs involving indices ($\\sum_k A_{ik}B_{kj}$) are notoriously error-prone. The diagrammatic proof is often a visual tautology—you simply \"pull the wires straight.\"\r\n\r\n3.  **Connection to Quantum Mechanics (ZX-Calculus):**\r\n    The structure of $\\mathbf{cb}_k$ is strikingly similar to the **ZX-calculus** used in quantum computing. In ZX, we also have two colors (Green and Red spiders) that satisfy a bialgebra law.\r\n    *   In Linear Algebra ($\\mathbf{cb}_k$): The structures are \"Copy\" ($\\circ$) and \"Add\" ($\\bullet$).\r\n    *   In Quantum (ZX): The structures correspond to complementary observables (Z and X bases).\r\n    Mastering $\\mathbf{cb}_k$ is an excellent prerequisite for understanding categorical quantum mechanics.\r\n\r\n### Applicability\r\nThis method is most effective when:\r\n*   **Analyzing Large Networks:** Signal flow graphs and electrical circuits are naturally modeled by these diagrams.\r\n*   **Proving Structural Identities:** When proving identities that hold for *any* dimension $n$, diagrams are superior to matrices, which often require fixing $n$.\r\n*   **Tensor Networks:** In machine learning and physics, the management of indices in tensor contractions is painful. Diagrammatic notation handles these contractions implicitly via wire connectivity.\r\n\r\n## References\r\n*   **Primary Paper:** *Graphical Linear Algebra*, arXiv:2105.06244.\r\n*   **Original Definitions:** Bonchi, Sobociński, Zanasi, *Interacting Hopf Algebras*, J. Pure Appl. Algebra (2014).\r\n*   **Web Resource:** [Graphical Linear Algebra](https://graphicallinearalgebra.net/) - A pedagogical blog by Pawel Sobocinski."
  },
  "hdc-email": {
    "title": "Follow-up on Hugo Duminil-Copin's Lecture: Probing SAW Universality and 4D Triviality",
    "date": "2025-11-27",
    "content": "## Overview\r\n\r\nFollowing the suggestion from Professor Hugo Duminil-Copin, I sent a detailed email to him to follow up on the questions I was unable to ask during the Q&A session. The email, sent on November 27, 2025, covers two major topics: the subtle mathematical reasons behind the solvability of **Self-Avoiding Walks (SAW)** on the honeycomb lattice versus the square lattice (the **Symmetry-Complexity Paradox**), and a more conceptual inquiry into his work on the **Marginal Triviality of the 4D $\\Phi^4$ model** in Quantum Field Theory. Since the email has not been answered, I plan to resolve these questions through self-study, and the formatted email below serves as the structured outline for that research.\r\n\r\n***\r\n\r\n## Detailed Summary of the Follow-Up Email\r\n\r\nThe email is structured into an introduction and two major sections, each containing a set of focused questions.\r\n\r\n### 1. Introduction and Context\r\n\r\nI identified myself as the undergraduate student from Nanjing University (NJU) who specifically traveled to Southeast University (SEU) for the talk and was the first to ask for a joint photograph. The purpose of the email was to convey my enthusiasm and follow up on the promised questions due to Professor Duminil-Copin's tight schedule.\r\n\r\n### 2. Part I: SAW Universality and Lattice Geometry\r\n\r\nThis section dives deep into the **Self-Avoiding Walk (SAW)** problem, focusing on the contrast between the solvable honeycomb lattice and the unsolved square lattice.\r\n\r\n*   **Core Fascination:** The \"analogy\" thinking that led to the solution via the **parafermionic operator** was highlighted as the central point of interest.\r\n*   **The Debate:** I presented a summary of a debate with a roommate (Yuyang Su) regarding the underlying reason for the honeycomb lattice's solvability.\r\n    *   *Opposing Argument:* The roommate suggested solvability is merely due to the **lower coordination number** (3 choices on honeycomb versus 4 on square).\r\n    *   *My Counter-Argument (Hypothesis):* I argued that this simplistic view violates the **Universality Principle** of statistical mechanics and that historical examples (like the solvable Ising model on the square lattice) contradict the idea that local degrees of freedom are the primary barrier. I hypothesized that the solution hinges on a specific, non-obvious **algebraic cancellation** allowed by the honeycomb's geometry but absent in the square lattice.\r\n\r\n*   **The Questions:**\r\n    1.  **Symmetry-Complexity Paradox:** Why does the superior four-fold rotational symmetry of the square lattice appear to *complicate* the analysis, while the less symmetric honeycomb lattice permits a closed-form solution? Is there a deeper mathematical principle governing this inverse relationship?\r\n    2.  **Methodological Extension:** Since the current method does not apply to the square lattice, could a modified approach involving **parafermionic operators**, perhaps integrated with additional symmetries or disorder operators, be the key to future progress?\r\n\r\n### 3. Part II: 4D Triviality and Scaling Limits\r\n\r\nThe second part transitions to Professor Duminil-Copin's work on fundamental physics, specifically the paper *Aizenman, Duminil-Copin, Marginal triviality of the scaling limits of critical 4D Ising and $\\phi^4$ models*, which was recommended by members of the Chinese academic forum \"Chaoli.\" I noted the connection to a forum member, Chengyang Shao, a postdoc at HDC's home institution, IHÉS.\r\n\r\n*   **The Concept:** The focus is on **marginal triviality**—the finding that the 4D $\\Phi^4$ model behaves like a Gaussian (free) field in the scaling limit.\r\n\r\n*   **The Questions:**\r\n    1.  **Geometric Intuition:** From an intuitive or geometric standpoint (e.g., in the language of **random currents** or polymers), what specific feature in four dimensions causes the non-Gaussian interactions to effectively vanish, making 4D intersections appear **\"transparent\"** in the limit?\r\n    2.  **SAW Connection:** Given that the **upper critical dimension for SAW is 4**, does the $\\Phi^4$ model's triviality imply that the \"self-avoiding\" constraint becomes geometrically negligible in 4D, making the polymer path behave essentially like a simple **random walk**?\r\n    3.  **Dynamical Perspective (Critical Regularity Structures):** A question posed by a forum member (Hachiri Tomoko) on the dynamic $\\Phi^4$ equation: Considering the static triviality and the success of Martin Hairer’s **Regularity Structures** theory in sub-critical cases (like $\\Phi^4_3$), is there a **\"critical version\" of regularity structures** (or an equivalent tool) that can rigorously describe the 4D dynamic $\\Phi^4$ equation?\r\n\r\n### 4. Conclusion\r\n\r\nThe email concluded with a polite acknowledgment of the volume of questions, stating that a brief comment or pointer to relevant literature would be sufficient, and reiterating my sincere enthusiasm.\r\n\r\n***\r\n\r\n## The Follow-up Email: Research Outline\r\n\r\nSince the email has not yet been answered, it will now serve as my personal research outline for investigating these advanced topics.\r\n\r\n> Subject: **Follow-up on your lecture at SEU: SAW Universality & 4D Triviality (Student from NJU)**\r\n> \r\n> From: Runnel Zhang <runnel.zhang@smail.nju.edu.cn>\r\n> \r\n> Date: Thursday, November 27, 2025, 10:08 PM\r\n> \r\n> To: Hugo Duminil-Copin <hugo.duminil@unige.ch>\r\n> \r\n> Dear Professor Duminil-Copin,\r\n> \r\n> I hope this email finds you well.\r\n> \r\n> I am the undergraduate student from Nanjing University who attended your lecture at Southeast University on November 26th. I traveled from NJU specifically to hear your talk, and I was the one who rushed to the stage first to ask for a photo with you. It was truly an inspiring experience for me.\r\n> \r\n> At that time, I had a few questions, but due to your tight schedule, you kindly suggested that I reach out via email. I am writing to follow up on that conversation.\r\n> \r\n> My first set of questions concerns the honeycomb lattice **Self-Avoiding Walks (SAW)** part of your talk. It is such a legendary work, and I was fascinated by the \"**analogy**\" thinking using the **parafermionic operator**. While my background is not yet deep enough to fully grasp the rigorous proof, I had an interesting debate with my roommate regarding the intuition behind it.\r\n> \r\n> My roommate Yuyang Su argued that the complexity of the SAW problem is primarily determined by the coordination number (the number of available directions at a vertex)—that the honeycomb lattice is solvable simply because a walker only has 3 choices, whereas other lattices have more. I respectfully disagreed with him. I argued that in statistical mechanics, difficulty rarely scales linearly with the number of local degrees of freedom. If it were just about counting paths, the principle of **Universality** would be compromised. I pointed out that historically, some integrable models (like the Ising model) were solved on square lattices despite having a higher coordination number, implying that \"having more directions\" is not the fundamental barrier. I suspect the honeycomb lattice succeeds because its geometry allows for a specific **algebraic cancellation** that the square lattice forbids—but I couldn't explain to him why the square lattice, with its superior symmetry, fails to support this structure.\r\n> \r\n> Driven by this discussion, I have formulated the following questions:\r\n> \r\n> 1. The square lattice possesses a higher four-fold rotational **symmetry** compared to the honeycomb lattice, which intuitively should simplify the problem. Yet in reality, this seems to make it more challenging. Is there a deeper mathematical principle explaining why **increased symmetry can sometimes complicate rather than simplify the analysis**?\r\n> 2. As you noted, the method does not apply directly to the square lattice, where the connective constant is still unknown. Do you think modified versions of the **parafermionic approach**—perhaps incorporating additional symmetries or **disorder operators**—could eventually yield progress there?\r\n> \r\n> The second part of my email relates to your other work. I am the youngest core member of a small academic forum here in China called \"**Chaoli**\". After sharing my excitement about your lecture, our members recommended that I read your work on 4D physics: *Aizenman M., Duminil-Copin H., Marginal triviality of the scaling limits of critical 4D Ising and $\\phi^4$ models.*\r\n> \r\n> Interestingly, the introductory article on our forum regarding this paper (https://chaoli.club/index.php/6841/) was authored by Chengyang Shao, who I believe is currently a postdoc at **IHÉS**, your home institution!\r\n> \r\n> Since my background in quantum field theory is still developing, I have a more intuitive question regarding this work:\r\n> \r\n> 1. The result establishes the \"**marginal triviality**\" (**Gaussian behavior**) in 4D. Intuitively, what specific geometric feature of the \"**random currents**\" or polymer representation in 4D causes the non-Gaussian interactions to vanish? Is there a visual way to understand why **4D intersections become \"transparent\"** in the scaling limit compared to 3D?\r\n> 2. This brings me back to your lecture on SAW. In 2D, the self-avoiding constraint fundamentally changes the universality class. However, since the **upper critical dimension for SAW is 4**, does this mean that in 4D, the \"**self-avoiding**\" constraint becomes geometrically negligible? Is the triviality of the **$\\phi^4$ field** essentially stating that the polymer representation behaves like a simple **random walk** because the paths rarely intersect in such high dimensions?\r\n> 3. One of our members nicknamed Hachiri Tomoko raised a question regarding the dynamical perspective. Since the static $\\phi^4_4$ is trivial, how should we understand this via **Stochastic Quantization**? Martin Hairer’s **Regularity Structure theory** has successfully handled the sub-critical cases (like $\\Phi^4_3$).\r\n> **The Question: Is there a \"critical version\" of regularity structures (or similar tools) that can rigorously describe the 4D dynamic $\\phi^4$ equation?** (This might be slightly tangential... I'm just the *porteur* of this question)\r\n> \r\n> Thank you so much for your time.\r\n> \r\n> I realize this email contains quite a few questions. Please do not feel pressured to answer them in detail. If you are busy, a brief comment or a pointer to relevant reading references would already be incredibly helpful. I do not wish to disturb your busy schedule but simply wanted to convey my enthusiasm.\r\n> \r\n> Sincerely yours,\r\n> \r\n> **Runnel Zhang** | Undergraduate Student\r\n> Nanjing University | Jianxiong Academy\r\n> 22 Hankou Road, Gulou District, Nanjing 210093, China\r\n> Phone: +86 198 5277 1690\r\n> runnel.zhang@smail.nju.edu.cn | nju.edu.cn"
  },
  "hdc-lecture": {
    "title": "A Successful Star-Chase: Cutting Class for Hugo Duminil-Copin's Lecture on Self-Avoiding Walks",
    "date": "2025-11-26",
    "content": "## Overview\r\n\r\nI cut class to attend a lecture by Fields Medalist Hugo Duminil-Copin and was the first to rush forward for a photo afterward—a completely successful fan moment! Initially, I thought I would not understand anything and was just going to observe, but Hugo's presentation was surprisingly accessible, which is also closely related to his choice of topic.\r\n\r\n![PHOTO WITH HDC](/fragments/hdc-lecture/default.jpeg)\r\n\r\n***\r\n\r\n## Detailed Summary of the Lecture Content\r\n\r\nThe lecture, while initially confusing to me, proved to be an illuminating exploration of combinatorial probability and statistical mechanics, primarily focusing on **Self-Avoiding Walks (SAW)**, not the more general concept of a random walk.\r\n\r\n### 1. Structure and Initial Analogy\r\n\r\nThe beginning of the talk was framed using an accessible analogy, which I initially summarized as:\r\n\r\n> \"The presentation was structured a bit like teaching sequences to high school students, where you look for a pattern step by step, and then are told the pattern you found is wrong, which served as an introduction to the difficulties of the random walk.\"\r\n\r\nThis method served to illustrate the inherent challenges and non-obvious nature of finding closed-form solutions in probability theory, especially concerning the intricacies of walks on lattices.\r\n\r\n### 2. The Focus: Self-Avoiding Walks (SAW)\r\n\r\nWhile I first mistook the subject for general random walks, the core of the discussion was the **Self-Avoiding Walk (SAW)**, a critical model in statistical mechanics for polymer chains.\r\n\r\n| Concept | Explanation |\r\n| :--- | :--- |\r\n| **Self-Avoiding Walk (SAW)** | A sequence of moves on a lattice that does not visit the same site more than once. It is a fundamental model for the shape of a long-chain polymer in a solvent. |\r\n| **Random Walk** | A mathematical formalization of a path that consists of a succession of random steps, typically allowing repetition of sites. |\r\n\r\n### 3. Key Concepts and Results Discussed\r\n\r\nHDC moved from general concepts to specific, groundbreaking results, highlighting the influence of geometry and symmetry on problem solvability.\r\n\r\n#### The Space-Filling Property\r\n\r\nIn the earlier part of the lecture, HDC emphasized a crucial property of SAW: **Space-Filling**.\r\n\r\n*   **Concept:** He discussed how, under certain conditions, supercritical self-avoiding walks are space-filling. This property is foundational to understanding the macroscopic behavior of the walks.\r\n*   **Reference:** This topic relates to his work: *H. Duminil-Copin, G. Kozma, and A. Yadin, “Supercritical self-avoiding walks are space-filling,” Probability Theory and Related Fields, 2014.* (arXiv:1110.3074) \r\n\r\n#### The Honeycomb Lattice Result\r\n\r\nThe central focus of his talk, and perhaps the main 'hook' for the audience, was the analytical solution for the **connective constant** of the honeycomb lattice.\r\n\r\n*   **Progression:** The lecture progressed from analyzing the random walk on a square lattice to the SAW on a honeycomb (hexagonal) lattice.\r\n*   **Groundbreaking Result:** HDC spoke at length about his result for the honeycomb lattice, which is currently \"the only determined exact analytic expression for a 2D case.\"\r\n*   **Connective Constant:** This is the exponential growth rate of the number of SAWs of length *n* on a given lattice.\r\n*   **Reference:** This result was published in a top-tier journal, reflecting the significance of the work: *H. Duminil-Copin and S. Smirnov, “The connective constant of the honeycomb lattice equals $\\sqrt{2 + \\sqrt{2}}$,” Annals of Mathematics, 2012.* (arXiv:1007.0575) \r\n*   **Confidence:** The fact that he presented an *Annals of Mathematics* result simply as an attention-grabbing \"hook\" demonstrates the confidence one would expect from a Fields Medalist.\r\n\r\n#### The Role of Geometry and Symmetry\r\n\r\nHDC then addressed the difficulty of the square lattice problem, explaining \"why his method is not viable for the random walk on the square lattice,\" referencing the \"influence of symmetry and other properties.\"\r\n\r\n### 4. The Methodological Takeaway\r\n\r\nThe concluding part of the lecture shifted away from \"hardcore content\" and focused on broader mathematical philosophy.\r\n\r\n> \"Behind this, there wasn't much hardcore content, just discussions about problem-solving mindsets.\"\r\n\r\n*   **Analogy as a Theme:** The overarching theme was the use of **Analogy** as a key problem-solving methodology. He emphasized drawing connections between different mathematical and physical systems.\r\n*   **Final Note:** He brought up **Fractals** at the end, primarily drawing an analogy between fractal properties and the previously discussed SAW characteristics like the space-filling property and symmetry.\r\n\r\n### 5. Post-Lecture Interaction and Missed Opportunities\r\n\r\nI missed the formal Q&A session. I had intended to ask a few questions privately, but HDC stated he did not have time and suggested I contact him via email instead. Nonetheless, I successfully achieved my goal of getting the joint photograph, which left me very satisfied.\r\n\r\n### 6. Observations and Anecdotes (Easter Eggs)\r\n\r\n1.  **French Mathematical Notation:** HDC uses traditional **French mathematical notation**, employing a **comma (`,`) as the decimal separator**. This initially caused significant confusion.\r\n2.  **French-English:** During the lecture, HDC spelled *Object* as **\"Objet,\"** reflecting a typical French-English linguistic crossover.\r\n3.  **Educational Commentary:** During the subsequent Q&A, a discussion about mathematics education in China and France led HDC to possibly mention the *Jiang Ping incident*. He seemed to have only partial or incomplete knowledge of the event.\r\n\r\n***\r\n\r\n## Contextual Discussion (From the Comments Section)\r\n\r\nThe lecture sparked a brief discussion that provided important context regarding HDC's overall contributions, particularly highlighting the distinction between his work known to mathematicians and that known to physicists.\r\n\r\n*   **Perspective from Computer Science (My view):** As someone primarily focused on Computer Science, my key recognition of HDC's work lies in his \"application of statistical physics ideas to solve problems in probability theory,\" specifically mentioning \"using the *parafermionic operator* to solve the honeycomb SAW problem,\" which is an excellent example of the **Analogy** he stressed in the lecture.\r\n*   **Perspective from Physics:** A commentator noted that for physicists, HDC's \"most important contribution is proving the **non-existence of the 4D $\\Phi^4$ fundamental theory**.\" This highlights the breadth of his influence, extending into constructive quantum field theory, an area I was not familiar with.\r\n\r\n| Concept | Explanation |\r\n| :--- | :--- |\r\n| **Parafermionic Operator** | A complex mathematical object used in conformal field theory and statistical mechanics that helped provide the exact solution to the honeycomb lattice SAW problem. It is a powerful example of how tools from physics can solve purely mathematical problems. |\r\n| **4D $\\Phi^4$ Theory** | A specific model in quantum field theory involving a scalar field $(\\Phi)$. Its non-existence in four dimensions (proven by HDC and others) is a crucial, high-impact result in fundamental physics. |"
  },
  "hopf-meme": {
    "title": "Echoes of Summer — From Hopf Fibrations to Higher Algebra",
    "date": "2024-07-27",
    "content": "## Overview\r\n\r\nDuring the summer, while scrolling through my QQ space, I stumbled upon a dynamic update from **Dr. Peng Keyao** (now, rightfully, **Prof. Peng**). It was a poster for his recent lecture titled *\"From Elementary Arithmetic to Higher Algebra.\"* Seeing his name instantly triggered a wave of nostalgia, transporting me back to the summer of 2021.\r\n\r\nThree years ago, he gave us a lecture on the **Hopf Fibration**. I still vividly remember spending days preparing for it, scribbling notes, and trying to wrap my head around the topology of spheres. The note is available at [Chaoli Forum](https://chaoli.club/index.php/6596), with a DOI: [10.6084/M9.FIGSHARE.20310042](https://doi.org/10.6084/M9.FIGSHARE.20310042).\r\n\r\nTime changes things — Dr. Peng has ascended to a postdoc at the Université de Bourgogne and been teaching Algebraic Geometry courses, and the topics have evolved from classical topology to the cutting-edge realm of **Infinity Categories** and **Higher Algebra**.\r\n\r\nAlthough I deeply regret missing his 2024 lecture, looking at the lecture abstract and the meme he famously shared back in the day (which seems to bridge his past and present research), I feel a strange sense of temporal overlap. The memories of 2021 have superimposed onto the reality of 2024.\r\n\r\nBelow is the context of his recent talk, followed by my attempt to decode that legendary \"Galaxy Brain\" meme, tracing the path from a simple sphere mapping to the profound \"truth\" of $0=1-1=-1+1=0$.\r\n\r\n---\r\n\r\n## Part I: The Lecture\r\n\r\n![LECTURE](/fragments/hopf-meme/lecture.jpg)\r\n\r\n**Title:** Entering the Hall — From Elementary Arithmetic to Higher Algebra\r\n**Speaker:** Peng Keyao (Université de Bourgogne)\r\n\r\n**The Abstract:**\r\n> *\"Higher Algebra\" is a brand-new mathematical direction independently developed by Jacob Lurie and others. It is built upon a foundation known as \"Infinity Categories\" (or $\\infty$-categories). Here, mathematical objects are endowed with \"Homotopy.\"*\r\n>\r\n> *Starting from a meme, we will encounter the Hopf Fibration, Homotopy Groups, Configuration Spaces, and the accompanying Algebraic K-Theory in this report. Simultaneously, we will gradually uncover the truth behind \"0=1-1=-1+1=0\".*\r\n\r\n---\r\n\r\n## Part II: Decoding the \"Galaxy Brain\" Meme\r\n\r\n![MEME](/fragments/hopf-meme/meme.jpg)\r\n\r\nProf. Peng used this meme to illustrate the vertiginous ascent of mathematical abstraction. It represents the journey from concrete geometric intuition to the abstract machinery of stable homotopy and K-theory. Here is my interpretation of the progression:\r\n\r\n### **Level 1: The Definition**\r\n$$ S^3 \\sim \\mathbb{C}^2 \\setminus \\{0\\} \\to \\mathbb{C}P^1 \\sim S^2 $$\r\nThis is the standard definition of the **Hopf Fibration**.\r\n*   **Context:** It describes a mapping from the 3-sphere ($S^3$) to the 2-sphere ($S^2$).\r\n*   **The Math:** By treating $S^3$ as the unit sphere in $\\mathbb{C}^2$, we map points $(z_1, z_2)$ to their ratio $[z_1:z_2]$ in the Complex Projective Line ($\\mathbb{C}P^1$), which is topologically a 2-sphere ($S^2$).\r\n*   **Significance:** This was the first example of a non-trivial fiber bundle, where the \"fibers\" (pre-images of points) are circles ($S^1$) that are linked together.\r\n\r\n### **Level 2: The Visualization**\r\n**The Image:** A visualization of nested tori filling space.\r\n*   **Interpretation:** This represents the stereographic projection of the Hopf Fibration into $\\mathbb{R}^3$. The fibers (circles) wrap around each other in a way that no two fibers can be separated without cutting. It is the geometric intuition behind the algebraic formula in Level 1—the beauty of topology made visible.\r\n\r\n### **Level 3: The First Non-Trivial Calculation**\r\n$$ \\pi_4(S^3) \\cong \\mathbb{Z}/2\\mathbb{Z} $$\r\n**Concept:** Homotopy Groups of Spheres.\r\n*   **The Shift:** We move from looking at the map itself to calculating the *invariants*. $\\pi_n(S^k)$ measures the number of distinct ways to map an $n$-dimensional sphere into a $k$-dimensional sphere.\r\n*   **The Surprise:** One might expect $\\pi_4(S^3)$ to be trivial (0) because $4 > 3$. However, the Hopf map generates a non-trivial element. The result $\\mathbb{Z}/2\\mathbb{Z}$ indicates that there is a \"twist\" that persists. This marks the entry into the notoriously difficult field of computing higher homotopy groups.\r\n\r\n### **Level 4: The Stable Homotopy & Geometry Connection**\r\n$$ \\pi_1^s(\\mathbb{S}) \\cong \\Omega_1^{fr} $$\r\n**Concept:** The Pontryagin-Thom Construction.\r\n*   **$\\pi_1^s(\\mathbb{S})$:** This denotes the **first stable homotopy group of spheres**. \"Stable\" means we look at what happens when dimensions go to infinity (suspension).\r\n*   **$\\Omega_1^{fr}$:** This is the **framed cobordism group** of 1-manifolds.\r\n*   **The Insight:** This isomorphism is a profound result (Pontryagin-Thom theorem) that translates a difficult topological problem (homotopy groups) into a geometric one (classifying manifolds with framed boundaries). It bridges the gap between \"wobbly\" topology and rigid geometry.\r\n\r\n### **Level 5: The Ultimate Abstraction (The \"Field with One Element\")**\r\n$$ K_1(\\mathbb{F}_1) \\cong S_\\infty^{\\text{ab}} $$\r\n**Concept:** Algebraic K-Theory and $\\mathbb{F}_1$.\r\n*   **$\\mathbb{F}_1$:** The **Field with One Element**. This is a hypothetical, non-existent mathematical object that mathematicians behave *as if* it exists to unify arithmetic and geometry.\r\n*   **$S_\\infty^{\\text{ab}}$:** This likely refers to the abelianization of the infinite symmetric group, or concepts related to the sphere spectrum in a stable setting.\r\n*   **The Meaning:** At this level of enlightenment, we are doing **Algebraic K-Theory** (the study of projective modules and invariants) on this ghost field. It suggests that the stable homotopy groups of spheres (the topology from Level 4) are actually just the K-theory of $\\mathbb{F}_1$. It is a glimpse into the \"Higher Algebra\" Prof. Peng mentioned—where Number Theory and Topology become indistinguishable.\r\n\r\n### **Level 6: The \"Truth\"**\r\n$$ 0 = 1 - 1 = -1 + 1 = 0 $$\r\n**Concept:** The Eilenberg Swindle / Infinite Stability.\r\n*   **The Paradox:** In elementary arithmetic, this is trivial. But in the context of infinite structures (like the \"Infinity Categories\" mentioned in the lecture abstract), this represents the **Eilenberg Swindle**.\r\n*   **Explanation:** If you have an infinite sum or an object capable of absorbing addition (like an infinite direct sum $S = A \\oplus A \\oplus \\dots$), you can shift parentheses:\r\n    $$ S = 1 - 1 + 1 - 1 \\dots $$\r\n    $$ S = (1 - 1) + (1 - 1) + \\dots = 0 $$\r\n    $$ S = 1 + (-1 + 1) + (-1 + 1) + \\dots = 1 $$\r\n*   **Conclusion:** This is the \"God Tier\" realization. It usually proves that certain invariants (like K-groups of infinite rings) vanish (become zero). It is the mechanism that allows \"stable\" phenomena to exist. The complex machinery of Level 5 collapses into this fundamental, beautiful arithmetic trick regarding infinity.\r\n\r\n---\r\n\r\n## Final Thought\r\n\r\nThree years ago, I was just learning what a fiber bundle was. Today, seeing Prof. Peng discuss the \"Truth of $0=1-1=-1+1=0$\" via Jacob Lurie’s Higher Algebra, I realize how deep the rabbit hole goes. While I missed the lecture, re-analyzing this meme with my current understanding feels like a small, personal seminar—a quiet nod to the passage of time and the enduring elegance of mathematics."
  },
  "iutt-oct": {
    "title": "The \"Holy War\" Moves to the Server Room — Notes on Mochizuki’s Oct 2025 Report",
    "date": "2025-11-15",
    "content": "## Overview\r\n\r\nI had a disscusion on digesting Shinichi Mochizuki’s *Report on the Current Situation Surrounding Inter-Universal Teichmüller Theory (IUT)*, released this past October, with some of my net friends. Our opinions were alike. Ostensibly, this 30-page document is a rebuttal to a critical article by J.D. Boyd in *SciSci Research*, but it reads more like a philosophical manifesto than a standard mathematical response.\r\n\r\nFor those of us tracking this saga for years, the report marks a significant shift. Mochizuki appears to have largely abandoned the hope of convincing the current generation of arithmetic geometers via traditional human dialogue. His argument is that the \"social/political dynamics\" of the mathematical community have superseded \"mathematical truth.\" His proposed solution? A complete retreat into formal verification (Lean 4).\r\n\r\nWhile the tone is calmer than some of his previous blog posts, the implications are arguably more radical. He isn't just defending a proof; he is proposing a redefinition of how mathematical consensus should be reached, seemingly to bypass the \"human\" element that has rejected his theory.\r\n\r\nBelow is a breakdown of the key points and my thoughts.\r\n\r\n---\r\n\r\n## 1. The \"Label-Removal\" Defense\r\nA significant portion of the report (§2.1–§2.3) is dedicated to dismantling the famous Scholze-Stix counterargument. Mochizuki argues that the contradiction Scholze and Stix found arises because they are impermissibly \"removing labels\" from distinct copies of universes.\r\n\r\nMochizuki uses a rather elementary analogy to explain why he believes his critics are wrong:\r\n\r\n> **From Example 2.2.1:**\r\n> \"Write $\\mathbb{N}^\\dagger$ for the quotient set of $\\mathbb{N}$ obtained by identifying the elements $2 \\in \\mathbb{N}$ and $3 \\in \\mathbb{N}$... If one assumes that addition of natural numbers in $\\mathbb{N}$ is sufficiently 'robust' in the sense that it is unaffected by the label-removal... then one immediately obtains the contradiction $1 + 3 = 3$.\"\r\n\r\nMochizuki is doubling down on the idea that IUT lives or dies by its complex apparatus of distinct, labeled universes. He asserts that Scholze and Stix treated these labeled objects as identical when they shouldn't have (Concept **FA2** in the report).\r\nWhile this defense is logically self-consistent within his framework, it remains unsatisfying to the outside observer. The criticism has always been that once you enforce all these distinct labels to prevent the structure from collapsing, you also prevent the structure from interacting enough to prove the *abc* inequality. Mochizuki insists the structure holds; the community insists it's too rigid to be useful. We are still at a stalemate here.\r\n\r\n## 2. The Pivot to Lean: \"Liberating Mathematical Truth\"\r\nThis is the most fascinating and slightly dystopian part of the report (§3). Mochizuki seems to view Lean (the theorem prover) not just as a tool for verification, but as an \"ideal, universal colleague\" (**Asp2**) that doesn't suffer from the \"social dynamics\" or \"faith en masse\" of human mathematicians.\r\n\r\nHe envisions a future where academic hierarchy is determined by code:\r\n\r\n> **From §3, (Asp4):**\r\n> \"...individuals — i.e., even, potentially, 'complete amateurs'... could be hired for/promoted to high-ranking positions... not on the basis of traditional criteria... but rather on the basis of **Lean code** that is submitted to the university or journal.\"\r\n\r\nHe also admits that the formalization of IUT is currently relying on \"black boxes\" (**BBxFm** in §3.2) for the heavy lifting in anabelian geometry.\r\n\r\nI think There is an irony here. Mochizuki criticizes the community for \"faith en masse\" regarding Scholze’s views, yet he asks us to have faith in a future formalization that is currently built on black boxes. If the logical gap exists where Scholze says it does—in the interface between the additive and multiplicative structures—formalizing the surrounding architecture won't fix it. The computer will simply confirm that *if* the definitions hold, the result follows. The question remains: do the definitions mean what Mochizuki thinks they mean?\r\n\r\n## 3. The Rejection of \"Partial\" Acceptance\r\nInterestingly, Mochizuki takes a hard line against the \"compromise\" position held by some younger researchers (like Emmanuel Lepage). The compromise view is that the *anabelian geometry* in IUT is interesting and correct, even if the proof of *abc* is flawed.\r\n\r\nMochizuki rejects this separation entirely:\r\n\r\n> **From §2.4 (AnMs1):**\r\n> \"The anabelian content of IUT... can somehow be *separated* and *isolated* from the portions/aspects of IUT that relate to the *abc inequality*... this sort of distinction is **mathematically meaningless**.\"\r\n\r\n\r\nThis \"all-or-nothing\" stance is risky. By refusing to let the community salvage the \"good parts\" of the theory without accepting the main result, he isolates himself further. He characterizes the attempt to separate the theory as a \"misunderstanding,\" but to many, it looks like the only way to save the framework from total obscurity.\r\n\r\n## Conclusion\r\nThe October 2025 report confirms that the IUT debate has left the realm of standard peer review. Mochizuki effectively declares that the \"functional peer review system\" is broken because it rejected his work, and that the only valid judge left is the machine (Lean).\r\n\r\nWhile I appreciate the intellectual commitment to formalization, the report reads like a door slamming shut. The \"strategic ambiguity\" is gone. Unless the Lean formalization can unpack the specific \"black boxes\" where the contradiction is suspected to hide, this report changes nothing about the mathematical consensus—it only formalizes the disagreement."
  },
  "ivan-iutt": {
    "title": "Unveiling Arithmetic Deformation Theory: Reflections on Fesenko’s \"Notes on the work of Shinichi Mochizuki\"",
    "date": "2021-10-07",
    "content": "## Overview\r\n\r\nThe genesis of this study lies in a perspective shared by my mentor at Geek College, Dr. Keyao Peng. Amidst the polarized academic atmosphere surrounding the *Inter-universal Teichmüller (IUT)* theory, Dr. Peng adopted a stance of pure intellectual curiosity—akin to \"eating to live,\" focusing on the sustenance of knowledge rather than the politics of validity.\r\n\r\nSeveral months ago, during a fortuitous overlap between a lecture by Peter Scholze on *Toposes Online* (regarding condensed mathematics) and a seminar by Shinichi Mochizuki on *tripodal transport*, a conceptual bridge emerged. While the two theories are formally distinct, the intuition of \"gluing\" structures—and the malleability of what we consider fundamental—resonated deeply. As Dr. Peng articulated, there is a profound difficulty in what Mochizuki terms \"descent\": the realization that while the multiplicative structure of a field might be fixed (reconstructible via Galois groups), the additive structure is essentially \"floating.\" In this view, $1$ is a fixed unit, but $1+1$ carries a structural ambiguity that requires stabilization.\r\n\r\nGuided by this open-minded philosophy—treating mathematics not as a battleground but as a landscape of structural beauty—I delved into Ivan Fesenko’s extensive survey, *“Arithmetic deformation theory via arithmetic fundamental groups and nonarchimedean theta-functions.”* The following are my notes on the traditional mathematical narrative, the radical deconstruction of ring structures, and the intuitive analogies presented in the theory.\r\n\r\n---\r\n\r\n## I. The Origins: From Anabelian Geometry to Deformation\r\n\r\nTo understand IUT, one must first understand the limitations of classical arithmetic geometry. Fesenko begins by grounding the theory in the history of **Anabelian Geometry**.\r\n\r\n**The Core Philosophy:**\r\nScheme theory is rigid. Anabelian geometry asks: *Can we recover the geometric object solely from its group of symmetries (the fundamental group)?*\r\nFesenko cites the **Neukirch–Ikeda–Uchida theorem**, which confirms that for number fields, the absolute Galois group $G_K$ determines the field $K$. This was the precursor to Grothendieck's vision for hyperbolic curves.\r\n\r\n> **Original Text (p. 408):**\r\n> *\"An irreducible smooth projective algebraic curve $C$ defined over a field of characteristic zero can be defined over an algebraic closure $\\mathbb{Q}^{alg}$... if and only if there is a covering $C \\to \\mathbb{P}^1$ which ramifies over no more than three points of $\\mathbb{P}^1$.\"* — **Belyi’s Theorem**\r\n\r\n**Why this matters:** Belyi’s theorem implies that the absolute Galois group $G_{\\mathbb{Q}}$ is deeply embedded in the geometric fundamental groups of hyperbolic curves. Mochizuki’s work evolves this by moving from \"Bi-anabelian\" geometry (comparing two objects) to **Mono-anabelian geometry**.\r\n*   **Mono-anabelian Geometry:** The ability to run a \"software algorithm\" on a topological group (the input) to reconstruct the ring structure of the underlying field (the output), without reference to a second comparison object.\r\n\r\n## II. The Machinery: Arithmetic Deformation\r\n\r\nThe central goal of IUT, as applied to the ABC conjecture (and Szpiro conjecture), is to bound the \"size\" of deformation of theta-data.\r\n\r\n### 1. The Theta-Link (The Heart of the Theory)\r\nTraditional scheme theory forbids us from separating addition and multiplication. IUT circumvents this by working in two distinct \"theaters\" (universes) and linking them via a map that respects multiplication but distorts addition.\r\n\r\nThis is the **Theta-link**. It is an *arithmetic deformation*.\r\n\r\n> **Original Text (p. 417):**\r\n> *\"We are now led to the study of a monoid-theoretic map which forms part of a so-called theta-link... viewed as the assignment:*\r\n> $$ q \\mapsto \\{ \\underline{\\underline{\\Theta}}(\\sqrt{-q^m}) = q^{m^2} \\}_{1 \\le m \\le (l-1)/2} $$\r\n> *This map is not scheme-theoretic. Its application may be viewed as a **deconstruction of the ring structure**.\"*\r\n\r\n**Concept Explanation:**\r\nImagine two copies of a local field. You cannot map one to the other preserving both $+$ and $\\times$ if you want to perform this specific deformation ($q \\to q^{m^2}$).\r\n*   We strip the ring down to its multiplicative monoid.\r\n*   We map the units via the identity.\r\n*   We map the value group element (the \"parameter\" $q$) to a specific value of the non-archimedean Theta function.\r\n*   **The Cost:** By doing this, we lose the additive structure. We must then *reconstruct* it using the log-link and Galois rigidity.\r\n\r\n### 2. The Log-Link and Log-Shell\r\nTo regain control over the additive structure after the theta-link disrupts it, Mochizuki employs the non-archimedean logarithm.\r\n\r\n*   **The Log-Link:** A map relating the multiplicative units to the additive structure via $\\log: \\mathcal{O}_L^\\times \\to L$.\r\n*   **The Log-Shell:** A \"container\" for the indeterminacies. Since we cannot match elements perfectly between deformed universes, we map them into a bounded region—the log-shell.\r\n> **Original Text (p. 427):**\r\n> *\"A log-shell is a very useful common structure for the log-links in one vertical line... By definition it is the compact subgroup $(p^*)^{-1} \\log(\\mathcal{O}_L^\\times)$.\"*\r\n\r\n### 3. Multiradiality\r\nThis is perhaps the most crucial philosophical innovation. Fesenko describes the **Wheel and Spokes** analogy.\r\n*   **The Hub:** The core arithmetic object (e.g., the field).\r\n*   **The Spokes:** The reconstruction algorithms.\r\n*   **Multiradiality:** An algorithm is multiradial if it is \"compatible with simultaneous execution at multiple spokes.\" It means the description of the object is robust enough to make sense from the perspective of different, mutually alien universes (theaters).\r\n\r\n## III. The Two Symmetries\r\n\r\nFesenko highlights that the theory relies on the interplay between two distinct types of symmetries acting on the labels of the structures (associated with $\\mathbb{Z}/l\\mathbb{Z}$).\r\n\r\n1.  **$\\mathbb{F}_l^{\\rtimes \\pm}$-symmetry (Geometric/Additive):**\r\n    *   Related to the geometric fundamental group.\r\n    *   Acts additively ($z \\mapsto \\pm z + a$).\r\n    *   Used for **conjugate synchronization** (aligning the \"basepoints\" of Galois groups).\r\n\r\n2.  **$\\mathbb{F}_l^*$-symmetry (Arithmetic/Multiplicative):**\r\n    *   Related to the global arithmetic fundamental group and number fields.\r\n    *   Multiplicative nature.\r\n    *   Used to separate the label $0$ from non-zero labels.\r\n\r\nThe tension between these two symmetries mirrors the tension between the geometric and arithmetic dimensions of the problem.\r\n\r\n## IV. The Main Theorem and Indeterminacies\r\n\r\nThe climax of the theory is an inequality bounding the volume of the deformation. The \"fuzziness\" introduced by tearing apart the ring structure is quantified by three **Indeterminacies**:\r\n\r\n1.  **(Ind1):** Permutation symmetries of the log-theta-lattice.\r\n2.  **(Ind2):** Horizontal theta-link indeterminacy (action on the log-shell).\r\n3.  **(Ind3):** Upper semi-compatibility of Kummer isomorphisms.\r\n\r\nThe main theorem asserts that even with these indeterminacies, the volume is bounded.\r\n\r\n> **Original Text (p. 429):**\r\n> *\"The main theorem... is a bound on log-volumes of the form:*\r\n> $$ -\\deg q_E \\le -\\deg \\Theta_E $$\r\n> *subject to the condition that the term on the RHS... is not equal to $+\\infty$.\"*\r\n\r\nFesenko shows that calculating the RHS (the deformation size) essentially leads to the Szpiro/ABC inequality:\r\n$$ \\frac{1}{6} \\deg q_E \\le (1 + \\epsilon)(\\deg \\text{cond}_E + \\deg \\delta_{F/\\mathbb{Q}}) + C $$\r\n\r\n## V. Reflections: A Paradigm Shift?\r\n\r\nReading Fesenko through the lens of Dr. Peng’s commentary, one realizes that IUT is not merely a method to solve a conjecture; it is a proposal for a new \"Meta-Structure\" of mathematics.\r\n\r\n*   **Deconstruction/Reconstruction:** Standard math works *inside* a fixed universe where $1+1=2$ is absolute. IUT steps *outside*, treats the ring structure as a variable, deforms it, and measures the distortion.\r\n*   **The \"Floating\" Addition:** As Dr. Peng noted, the theory formalizes the intuition that while multiplication is rigid (Galois-theoretic), addition is a \"floating\" structure that requires stabilization via the Log-theta-lattice.\r\n*   **Inter-universal:** The term is literal. We are moving between universes where ring isomorphisms do not exist, using topological groups as the only common language.\r\n\r\n**Conclusion:**\r\nRegardless of the ultimate consensus on the proofs, the intellectual architecture described in Fesenko's notes—specifically the concept of **Arithmetic Deformation**—offers a staggering view of how deep the rabbit hole goes. As Fesenko notes, studying this requires \"at least 250-500 hours\" and a willingness to learn a new language. But as my mentor experienced, stripped of the \"war\" narratives, what remains is a fascinating attempt to unify the combinatorial dimensions of a ring with the geometric dimensions of a curve."
  },
  "leinster-email": {
    "title": "Correspondence with Professor Tom Leinster: My Translation of \"Rethinking Set Theory\" and a Request for Guidance",
    "date": "2022-12-30",
    "content": "**Overview**\r\n\r\nIn late December 2022, driven by my passion for mathematics, particularly category theory and homotopy type theory, I reached out to Professor Tom Leinster, a mathematician I deeply admire. As a 15-year-old high school student, I proudly shared my Chinese translation of his accessible article, \"Rethinking Set Theory,\" which I had made available online. I sought his feedback on the translation and, more importantly, his guidance on structuring my advanced mathematical studies, having already delved into undergraduate topics like algebraic topology and abstract algebra. Professor Leinster replied in January 2023, expressing his admiration for my effort (though he noted he couldn't verify the Chinese) and recommending two insightful, unconventional books for further study: Saunders Mac Lane's \"Mathematics: Form and Function\" and Michio Kuga's \"Galois's Dream.\" This exchange was an inspiring and unforgettable milestone in my early mathematical journey. From then on, I continued corresponding with Professor Leinster under my real identity, though those emails are private and will not be shared here.\r\n\r\n***\r\n\r\n### Original Correspondence\r\n\r\n#### Yuanjue Chou to Tom Leinster\r\n\r\n> **Admiration for your work and request for guidance**\r\n>\r\n> **Yuanjue Chou** <vsixadafahin5677@gmail.com>\r\n>\r\n> Fri, Dec 30, 2022, 6:30 PM\r\n>\r\n> to Tom.Leinster\r\n>\r\n> Dear Professor Leinster,\r\n>\r\n> I am writing to express my utmost admiration and respect for your contributions to the field of mathematics. As a 15-year-old high school student from China with a deep passion for math, I hope to one day follow in your footsteps and engage in research, particularly in the areas of category theory and homotopy type theory.\r\n>\r\n> I am thrilled to share that I have translated one of your articles, \"Rethinking Set Theory,\" and made it available at the following website: https://chaoli.club/index.php/7082. I would be truly honored if you would consider reviewing my translation and providing feedback.\r\n>\r\n> I am also writing to humbly request your guidance on how to best plan my studies to achieve my aspirations. While I have had the opportunity to study some undergraduate material in abstract algebra, set topology, algebraic topology, and a little bit of category theory, I feel as though I have only just begun to scratch the surface. I would be deeply grateful for any recommendations you have on how I can continue to learn and grow as a mathematician.\r\n>\r\n> Additionally, I would be grateful for any recommendations you have for explanatory articles similar to \"Rethinking Set Theory.\"\r\n>\r\n> Finally, I wanted to express my warmest wishes for the new year!\r\n>\r\n> Sincerely,\r\n> Yuanjue Chou\r\n\r\n#### Tom Leinster to Yuanjue Chou\r\n\r\n> **Tom Leinster** <Tom.Leinster@ed.ac.uk>\r\n>\r\n> Wed, Jan 18, 2023, 5:17 AM\r\n>\r\n> to me, Tom\r\n>\r\n> Dear Yuanjue,\r\n>\r\n> Thank you for your very kind email, and apologies for the delayed reply; I hope you got an automatic email saying I was away.\r\n>\r\n> It's very nice that you've translated \"Rethinking set theory\". I'm impressed! Unfortunately I don't read Chinese, so I'm not able to give any feedback, but congratulations in any case - it's a great achievement.\r\n>\r\n> I've been thinking about the best recommendations to make for materials to study with. I imagine you have already come across a few standard undergraduate textbooks, and there are thousands of those. So let me recommend two books that are not quite normal textbooks.\r\n>\r\n> The first is a book by Saunders Mac Lane (one of the creators of category theory) called \"Mathematics: Form and Function\". Officially, this is an explanation of Mac Lane's philosophy of mathematics. However, what I like most about it is that it's filled with wonderful explanations of many different parts of mathematics. I read it when I was an undergraduate and found it very exciting, as it opened up new worlds to me and gave me tantalizing hints of how they were connected.\r\n>\r\n> The second is \"Galois's Dream\" by Michio Kuga. This one I haven't actually read, but I've heard many good things about it. The subject is group theory and differential equations, but what's joyful about it is the unusual style it's written in. It's based on a lecture course that Kuga gave to first-year undergraduates, even though Galois theory is usually a rather more advanced course.\r\n>\r\n> Those are just two random ideas! You may or may not like them. In any case, I wish you the best of luck in your studies.\r\n>\r\n> Best wishes,\r\n> Tom\r\n>\r\n>\r\n> On 30/12/2022 10:30, Yuanjue Chou wrote:\r\n> This email was sent to you by someone outside the University.\r\n> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.\r\n>\r\n> --\r\n> Professor Tom Leinster\r\n> School of Mathematics, University of Edinburgh\r\n> https://www.maths.ed.ac.uk/~tl\r\n> The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th’ ann an Oilthigh Dhùn Èideann, clàraichte an Alba, àireamh clàraidh SC005336."
  },
  "linear-logic": {
    "title": "The Geometry of Dialogue and the Logic of Narrative: A Taste of Linear Logic",
    "date": "2022-10-05",
    "content": "## Overview\r\n\r\nThis fragment serves as a synthesis of my recent immersion into the world of **Linear Logic** and its profound implications for systems beyond mere mathematical tautology. Following the intellectual breadcrumbs left by Dr. Keyao Peng last year, I have moved away from the static view of logic as a classification of truth and towards a dynamic view of logic as *interaction*, *resource*, and *game*.\r\n\r\nWhat began as an inquiry into game design mechanics—specifically the tension between modular pipelines and emergent storytelling—has evolved into a philosophical re-evaluation of how meaning is constructed. As the following notes and visual analyses demonstrate, the bridge between a child’s fable, a philosophical debate, and high-dimensional topology is built upon the rigorous negation-duality of Linear Logic.\r\n\r\n---\r\n\r\n## Part I: \"The Signifier Chain Without the Signifier\"\r\n**Reflections on Dr. Peng’s First Theme**\r\n\r\nDr. Peng’s cryptic observation regarding the \"signifier chain without the signifier\" forces us to confront the structuralist heritage of modern logic. In the context of Jean-Yves Girard’s *Ludics* and the diagrams we have analyzed, this statement acts as a methodological razor.\r\n\r\nIn classical logic (and traditional semantics), we are often obsessed with the \"Signified\"—the semantic content or the \"truth value\" residing behind the symbol. We ask, \"Is $A$ true?\" assuming $A$ points to a platonic reality. However, the move toward Linear Logic and Ludics represents a radical shift. We are no longer observing the *object* (the signifier) but the *location* and the *link* (the chain).\r\n\r\nAs seen in the argumentation analysis (Image 1), the specific content of the debate (whether the child has bad habits) is secondary to the *form* of the interaction. The \"signifier\" is emptied of its ontic weight; what remains is its \"valency\"—its ability to connect, oppose, and transform. The \"chain\" is the sequence of focalized actions in a proof. In Ludics, formulas are abandoned in favor of \"Loci\" (addresses). We do not prove a formula; we interact with a design at a specific address.\r\n\r\nThis echoes Lacan’s notion of the sliding chain of signifiers, but here it is rigorous mathematics: the meaning of a logical operator is not defined by a truth table, but by its geometric interaction with its dual. The \"chain\" is the trajectory of the cut-elimination procedure, a pure movement of syntax that generates meaning through friction, without ever needing a pre-existing \"signified\" to ground it.\r\n\r\n---\r\n\r\n## Part II: Linear Logic as Game, Narrative, and Interaction\r\n**Reflections on Dr. Peng’s Second Theme**\r\n\r\n> *\"I thought there wasn't much to Linear Logic, but it opened a new world... Logic has ascended to the level of interaction, or rather, the Game.\"* — Dr. Keyao Peng\r\n\r\nDr. Peng’s second commentary serves as the backbone of my current research. The realization that logic is not a static description of the world, but a set of rules for *changing* it, bridges the gap between my interest in game design and formal systems.\r\n\r\n### 2.1 The Narrative as a Resource Pipeline (The Three Little Pigs)\r\n\r\nOne of the most striking applications of this logic is the ability to formalize narrative causality not as a sequence of distinct events, but as a chemical reaction of resources.\r\n\r\n![FIGURE1](/fragments/linear-logic/three-pigs.jpeg)\r\n\r\n*Figure 1: The Sequent Calculus of Narrative Construction*\r\n\r\n\r\n**Analysis of Figure 1:**\r\nThe image above demonstrates a proof-search interpretation of the \"Three Little Pigs\" folktale. Here, the story is encoded in **Linear Logic**, specifically using the multiplicative conjunction ($\\otimes$) and linear implication ($\\multimap$).\r\n\r\n*   **The Logic of Conservation:** In classical logic, if I have a premise $A$, I can use it infinite times ($A \\to A \\land A$). In the story of the Three Little Pigs, materials are finite. A pig cannot simultaneously build a straw house and remain an idle pig. Linear Logic captures this perfectly.\r\n    *   Rule $r_1$: $\\text{pig} \\otimes \\text{straw} \\multimap \\text{straw\\_house}$.\r\n    *   This implies that to create a `straw_house`, the resources `pig` and `straw` must be *consumed*. They are no longer available in the context $\\Delta$ after the transition.\r\n\r\n*   **The Proof Tree as Storyboard:** The derivation tree at the bottom of Figure 1 ($D_1$ through $D_5$) is not just a mathematical proof of validity; it is the *timeline* of the story.\r\n    *   The \"Initial Configuration\" ($\\Delta_0$) is the set of actors and props: $\\{\\text{pig, pig, pig, straw, bricks, sticks, wolf}\\}$.\r\n    *   The \"Sequent\" to be proven is $\\Delta_0 \\vdash \\text{brick\\_house}$.\r\n    *   The proof search represents the plot. The wolf interacts (via \"cuts\" or logical inferences) with the straw house ($r_4: \\text{wolf} \\otimes \\text{straw\\_house} \\multimap \\text{wolf}$), effectively destroying the house but preserving the wolf.\r\n    *   The final state (the bottom of the tree) is the canonical ending where only the brick house stands.\r\n\r\nThis confirms Dr. Peng's insight: *Linear logic's resource semantics is the language of material processing pipelines.* Whether it is an industrial assembly line or the plot points of a fable, the logic remains valid: $A \\otimes B \\multimap C$ is the fundamental unit of change.\r\n\r\n### 2.2 Dialectics: The Art of Winning Controversies (Schopenhauer & Ludics)\r\n\r\nDr. Peng noted that logic has moved \"from absolute unary to subject-object duality, from proof to dialectic.\" This is explicitly visualized in the analysis of Schopenhauer’s *stratagems* through the lens of **Ludics**.\r\n\r\n![FIGURE2-1](/fragments/linear-logic/retorsio.jpeg)\r\n\r\n![FIGURE2-2](/fragments/linear-logic/retorsio2.jpeg)\r\n\r\n*Figure 2: Formalizing 'Retorsio Argumenti' in Dialogue Acts*\r\n\r\n**Analysis of Figure 2:**\r\nThis fragment references Schopenhauer’s *The Art of Being Right* (*L'Art d'avoir toujours raison*), interpreting dialectics as \"the art of winning controversies.\"\r\n\r\n*   **Logic as Warfare:** In standard logic, a proof is a static object. In Ludics (a development of Linear Logic), a proof is a *strategy* against a counter-proof. The \"Proponent\" ($P$) tries to establish a thesis, while the \"Opponent\" ($O$) tries to find a flaw.\r\n*   **The Mechanism of Retorsio:** The text analyzes a specific rhetorical move: *retorsio argumenti* (turning the tables).\r\n    *   *Opponent ($O$):* \"He is a child ($P_1$), so you must be lenient ($P_2$).\"\r\n    *   *Proponent ($P$):* \"Because he is a child ($P_1$), I must correct him, or he will keep bad habits (Not-$P_2$).\"\r\n*   **The Formalization:** The text maps this natural language exchange into \"Dialogue Acts\" with specific polarities ($+, -$):\r\n    *   The concession \"Just because he is a child\" is a positive action accepting the premise.\r\n    *   The counter-argument is the *dual* action.\r\n    *   The notation $(+, \\xi, \\{1,2\\})$ represents the ramification of the argument. The debate is a tree of possibilities; winning the argument corresponds to finding a \"winning strategy\" in the game-theoretical sense—a path through the tree that handles every possible move by the opponent.\r\n\r\nThis validates the view of logic as **interaction**. Truth is not a property of the sentence \"The child must be corrected\"; truth is the existence of a winning strategy for $P$ in the debate game defined by these rules.\r\n\r\n### 2.3 The Geometry of Interaction (Mellies' Topologies)\r\n\r\nFinally, we arrive at the most abstract representation: the topological view of logical interaction.\r\n\r\n![FIGURE3](/fragments/linear-logic/morphism.jpeg)\r\n\r\nFigure 3: String Diagrams and the Flow of Logic\r\n\r\n**Analysis of Figure 3:**\r\nThis diagram, likely derived from the work of Paul-André Melliès (a student of Girard), visualizes a \"morphism\" in a logical category (likely a $*$-autonomous category or a dialogue category).\r\n\r\n*   **Feynman Diagrams for Logic:** Dr. Peng joked that \"human interaction becomes like Feynman diagrams.\" This is literally true in *Game Semantics*. The ribbons represent the trajectory of information (or control) flow between the Player and the Opponent.\r\n*   **The Structure:**\r\n    *   The diagram depicts a transformation $L a \\longrightarrow L(*m) \\otimes L((Rm) \\otimes a)$.\r\n    *   The colors (Orange/Red vs. Blue) likely represent **Polarity**: Positive (Player/Proponent) vs. Negative (Opponent).\r\n    *   The connections (the \"wires\") show how input types are routed to output types.\r\n    *   The \"clasps\" or nodes where ribbons split or join represent logical connectives (Tensor $\\otimes$ or Par $\\wp$).\r\n*   **Topological Invariants:** The power of this representation is that logical equivalence becomes topological deformation. If you can stretch or slide one ribbon diagram into another without cutting it, the two logical proofs are effectively \"the same\" (they have the same normal form). This is the **Geometry of Interaction**: logic is not about symbols on a line, but about the topological linkage of processes in space.\r\n\r\n---\r\n\r\n## Part III: Comprehensive Learning Notes\r\n**Subject: Linear Logic, Game Semantics, and the Reconstruction of Meaning**\r\n\r\nBased on the synthesis of Dr. Peng's themes and the visual artifacts above, I have compiled the following detailed study notes. These notes aim to deconstruct the \"new world\" of logic that Dr. Peng referred to—moving from simple categorization to complex interaction.\r\n\r\n### 1. The Foundation: From Truth to Resource\r\n**Linear Logic (LL)**, introduced by Jean-Yves Girard in 1987, is not merely a \"logic without Excluded Middle\" (like Intuitionism); it is a logic of **action**.\r\n\r\n*   **The Decomposition of Implication:**\r\n    In classical logic, $A \\to B$ is coarse. It combines the ability to use $A$ (consumption) with the ability to repeat $A$ (structural rule of Contraction) and ignore $A$ (structural rule of Weakening).\r\n    LL decomposes this into:\r\n    $$ A \\to B \\equiv (!A) \\multimap B $$\r\n    Where \"!\" (Why Not / Bang) is the exponential modality that allows indefinite reuse. The core arrow, $\\multimap$ (Lollipop), is strictly resource-sensitive.\r\n\r\n*   **The Two Conjunctions (Choice vs. Co-existence):**\r\n    LL resolves the ambiguity of \"And\":\r\n    1.  **Multiplicative \"And\" ($\\otimes$ - Tensor):** \"I have $A$ and I have $B$ simultaneously.\" ($10 implies I can buy a Coke AND a Burger).\r\n        *   *Narrative Application:* The `pig` and the `straw` in Figure 1 are tensored ($\\text{pig} \\otimes \\text{straw}$). They are both present and consumed together.\r\n    2.  **Additive \"And\" ($\\&$ - With):** \"I have a choice between $A$ and $B$.\" ($10 implies I can buy a Coke OR a Burger, but not both).\r\n        *   *Game Application:* The Opponent offers a choice of attack. I must be ready to defend against A *and* defend against B, but only one will actually happen in a single play-through.\r\n\r\n### 2. The Interaction: Logic as a Game\r\nDr. Peng mentioned that logic has become a \"2-player game.\" This is formalized in **Game Semantics** (Hyland, Ong, Abramsky, etc.).\r\n\r\n*   **Proponent vs. Opponent:**\r\n    Every logical formula is viewed as a game.\r\n    *   **Propositions** are games.\r\n    *   **Proofs** are strategies for the Proponent.\r\n    *   **Validity** means the Proponent has a winning strategy (can always win regardless of Opponent's moves).\r\n\r\n*   **The Dialectical Turn:**\r\n    As seen in the Schopenhauer example (Figure 2), this models real-world argumentation. A logical fallacy is simply a bad strategy that allows the Opponent to trap you in a contradiction.\r\n    *   *The \"Cut\" Rule:* In Game Semantics, the \"Cut\" (combining two proofs) corresponds to letting two strategies play against each other. The \"Cut Elimination\" process is the actual execution of the game—the dialogue that ensues until a winner is determined.\r\n\r\n### 3. Ludics: The Location of Meaning\r\nDr. Peng’s reference to the \"Signifier chain\" leads us to **Ludics**, Girard's attempt to rebuild logic without the \"semantic prejudice.\"\r\n\r\n*   **Loci (Locations) instead of Formulas:**\r\n    In Ludics, we don't say \"Proposition A implies Proposition B.\" We say \"Design at address $\\xi$ interacts with Design at address $\\sigma$.\"\r\n    This is radical because it removes the \"meaning\" of the proposition. It doesn't matter *what* the pig or the straw is. What matters is their *address* in the memory and the *rules* governing their interaction.\r\n\r\n*   **Interaction as the Primitive:**\r\n    Usually, we define syntax (grammar) and semantics (meaning) separately. In Ludics, **semantics is the interaction of syntax with itself**.\r\n    *   Two designs are \"orthogonal\" (roughly, compatible) if their interaction terminates properly.\r\n    *   The \"meaning\" or \"type\" of a design is simply the set of all designs that interact well with it. This is the **Behavioral Semantics**.\r\n\r\n### 4. Transcendental Syntax & The Closure of Negation\r\nDr. Peng’s final point regarding Girard’s *Transcendental Syntax* is the most profound.\r\n\r\n*   **The Death of the \"Real\":**\r\n    Traditional logic assumes a \"Real world\" outside of logic that we are trying to describe. Girard argues that logic should be self-contained. The \"Real\" is not an external object, but the *result* of the interaction between the Subject (Proponent) and the Object (Opponent).\r\n\r\n*   **Negation as Definition:**\r\n    \"In this sense, the proposition is defined by its negation.\"\r\n    This is a Cybernetic or Hegel-influenced view. I do not know what $A$ is by looking at $A$. I know what $A$ is by looking at *everything that contradicts $A$*.\r\n    *   $A = (A^\\perp)^\\perp$.\r\n    *   The \"Closure of Negation\": The system is complete because every entity is defined solely by how it interacts with its environment (its dual).\r\n\r\n*   **Negation of Negation:**\r\n    Dr. Peng notes, \"Negation of negation completes the argument closure.\" In the Schopenhauer example, the Proponent wins not by stating a fact, but by negating the Opponent's negation.\r\n    *   Opponent: \"You must make allowance.\" (Thesis)\r\n    *   Proponent: \"I must correct him.\" (Antithesis / Negation)\r\n    *   Synthesis: The strategy that successfully defends the correction against the allowance plea.\r\n\r\n### 5. Application: From Narrative to Social Relations\r\nDr. Peng’s insight extends these logical structures to **Production Relations** and **Narrative Generation**.\r\n\r\n*   **Narrative Generation:**\r\n    Using the Linear Logic structure (Figure 1), we can build an \"Automatic Storyteller.\"\r\n    *   *State:* A multiset of resources ($\\Delta$).\r\n    *   *Events:* Linear implications ($\\multimap$) that consume resources and produce new ones.\r\n    *   *Plot:* The proof tree.\r\n    *   *Conflict:* The competition for limited resources (e.g., the Wolf wants to consume the Pig, the Pig wants to build a House). If resources are limited, these branches are mutually exclusive (Additive conjunction), requiring a choice (branching narrative).\r\n\r\n*   **Social/Marxist Analysis:**\r\n    The \"Feynman Diagram\" view of human interaction (Figure 3) suggests a new sociology. Interactions are not just people talking; they are exchanges of logical types/resources.\r\n    *   Alienation could be modeled as a failure of orthogonality—an interaction that diverges or fails to terminate.\r\n    *   Production is the tensor product ($\\otimes$).\r\n    *   Consumption is the linear implication ($\\multimap$).\r\n    We can model an economy not just numerically, but *logically*, proving whether a certain distribution of resources (premises) can actually lead to a desired societal outcome (conclusion) without \"magic\" (Weakening/Contraction).\r\n\r\n---\r\n\r\n### Conclusion: The New Logic\r\n\r\nMy time studying these fragments has shifted my perspective irrevocably. Logic is no longer the dry study of tautologies ($A=A$). It is the vibrant, geometric, and game-theoretical study of **information flow**.\r\n\r\nWhether we are:\r\n1.  Analyzing a debate strategy using **Ludics** (Figure 2),\r\n2.  Visualizing the topology of a conversation using **String Diagrams** (Figure 3),\r\n3.  Or generating a folktale using **Linear Sequent Calculus** (Figure 1),\r\n\r\nThe underlying principle remains the same: **Structure is defined by Interaction.** The \"Signifier\" may be empty, but the \"Chain\"—the web of dualities, negations, and connections—is where meaning, story, and reality are generated.\r\n\r\nAs Dr. Peng suggested, the world is a game. But it is not a game of chance; it is a game of Logic. And we are just beginning to learn the rules."
  },
  "maniac-meme": {
    "title": "The Proper Way to Speak Like a Mathematical Maniac: A Self-created Meme",
    "date": "2025-07-14",
    "content": "## Overview\r\n\r\nThis document serves as a **Self-Correcting Lexicon of Mathematical Cryptography**, translating sixteen common, everyday conversational phrases into their most technically dense and mathematically absurd equivalents. This meme, originating from a discussion among academic peers, highlights the humorous tendency of mathematicians to formalize the mundane. Each entry includes the translation, the precise mathematical expression, a detailed explanation of the concept, and the author’s subsequent self-critique and correction process, where applicable.\r\n\r\n***\r\n\r\n## The Lexicon Table: Conversational to Formal Translation\r\n\r\n| Conversational Phrase | English Translation | Formal Mathematical/Computational Equivalent |\r\n| :--- | :--- | :--- |\r\n| 你好笨 | You are so stupid | $O(n!)$ solution to an **NP-hard** problem |\r\n| 不想去 | Don't want to go | $\\text{Let } X \\text{ be a scheme. Then } H^0(X, \\mathcal{O}_X) = \\emptyset$ |\r\n| 不行 | No way/Impossible | $\\text{ZFC} \\not\\vdash \\text{CH}$ |\r\n| 随便 | Whatever/Up to you | $\\text{AC}$ |\r\n| 你去忙吧 | You go on with your work | $\\Delta t \\to \\infty, \\text{ where } \\Delta t \\text{ is interaction time}$ |\r\n| 我不会 | I can't do it | $\\text{Problem} \\in \\mathbf{RE} \\setminus \\mathbf{R}$ |\r\n| 唯一真神 | The only true God | $\\sum = \\frac{ }{2}$ |\r\n| 你好烦 | You are annoying | $\\dim_{\\mathbb{C}} H^0(X, K_X) = \\infty$ |\r\n| 要你管 | None of your business/Mind your own business | $\\text{Aut}(G) \\not\\cong \\text{Inn}(G)$ |\r\n| 滚 | Get lost/Go away | $\\text{Proof of } \\text{ind}(D) = \\int_M \\hat{A}(M) \\text{ is acceptable}$ |\r\n| 我错了 | I was wrong | $\\blacksquare \\text{ contradiction}$ |\r\n| 你错了 | You are wrong | $0.999999\\dots \\neq 1$ |\r\n| 吃过了 | I've eaten | $\\exists x \\in \\text{Spec}\\mathcal{O}_K, \\kappa(x) \\neq \\emptyset$ |\r\n| 帮我个忙 | Help me out/Do me a favor | $\\Gamma \\vdash ? : \\text{Req} \\to \\text{Action}$ |\r\n| 你陪我 | Keep me company | $\\text{Seeking } F \\dashv G \\text{ in } \\mathcal{C}$ |\r\n| 气死我了 | I'm furious/It drives me mad | $\\text{Gal}(E/\\mathbb{Q}) \\text{ is not solvable}$ |\r\n\r\n***\r\n\r\n## Detailed Explanations and Corrections\r\n\r\nThe meme's effectiveness lies in its technical density, which often draws from multiple advanced mathematical fields.\r\n\r\n### 1. You are so stupid $\\rightarrow O(n!)$ solution to an NP-hard problem\r\n\r\n*   **Concept:** This refers to the computational complexity of algorithms. An **NP-hard problem** is at least as hard as the hardest problems in NP.\r\n*   **Mathematical Humor:** A solution with **$O(n!)$ (Factorial time complexity)** is utterly inefficient. The insult is that the proposed \"solution\" is computationally stupid.\r\n\r\n### 2. Don't want to go $\\rightarrow \\text{Let } X \\text{ be a scheme. Then } H^0(X, \\mathcal{O}_X) = \\emptyset$\r\n\r\n*   **Concept:** **Algebraic Geometry**. $H^0(X, \\mathcal{O}_X)$ is the space of global sections of the structure sheaf, representing the \"presence\" or \"structure\" over the entire space $X$. Setting it to $\\emptyset$ means no structure exists.\r\n*   **Author's Correction:** The expression $H^0(X, \\mathcal{O}_X) = \\emptyset$ is **formally incorrect**. The space of global sections of the structure sheaf *must* contain at least the unit element (the scalar $1$), meaning the set is never empty. This was an honest error, not an intended pun.\r\n\r\n### 3. No way/Impossible $\\rightarrow \\text{ZFC} \\not\\vdash \\text{CH}$\r\n\r\n*   **Concept:** **Set Theory**. This states that the **Continuum Hypothesis (CH)** is **undecidable** in the standard Zermelo-Fraenkel set theory with the Axiom of Choice ($\\text{ZFC}$), meaning it can neither be proven nor disproven.\r\n*   **Mathematical Humor:** The everyday \"impossible\" is translated to an axiomatically proven **non-determinability**.\r\n\r\n### 4. Whatever/Up to you $\\rightarrow \\text{AC}$\r\n\r\n*   **Concept:** **Axiom of Choice (AC)**. AC asserts the *existence* of a choice function but offers no constructive method for performing the selection.\r\n*   **Mathematical Humor:** The non-constructive nature of the axiom perfectly captures the sentiment of saying \"I guarantee a choice can be made, but I won't tell you how.\"\r\n\r\n### 5. You go on with your work $\\rightarrow \\Delta t \\to \\infty, \\text{ where } \\Delta t \\text{ is interaction time}$\r\n\r\n*   **Concept:** **Limit Theory/Physics**. $\\Delta t \\to \\infty$ means the interaction or waiting time tends toward infinity.\r\n*   **Mathematical Humor:** The phrase \"Don't wait for me\" is formalized as an infinitely long waiting period, or the total decoupling of two systems.\r\n\r\n### 6. I can't do it $\\rightarrow \\text{Problem} \\in \\mathbf{RE} \\setminus \\mathbf{R}$\r\n\r\n*   **Concept:** **Computability Theory**. $\\mathbf{R}$ (Decidable) are problems with an algorithm. $\\mathbf{RE}$ (Recursively Enumerable) are problems where a \"yes\" answer can be verified. $\\mathbf{RE} \\setminus \\mathbf{R}$ is the set of **undecidable problems**.\r\n*   **Mathematical Humor:** \"I can't do it\" is an assertion that the task is fundamentally and provably undecidable by any general algorithm.\r\n\r\n### 7. The only true God $\\rightarrow \\sum = \\frac{ }{2}$\r\n\r\n*   **Concept:** **Notational Fallacy/Academic Satire**. This specific, visually ambiguous notation is a direct satire of the **Jiang Ping incident**, where a purported mathematical genius made an absurd notational error—the $\\sum$ symbol was visually confused with a fraction line and the number 2, suggesting a grotesque error in writing an equation or a simple division/sum.\r\n*   **Mathematical Humor:** Instead of referencing established but paradoxical math (like divergent series summation), this entry satirizes the phenomenon of **pseudo-mathematical genius** by enshrining a clear notational absurdity as a \"divine truth.\"\r\n\r\n### 8. You are annoying $\\rightarrow \\dim_{\\mathbb{C}} H^0(X, K_X) = \\infty$\r\n\r\n*   **Concept:** **Algebraic Geometry**. This describes an infinitely-dimensional space of sections of the Canonical Bundle.\r\n*   **Mathematical Humor:** The structure is literally **infinitely complex**, making its study frustratingly \"annoying.\"\r\n\r\n### 9. None of your business/Mind your own business $\\rightarrow \\text{Aut}(G) \\not\\cong \\text{Inn}(G)$\r\n\r\n*   **Concept:** **Group Theory**. $\\text{Aut}(G)$ (all automorphisms) is not isomorphic to $\\text{Inn}(G)$ (automorphisms by conjugation, internal operations). The difference means there exist **Outer Automorphisms**.\r\n*   **Mathematical Humor:** The existence of an **Outer Automorphism** is a formal way of saying there are structural changes that are \"outside the group's control\" and, therefore, \"none of your business.\"\r\n\r\n### 10. Get lost/Go away $\\rightarrow \\text{Proof of } \\text{ind}(D) = \\int_M \\hat{A}(M) \\text{ is acceptable}$\r\n\r\n*   **Concept:** **Differential Geometry/Topology** (The Atiyah–Singer Index Theorem). This is a reference to a mathematical inside joke concerning a known historical controversy or skepticism surrounding a late proof or variation related to the Index Theorem.\r\n*   **Mathematical Humor:** The word \"acceptable\" is used sarcastically to mean \"rejected\" or \"met with enormous resistance,\" thus serving as a dramatic technical equivalent for \"Go away.\"\r\n\r\n### 11. I was wrong $\\rightarrow \\blacksquare \\text{ contradiction}$\r\n\r\n*   **Concept:** **Logic/Proof Theory**. The $\\blacksquare$ symbol (or $\\rightarrow\\leftarrow$) is the formal termination of a **Proof by Contradiction**, which demonstrates the original hypothesis was false.\r\n*   **Mathematical Humor:** An admission of error is the ultimate, non-negotiable conclusion derived from formal logical deduction.\r\n\r\n### 12. You are wrong $\\rightarrow 0.999999\\dots \\neq 1$\r\n\r\n*   **Concept:** **Real Analysis/Non-Standard Analysis**. In standard analysis, $0.999\\dots$ is rigorously equal to $1$.\r\n*   **Author's Correction:** The **primary intent** was to capture the **pedantic stubbornness of a \"math crank\"** insisting on a position that is false in standard contexts (like the never-ending internet debate over $0.\\bar{9} = 1$). A **secondary interpretation** is that the statement holds true only within the framework of **Non-Standard Analysis**, which allows for non-zero infinitesimals, thus enabling the speaker to \"correct\" the other person from an obscure, high-level context.\r\n\r\n### 13. I've eaten $\\rightarrow \\exists x \\in \\text{Spec}\\mathcal{O}_K, \\kappa(x) \\neq \\emptyset$\r\n\r\n*   **Concept:** **Algebraic Number Theory/Scheme Theory**. The condition asserts the existence of a prime ideal $x$ in the ring of integers $\\mathcal{O}_K$ such that its **residue field $\\kappa(x)$ is non-empty**.\r\n*   **Mathematical Humor:** This is an overly formal, abstract statement that there is \"residual matter\" (residue field) in the system.\r\n\r\n### 14. Help me out/Do me a favor $\\rightarrow \\Gamma \\vdash ? : \\text{Req} \\to \\text{Action}$\r\n\r\n*   **Concept:** **Type Theory/Programming Language Logic**. A **Typing Judgment** asserting that in a given context $\\Gamma$, one must construct a term (?) of the function type $\\text{Req} \\to \\text{Action}$.\r\n*   **Mathematical Humor:** A simple favor request is formalized as a rigorous need to implement a function that maps the **Request** to a corresponding, type-correct **Action**.\r\n\r\n### 15. Keep me company $\\rightarrow \\text{Seeking } F \\dashv G \\text{ in } \\mathcal{C}$\r\n\r\n*   **Concept:** **Category Theory**. $F \\dashv G$ denotes an **Adjunction**, a powerful duality relationship between two functors ($F$ and $G$) within a category $\\mathcal{C}$.\r\n*   **Author's Correction:** The **Adjunction** is the primary concept. The author noted the final \"in $\\mathcal{C}$\" is formally vague. The structure being sought might be more precisely defined by functors between two specific categories (e.g., $F: \\mathcal{C} \\to \\mathcal{D}$) or, if $F$ and $G$ act on the same category, as $\\text{End}(\\mathcal{C})$. The core meaning—seeking a structured, dual relationship—remains, but the notation's precision was called into question.\r\n*   **Mathematical Humor:** Companionship is defined as finding a profound, structured, and mutually beneficial **duality**.\r\n\r\n### 16. I'm furious/It drives me mad $\\rightarrow \\text{Gal}(E/\\mathbb{Q}) \\text{ is not solvable}$\r\n\r\n*   **Concept:** **Galois Theory/Abstract Algebra**. The expression means the Galois group of a polynomial equation is **not solvable**, which by the Abel–Ruffini Theorem, implies the equation has **no solution in terms of radicals**.\r\n*   **Mathematical Humor:** The **non-solvability** of the equation perfectly mirrors the state of being furious/unable to solve an emotional problem. This also serves as a historical reference to the passionate circumstances leading to Évariste Galois's death.\r\n\r\n***\r\n\r\n**Final Note:** The author extends thanks for the corrections, acknowledging the commitment to rigor even in the creation of academic memes."
  },
  "name-game": {
    "title": "The Naming Game — From RC，Runnel, Rangnuo, Jeanot to Rinelle",
    "date": "2025-06-28",
    "content": "## Overview\r\n\r\nThis document explores the multi-layered architecture of my personal identity, tracing a philological journey that bridges my Chinese heritage with Western linguistic traditions. By weaving together the etymology of my primary names—**Runnel (Runcheng)**, the courtesy name **Rangnuo (Jeanot)**, and the studio title **Xiangruo**—with a playful aristocratic alter ego, I demonstrate a philosophy where names serve as both \"tally-bonds between Heaven and Earth\" and vessels for silent action. Through translated classical prefaces and European nomenclature, this overview reveals a self-conception rooted in the virtues of deference, promise, and the perpetual \"renaissance\" of the intellect.\r\n\r\n## I. The Etymology of Identity\r\n\r\nThe genesis of my nomenclature begins with my given Chinese name: **Runcheng** (润程).\r\n\r\nThe character **Run (润)** implies moistening, enriching, or gentle elegance; **Cheng (程)** signifies a journey or a standard. When Anglicizing this, I sought a name that preserved both the phonetic root and the semantic essence. I chose **Runnel**, a word denoting a small stream or brook. It flows naturally from \"Run,\" capturing the water radical implies in the original Chinese, and shares the initials **RC** (Runnel Cheung).\r\n\r\nFrom **Runnel**, a philological chain reaction occurred:\r\n1.  **Phonetic Evolution:** \"Runnel\" bears a striking acoustic resemblance to the Chinese transliteration **Rangnuo** (让诺).\r\n2.  **The Courtesy Name:** Consequently, I adopted \"Rangnuo\" as my *Hao* (courtesy name), styling myself the **\"Layman Rangnuo\"** (让诺居士).\r\n3.  **The French Connection:** Transliterated into French, Rangnuo becomes **Jeanot**. This happy accident fits perfectly, as the diminutive suffix suggests a perennial youthfulness—mirroring my own appearance, which often belies my actual age.\r\n\r\n### The Architecture of the Studio: \"Xiangruo\"\r\n\r\nThe construction of my studio's name, **Xiangruo Zhai** (襄若斋), is a play on logograms. The traditional characters for Rangnuo are **讓諾**.\r\n*   By excising the \"Speech\" radical (言) from **Rang (讓)**, we are left with **Xiang (襄)**.\r\n*   By excising the \"Speech\" radical (言) from **Nuo (諾)**, we are left with **Ruo (若)**.\r\n\r\nThus, **\"Rangnuo\"** (Yielding and Promising) transforms into **\"Xiangruo\"** (Assisting and Complying). This subtraction of \"speech\" symbolizes a shift from spoken virtue to silent action.\r\n\r\n---\r\n\r\n## II. The Philosophical Justification\r\n*Below are the annotated translations of the Classical Chinese texts justifying these names. You can read the original version of Jeanot Collection at [Library: Classics](https://www.runnelzhang.com/library/classics)*\r\n\r\n### Text A: Preface to the Jeanot Collection\r\n*(Original: 《让诺集·让诺集序》)*\r\n\r\n> **Original Text:**\r\n> “夫名者，天地之符契；文者，星斗之经纬。余以己西名“让诺”二字署集…… 故曰：让者，仁之兵戈，智之甲胄。…… 故诺者，非唇齿轻碰之语，实血脉奔涌之誓。…… 吾斋名“襄若”，刈除言旁，非效金人缄口，实慕“天何言哉”之化育。……让非懦弱，乃蓄雷霆于渊默；诺非轻许，实寄泰华于毫末。……”\r\n\r\n**Translation:**\r\n\r\nNames are the tally-bonds between Heaven and Earth; writings are the warp and weft of the constellations. I have signed this collection with my Western name, \"Rangnuo\" (Jeanot), not merely to harmonize Western phonetics with the Six Directions, but to forge a pair of jades to illuminate my inner heart.\r\n\r\n**On \"Rang\" (Deference/Yielding):**\r\nThe virtue of *Rang* is like the spring rain, moistening all things in silence. In antiquity, Emperor Shun cultivated Mount Li and thrice retreated before the aggression of Danzhu; Tai Bo fled to Wu, deferring the throne so completely that he effaced his traces from the ancestral temple. Yet, observing the *I Ching* image of \"Mountain within the Earth\" (Humility), and the *Book of Songs* praising the \"Elegant Gentleman,\" we perceive that to retreat is not cowardice—it is to possess a capacity that can swallow the cosmos. Thus, I say: Deference is the weaponry of Benevolence and the armor of Wisdom.\r\n\r\n**On \"Nuo\" (Promise/Assent):**\r\nThe meaning of *Nuo* is like a gnomon or a standard—resounding and true. A single promise from Ji Bu was valued by the men of Chu above a hundred catties of gold; the fidelity of Fan Shi, traversing a thousand miles to keep an appointment, engraved the pact of \"chicken and millet\" onto the annals of life and death. A Promise is not the light collision of lips and teeth; it is an oath surging through the blood.\r\n\r\n**The Synthesis:**\r\nWhen these two characters are joined, it is like the oscillation of Yin and Yang generating the myriad phenomena. *Rang* is the winding water encircling the stone; *Nuo* is the sturdy pine anchoring the cliff. Confucius praised Qu Boyu, saying: \"When the state has the Way, he serves; when it lacks the Way, he rolls up his principles and hides them in his bosom\"—this is the Promise concealed within Deference. Yu Rang swallowing charcoal to disfigure himself, keeping faith with a fallen lord—this is Deference contained within a Promise.\r\n\r\nI have named my studio **\"Xiangruo,\"** shearing away the radical for \"speech.\" I do not seek to emulate the silence of the Bronze Statue, but rather to aspire toward the silent transformative power of the Cosmos—as the Sage asked, \"Does Heaven speak?\"\r\n\r\nIn this collection, whether discussing history or chanting of objects, I seek to advance by retreating, and to contain the solid within the void. If the reader can discern the ambition of the Leviathan and the Roc within my Deference, and feel the sincerity of bronze and stone within my Promise, then I may, like Tao Qian, \"seek no deep understanding,\" yet drain three great goblets of wine in content.\r\n\r\n### Text B: Record of the Xiangruo Studio\r\n*(Original: 《让诺集·襄若斋志》)*\r\n\r\n> **Original Text:**\r\n> “襄若者，余号“让诺”刈除言旁所得。襄者，助也，若者，顺也。余尝思君子处世，当以谦襄万物，虚怀若谷；顺天应时，若水之处下。…… 斋跨屋三、四重檐，若云梯接霄汉。…… 尤忆玄冬呵冻誊《阳阿》，砚冰初化时，墨色尤见哀泪。…… 每当暮霭垂檐，紫藤筛月，父母与余及麻璆共聚襄若斋三层书案前。……”\r\n\r\n**Translation:**\r\n\r\n\"Xiangruo\" is derived from my alias \"Rangnuo\" by pruning the verbal radical. **Xiang (襄)** signifies assistance; **Ruo (若)** implies compliance. I have often reflected that a gentleman should assist the myriad things with humility, his heart as empty as a valley, and comply with the seasons of Heaven, positioning himself below like water.\r\n\r\nThe studio spans the third and fourth eaves of the house, resembling a cloud-ladder reaching toward the Milky Way. Each morning, when the casements are opened, fresh dew from the wisteria dampens my sleeves; amidst the purple clouds shading the window, the downy feathers of turtledoves are occasionally revealed—a natural brocade screen.\r\n\r\n**The Third Floor (The Archive):**\r\nThis is the locus of books and composition. The shelves are lined with volumes ranging from primers on prosody to the *Anthology of Literature* (Wen Xuan), arranged like the terraced ridges of spring fields. On the western desk lie seals carved from Qintian stone; one bears the seal-script for \"Rangnuo,\" another \"Xiangruo Zhai,\" carved during my sojourn in Qufu. Seeing them recalls the mists of the River Si. Most precious is a sandalwood box containing mementos from Yenching University and letters from my dear friend Mr. Zhou; though years have passed, the fragrance of the stationery endures.\r\n\r\n**The Fourth Floor (The Atrium):**\r\nAscending the spiral stair, one reaches the place where the brush is wielded. In the clear daylight, wind chimes answer the murmuring doves. I recall copying the *Yang A* rhapsody in the dead of winter, breathing upon my frozen hands; as the ice in the inkstone first melted, the color of the ink seemed to weep with sorrow. The room opens onto a glass pavilion. On rainy nights, brewing tea with my student Xu, we would gaze at **Lake Luoma**: amidst the broken silver of the icy mirror, fishing lights appeared like the Galaxy pouring downwards.\r\n\r\n**The Gathering:**\r\nWhenever evening mists hung from the eaves and the wisteria sifted the moonlight, my parents, myself, and our cat, **Ma Qiu (麻璆)**, would gather before the desk. My father, holding a celadon tea cup, would ask about my studies. My mother, pausing her pen, would smile and say: \"When you learned to walk, you fell and rose by yourself; today's bottleneck is but a stone step.\" Ma Qiu, curled on the chair, would tap my palm with his tail, as if mocking my hesitation.\r\n\r\nSuch were the nights from the Awakening of Insects to the Start of Summer. Ma Qiu accompanied my reading like a shadow, and my difficulties vanished like ice melting in a spring creek. Alas! The objects in this studio, whether dust-laden or claw-marked, all possess the zest of life. Exhausted from night reading, hearing only the copper clepsydra rubbing against the vine shadows on the paper window, I feel this body has transcended into the time of the Ancients.\r\n\r\n---\r\n\r\n## III. L'Alter Ego Aristocratique\r\n\r\n*Ce fragment représente une extension ludique de mon identité, née d'une plaisanterie affectueuse et développée avec l'aide de l'intelligence artificielle.*\r\n\r\n**Son Excellence, Monsieur le Vicomte René Gilles Rinelle von Leutstetten de Provence, Chevalier de l'Ordre du Saint-Michel.**\r\n*(Abrégé en : Rinelle de Provence)*\r\n\r\nVoici l'exégèse de ce titre baroque :\r\n\r\n1.  **Vicomte (Le Titre) :** Un titre de noblesse intermédiaire, ni trop haut ni trop bas. Il fait écho à mes loisirs tels que le golf et l'équitation, tout en symbolisant mon apparence éternellement juvénile (« l'enfant noble »). Il reflète également un certain statut que j'occupe au sein de diverses communautés en ligne.\r\n2.  **René (Le Prénom) :** Signifie littéralement **« celui qui est né de nouveau »** (Renaissance).\r\n3.  **Gilles (Le Second Prénom) :** Signifie **« le jeune chevreau »** ou, par extension étymologique liée à l'égide (*aigis*), **« le porteur de bouclier »**. Cela symbolise la prudence, la protection et une certaine innocence.\r\n4.  **Rinelle (Le Patronyme) :** Le nom de famille principal de ce personnage. C'est une variation phonétique directe de mon nom anglais, **Runnel**.\r\n5.  **von Leutstetten (La Lignée Germanique) :** La particule **`von`** connecte le personnage à une ascendance allemande imaginaire. **Leutstetten** est un véritable lieu près de Munich, situé au bord d'un lac. Cela fait écho à la réalité de ma résidence : une demeure de style villégiature allemande au bord de l'eau.\r\n6.  **de Provence (Le Fief Français) :** La particule **`de`** rattache le titre à une terre française. La **Provence** incarne mon attachement sentimental profond pour cette région et mon admiration pour l'école mathématique française. C'est le « port d'attache » spirituel et l'identité finale de ce personnage.\r\n7.  **Chevalier de l'Ordre du Saint-Michel (La Décoration) :** Une référence aux « chevaliers de l'esprit ». Cela représente un anoblissement non par le sang, mais par le savoir, la culture et l'intellect."
  },
  "nikonov-knot": {
    "title": "The Space Between the Lines: A Post-Gaokao Journey into Knot Theory via Nikonov's seminar",
    "date": "2025-07-05",
    "content": "## Overview\r\n\r\nThe summer after the *Gaokao* is a strange time. The pressure valve releases, and suddenly, there is silence. To fill that silence, I found myself in a online seminar room, listening to I. M. Nikonov speak about \"Partial Tribrackets.\"\r\n\r\nI will be honest: I was completely lost. Terms like \"quasigroups,\" \"biquandloids,\" and \"thickened surfaces\" were flying around the room, and I felt like I had walked into a movie halfway through. My high school mathematics education—calculus, geometry, algebra—had built a strong foundation, but this was a skyscraper I couldn't see the top of.\r\n\r\nRefusing to let the confusion win, I tracked down the speaker's related paper: **“The crossing and the arc from the topological viewpoint” (arXiv:2504.18836v1)**. I decided to treat this paper not just as a reading assignment, but as a map.\r\n\r\nMy study session became \"top-heavy.\" I spent days obsessing over the **Introduction** and **Section 2**, specifically the fundamental philosophical divide in knot theory: the **Topological** view vs. the **Combinatorial** view. This note is the result of that deep dive—a compilation of what I learned from the paper, supplemented by the external research I had to do just to understand the first page.\r\n\r\n---\r\n\r\n## **Part I: The Two Faces of Knot Theory**\r\n\r\nThe paper opens with a sentence that dictates the entire structure of the field:\r\n\r\n> *\"Knot theory can be approached from two different sides. The topological approach defines a knot as an embedding of the circle in $\\mathbb{R}^3$. ... Combinatorially, a knot can be defined as an equivalence class of diagrams modulo Reidemeister moves.\"* — Nikonov\r\n\r\nThis duality fascinated me. It’s like the wave-particle duality in physics; to truly understand the object, you must accept it behaves as two different things simultaneously.\r\n\r\n### **1. The Topological Approach: The God’s Eye View**\r\n\r\nThis is the definition that feels most \"real.\" It treats the knot as a physical object existing in 3-dimensional space.\r\n\r\n**Definition:** A knot $K$ is an embedding of the circle $S^1$ into the Euclidean space $\\mathbb{R}^3$ (or the sphere $S^3$).\r\n$$ f: S^1 \\hookrightarrow \\mathbb{R}^3 $$\r\n\r\nWhen I first read \"embedding,\" I had to look up what that actually meant mathematically. It’s not just placing a loop in space; it must be a homeomorphism onto its image. Crucially, knot theory generally deals with *tame* knots (knots that can be represented as a polygon with a finite number of sides), avoiding \"wild knots\" that have infinite wiggliness (like the Fox-Artin wild arc).\r\n\r\nThe core problem in the topological approach is **Ambient Isotopy**. Two knots $K_1$ and $K_2$ are equivalent if there is a continuous deformation of the space $\\mathbb{R}^3$ that carries $K_1$ to $K_2$. It’s not just that the string moves; the *entire universe around the string* stretches and twists like rubber to accommodate the movement.\r\n\r\nThe paper lists several major topological achievements that I had to unpack one by one:\r\n\r\n#### **A. Prime Decomposition (Schubert)**\r\nNikonov cites [35] regarding the decomposition of knots.\r\n*   **The Concept:** Just as every integer can be uniquely factored into prime numbers (e.g., $12 = 2 \\times 2 \\times 3$), every knot can be decomposed into \"Prime Knots.\"\r\n*   **The Operation:** The \"multiplication\" for knots is the **Connected Sum** ($K_1 \\# K_2$). You cut a small arc out of each knot and splice them together.\r\n*   **The Theorem:** Horst Schubert proved in 1949 that this decomposition is unique. A knot is \"prime\" if it cannot be written as the sum of two non-trivial knots.\r\n*   *Why this matters:* It gives us a periodic table of knots. The Trefoil is prime. The Figure-Eight is prime. But a \"Granny Knot\" is just two Trefoils added together.\r\n\r\n#### **B. Thurston’s Trichotomy**\r\nThis was the most intimidating concept in the introduction. The paper references Thurston [38], a giant in the field.\r\n*   **The Concept:** In the late 1970s, William Thurston revolutionized topology by linking it to geometry. He proposed that 3-manifolds (like the space obtained by carving a knot out of $\\mathbb{R}^3$, called the *knot complement*) can be cut into pieces, each of which has a specific geometric structure.\r\n*   **The Three Types of Knots:**\r\n    1.  **Torus Knots:** These live on the surface of a donut (torus). They are highly structured and repetitive.\r\n    2.  **Satellite Knots:** These are \"knots within knots.\" Imagine taking a solid torus that contains a knot, tying that entire solid torus into *another* knot, and pulling it tight. They are \"composite\" in a geometric sense.\r\n    3.  **Hyperbolic Knots:** This was the shocker. *Most* knots fall into this category. Their complements admit a metric of constant negative curvature (hyperbolic geometry). This means the knot complement has a finite, rigid **Hyperbolic Volume**, which becomes a powerful topological invariant. The Figure-Eight knot is the simplest hyperbolic knot.\r\n\r\n#### **C. The Knot Group**\r\nNikonov mentions the \"knot group [9].\"\r\n*   **Definition:** $\\pi_1(\\mathbb{R}^3 \\setminus K)$. This is the fundamental group of the space *around* the knot.\r\n*   **Interpretation:** Imagine holding a loop of string in the empty space around the knot. Can you shrink that loop to a point without touching the knot? If the knot wasn't there, the answer would always be yes (the group is trivial). But the knot acts as an obstacle. The algebra of how those loops wind around the knot captures the knot's topology perfectly.\r\n*   **The Catch:** While the Knot Group is a perfect invariant (it distinguishes the unknot from everything else), it is an infinite non-abelian group. Checking if two such groups are isomorphic is an algorithmically unsolvable problem in general!\r\n\r\n### **2. The Combinatorial Approach: The Shadow World**\r\n\r\nWhile the topological approach is elegant, it is incredibly hard to calculate with. How do you calculate the \"hyperbolic volume\" of a string in your pocket? This is where the Combinatorial approach enters.\r\n\r\n**Definition:** A knot is an equivalence class of **Diagrams** modulo **Reidemeister Moves**.\r\n\r\nThis essentially flattens the 3D complexity into 2D graphs with \"over/under\" information.\r\n*   **The Diagram:** A 4-valent planar graph where vertices (crossings) are marked to show which strand is on top.\r\n*   **Reidemeister Moves:** Kurt Reidemeister proved that any two diagrams of the same knot can be transformed into each other using just three local moves:\r\n    1.  $\\Omega_1$: Twisting a loop (adding/removing a curl).\r\n    2.  $\\Omega_2$: Sliding one strand over another (adding/removing two crossings).\r\n    3.  $\\Omega_3$: Sliding a strand across a crossing (the triangle move).\r\n\r\nThe paper notes a crucial limitation here:\r\n> *\"Many constructions of knot invariants ... use labels assigned to diagram elements. ... The universal invariant labels ... can be thought of as equivalence classes of arcs and crossings.\"*\r\n\r\nThis is the problem. In the combinatorial world, we chop the knot into pieces—**Arcs** (lines between undercrossings), **Regions** (spaces between lines), and **Crossings**. We assign algebraic values (colors) to these pieces to build invariants (like the Jones Polynomial or Skein Modules).\r\n\r\n**The Philosophocal Gap:**\r\nWhen we calculate something using a diagram, we often lose the geometric intuition. *Why* does coloring an arc with a matrix correspond to 3D topology? Is an \"arc\" just a line of ink on paper, or is it something real?\r\n\r\n---\r\n\r\n## **Part II: The Bridge — Nikonov’s \"Probes\"**\r\n\r\nThis is where Nikonov’s paper truly shines and where my deep reading paid off. He proposes a way to unify these two worlds. He asks: **What if the combinatorial elements (arcs, crossings) were actually topological objects?**\r\n\r\nTo do this, he introduces the environment of a **Thickened Surface**.\r\nInstead of $\\mathbb{R}^3$, we work in $F \\times I$, where $F$ is a surface and $I=[0,1]$ is an interval. This is like a slice of space, a slab of jelly.\r\n\r\n### **1. Redefining Diagram Elements**\r\nThis section of the paper (Section 2.2 - 2.5) blew my mind. Nikonov stops treating diagram elements as 2D drawings and redefines them as **Isotopy Classes of Paths**, which he calls **Probes**.\r\n\r\n*   **The Arc (Topological Definition):**\r\n    Usually, an arc is a line segment in a diagram.\r\n    *Nikonov's View:* An arc is an isotopy class of a path starting on the knot $K$ and travelling \"up\" through the thickened surface to the top boundary $F \\times \\{1\\}$.\r\n    *Visualization:* Imagine the knot floating in the middle of the jelly slab. You stick a needle (the probe) from the top surface down to touch the knot. The \"arc\" is that needle. If you wiggle the needle (isotopy), it's still the same arc.\r\n\r\n*   **The Semiarc (Topological Definition):**\r\n    Usually, a semiarc is an edge of the graph from one crossing to another.\r\n    *Nikonov's View:* A path from the bottom surface $F \\times \\{0\\}$ to the top surface $F \\times \\{1\\}$ that intersects the knot $K$ exactly once.\r\n\r\n*   **The Crossing (Topological Definition):**\r\n    Usually, a vertex where two lines cross.\r\n    *Nikonov's View:* A path from bottom to top that intersects the knot **twice**.\r\n    *Why this is brilliant:* A crossing isn't just a point; it's a history of interaction. The probe passes through the knot at two different depth levels, capturing the \"over/under\" nature physically.\r\n\r\n*   **The Region (Topological Definition):**\r\n    *Nikonov's View:* A path from bottom to top that **never** intersects the knot. It explores the empty space (the knot complement).\r\n\r\n### **2. Invariants vs. Coinvariants**\r\nThe Introduction makes a subtle but vital distinction between *Invariants* and *Coinvariants*, a concept linked to **Categorification**.\r\n\r\n*   **Invariant:** A value that is exactly the same for all diagrams of a knot (e.g., The genus is always an integer, say $g=1$).\r\n*   **Coinvariant:** A set or space that is *isomorphic* for all diagrams, but not identical.\r\n    *   *My Analogy:* Think of a Vector Space $V$. Its dimension (a number) is an invariant. The Space $V$ itself is a coinvariant. If you change the basis (change the diagram), the coordinates change, but the space is intrinsically the same.\r\n    *   Nikonov argues that the set of all possible Arc Probes is the **Universal Coinvariant**. It contains all the information needed to build other invariants.\r\n\r\nBy defining these elements topologically, Nikonov validates the combinatorial approach. When we perform a Reidemeister move, we aren't just erasing lines on paper; we are isotoping these \"probes\" in 3D space.\r\n\r\n---\r\n\r\n## **Part III: From Topology to Algebra (The Seminar Connection)**\r\n\r\nHaving grounded myself in the definitions, the second half of the paper (and the actual content of the seminar) finally made sense. The seminar was about \"Partial Tribrackets.\" I realized this was simply the algebraic shadow of the topological probes I had just studied.\r\n\r\nThe paper transitions from **Isotopy** (physical movement) to **Homotopy** (algebraic equivalence). When we look at the homotopy classes of these probes, they naturally form algebraic structures. This answers the question: \"How do we color a knot?\"\r\n\r\n### **1. Arcs $\\to$ Quandles**\r\nThis is the most famous example. If you take the homotopy classes of the Arc Probes, they form a structure called a **Quandle**.\r\n*   *The Logic:* If two arcs $a$ and $b$ meet at a crossing to form a third arc $c$, the algebraic relationship $c = a * b$ must hold.\r\n*   *Topologically:* This corresponds to the fundamental group of the knot complement acting on the arcs.\r\n\r\n### **2. Regions $\\to$ Partial Ternary Quasigroups (Tribrackets)**\r\nThis was the specific topic of Nikonov's talk.\r\n*   *The Setup:* Instead of arcs, we color the **regions**.\r\n*   *The Interaction:* At a crossing, four regions meet. If you know the colors of three, can you determine the fourth?\r\n*   *The Structure:* This creates a ternary operation $[a, b, c] = d$. This structure is called a **Tribracket**.\r\n*   *Why \"Partial\"?* In the standard plane, any regions can technically interact. But in a thickened surface (topology!), there are obstructions. Not all regions *can* touch each other due to the genus of the surface. Therefore, the algebraic operation is only defined for \"neighboring\" regions. Hence, **Partial** Tribrackets.\r\n\r\n### **3. Semiarcs $\\to$ Biquandloids**\r\nStandard Biquandles are used for virtual knots. Nikonov introduces the **Biquandloid** to handle the geometric constraints of knots in fixed surfaces. It’s a biquandle with \"shadow maps\" to account for the spatial positioning of the semiarcs.\r\n\r\n### **4. Crossings $\\to$ Crossoids**\r\nFinally, he defines a structure for the crossings themselves, called a **Crossoid**. This generalizes the theory of Parity (which distinguishes \"good\" and \"bad\" crossings in virtual knot theory).\r\n\r\n---\r\n\r\n## **Conclusion: The Grand Unification**\r\n\r\nThe paper concludes by introducing the **Homotopical Multicrossing Complex**. This felt like the \"Final Boss\" of the paper. It seems Nikonov is constructing a massive homology theory where:\r\n1.  The chains are made of these \"multicrossings\" (sequences of probes).\r\n2.  The boundary operations correspond to resolving these crossings.\r\n3.  The Tribracket, Biquandle, and Crossoid homologies are just specific \"projections\" or pairings of this one universal complex.\r\n\r\n**Final Thoughts:**\r\nMy attempt to understand a single seminar turned into a journey through the foundations of low-dimensional topology. I started by looking for a definition of a \"tribracket\" and ended up realizing that the lines we draw on paper to represent knots are actually physical, topological probes reaching through a thickened surface.\r\n\r\nThe gap between the \"God's eye\" Topological view and the \"Shadow\" Combinatorial view is vast, but concepts like Nikonov's Probes provide the bridge. The algebra isn't just abstract rules; it's the encoded movement of these probes in 3D space. While I definitely need more time to digest the complexities of the Multicrossing Complex, I no longer feel like I walked into the movie halfway through. I’m just starting to watch it from the beginning."
  },
  "nmo-physics": {
    "title": "Minecraft: The Riemann Manifold of Fun—A Hypothetical Physics Simulation",
    "date": "2025-07-30",
    "content": "## Overview\r\n\r\nThe following is a semi-serious, highly technical, and completely humorous review of the Swedish video game *Minecraft*. This title, often described as a sandbox construction game, is revealed here as an ambitious, albeit incomplete, simulation built upon a set of **radically altered fundamental physical axioms**. Much like Greg Egan’s *Orthogonal* trilogy, which explores a universe where spacetime is a Riemannian rather than a Lorentzian manifold, *Minecraft* offers a world governed by novel, non-standard laws, yielding a highly amusing, yet surprisingly fertile, ground for engineering and logic.\r\n\r\nWe present the core deviations from classical and quantum physics, followed by the advanced (modded) scientific extensions, concluding with an enthusiastic invitation to join the Nanjing University Minecraft Organization (NMO).\r\n\r\n***\r\n\r\n## Minecraft: A Universe Governed by Novel Physical Axioms\r\n\r\nThe game’s construction and behavior fundamentally violate established principles, creating a unique, blocky physics:\r\n\r\n### 1. The Selective Gravitational Field (A Non-Universal Force)\r\n\r\n*   **Standard Physics:** Gravity is a universal force, affecting all mass-energy according to the equivalence principle.\r\n*   **Minecraft Axiom 1:** The **Gravitational Field is Selective and Binary**. Most solid, block-based matter is completely immune to gravitational acceleration, existing in a state of perpetual, stable, rigid suspension ($\\mathbf{g} \\rightarrow 0$ for blocks). Conversely, **biological entities (mobs), dropped items (entities), and a few special blocks (e.g., sand, gravel)** are fully subject to Newtonian mechanics in the vertical dimension.\r\n*   **Academic Joke:** This posits a universe operating on a **\"Preferred Mass Triviality\"** principle, where the vacuum energy density of block materials is perfectly zero, or where the interaction range of the mediating graviton field is artificially restricted to a select subset of material phases.\r\n\r\n### 2. The Entropically-Neutral Life Cycle (Weakened Energy Conservation)\r\n\r\n*   **Standard Physics:** Biological generation, death, and interaction are governed by the conservation of energy and the Second Law of Thermodynamics (entropy increases).\r\n*   **Minecraft Axiom 2:** **Energy Conservation is Critically Weakened for Biological Processes.** The spawning and despawning of biological entities (mobs) are entirely decoupled from energy conversion (no heat loss, no chemical potential change), making the $\\Delta E$ of the process arbitrarily close to zero. The **Entropy Model is Not Applicable** to population dynamics.\r\n*   **Academic Joke:** This implies the existence of a perfectly efficient, localized, **Non-Equilibrium Spawning Operator** that bypasses the need for free energy conversion entirely, suggesting a non-thermal origin for life in this simulated cosmos.\r\n\r\n### 3. Population Dynamics: Discrete Events vs. Continuous Models\r\n\r\n*   **Standard Physics:** Real-world food webs are modeled by continuous **Population Dynamics** (e.g., the Lotka-Volterra predator-prey equations, which account for carrying capacity and continuous rates of consumption).\r\n*   **Minecraft Axiom 3:** **Biological Interaction is Driven by Discrete State Transitions.** The interaction between species (e.g., a wolf attacking a sheep) is resolved as an immediate, discrete event, entirely **ignoring continuous variables** like environmental carrying capacity, energy expenditure for hunting, and instantaneous rates of predation.\r\n*   **Academic Joke:** The simulated ecosystem is a vast, interconnected **Finite State Machine (FSM)**, where the biological agents simply transition between states (e.g., 'Target Acquired' $\\rightarrow$ 'Attack Executed' $\\rightarrow$ 'Target Entity Destroyed'), making the entire system computationally simple but ecologically nonsensical.\r\n\r\n### 4. Structural Engineering: The $\\mathbf{F}_{\\text{critical}} \\rightarrow \\infty$ Universe\r\n\r\n*   **Standard Physics:** Real-world engineering structures must adhere to material science principles, especially **Hooke's Law**, and structural failure due to **Euler Buckling**. The critical load for a column is $F_{\\text{critical}} = \\pi^2 E I / (K L)^2$, where $E$ is Young's Modulus and $I$ is the Area Moment of Inertia.\r\n*   **Minecraft Axiom 4:** **The Young's Modulus is Infinite, and Buckling is Prohibited.** Materials can be stacked indefinitely into cantilevers, suspension bridges, or towers without concern for tensile, compressive, or shear stresses. The buckling critical load limit is $\\mathbf{F}_{\\text{critical}} \\rightarrow \\infty$, rendering all structures perfectly rigid.\r\n*   **Academic Joke:** This is a universe built upon the principle of **Perfectly Rigid Bodies** where all elastic and plastic deformation is set to zero. All construction is, by default, an ideal, non-deformable **Born-Oppenheimer Approximation** of a structure.\r\n\r\n### 5. Fluid Dynamics: The Navier-Stokes Trivialization\r\n\r\n*   **Standard Physics:** Fluids obey the **Navier-Stokes Equations**, accounting for viscosity, pressure gradients, and the conservation of momentum (e.g., the Bernoulli principle linking speed and pressure).\r\n*   **Minecraft Axiom 5:** **Fluid Mechanics is Trivialized into a Simple State Machine.** Fluid flow (water and lava) does not adhere to viscosity, pressure-gradient forces, or the Bernoulli principle. Flow velocity is purely a function of the **block-volume displacement**—a simple, discrete decay model from the source block.\r\n*   **Academic Joke:** The game's liquid is an example of a **Non-Newtonian Block-Wise Fluid** where the velocity field is quantized and the stress tensor is trivialized, making it an ideal model for computational simplicity, if not physical accuracy.\r\n\r\n### 6. Redstone Circuits: The Pure Boolean Logic Engine\r\n\r\n*   **Standard Physics:** Electronic circuits rely on **Electromagnetism**, governed by Maxwell's Equations, where signal transmission is due to the movement of electrons and photons.\r\n*   **Minecraft Axiom 6:** **Signal Transmission is Purely Logical.** The *Redstone* system simulates Boolean logic gates (AND, OR, NOT, XOR, etc.) but its operation is entirely decoupled from the fundamental laws of electricity and magnetism. The signal decay is a *digital delay* over distance, not an ohmic loss.\r\n*   **Academic Joke:** Redstone is a perfect **Analytic Continuation of Boolean Algebra into Physical Space**, acting as a medium for pure, unadulterated *logic*, rather than messy, analog electromagnetic waves.\r\n\r\n***\r\n\r\n## Advanced Academic Extensions (Modded Physics)\r\n\r\nFor those finding the base physics too simplistic, the game supports **\"Mod-Science\"**, allowing the integration of complex hypothetical systems:\r\n\r\n*   **Thaumcraft:** Introduces **Alchemical Engineering** based on a quasi-quantum substance-energy field theory, demanding the balancing of *Aspects* (elemental energy charges).\r\n*   **Ars Nouveau:** Allows the construction of a **Programmable Runic Dynamical System**—a Turing-complete system for magic utilizing custom-defined flow charts and abstract elemental components.\r\n*   **GregTech:** Implements a complex, high-throughput **Strongly Correlated Electron Industrial System**, demanding real-world thermodynamic and material constraints for high-tier processing.\r\n*   **Create Mod:** Introduces **Rotational Kinematics and Stress-Field Matter Reorganization**, requiring players to manage *Stress* (a simplified equivalent of torque and material strength) to power kinetic machines, thereby reintroducing a non-trivial **Young's Modulus** (Axiom 4 is partially disabled). This mod also features mechanisms for **Quantum Tunneling Transmission** and **Precision Manipulation Systems**.\r\n\r\n## Call to Action\r\n\r\nThe world of *Minecraft* is not merely a game; it is a laboratory for exploring non-standard physical realities and designing complex computational systems.\r\n\r\n**Join the Nanjing University Minecraft Organization (NMO)** to delve deeper into these systems and build incredible worlds!\r\n\r\nFind out more: [https://www.nmo.net.cn/](https://www.nmo.net.cn/)\r\n\r\n**Join the NMO meow, join the NMO thank you meow.**"
  },
  "saburou-zero": {
    "title": "The Absolute Zero: Saburou Saitoh’s Crusade to Redefine Mathematics",
    "date": "2022-07-18",
    "content": "## Overview\n\n**The \"Fun Person\" of the Day:** Prof. Saburou Saitoh (Gunma University).\n\n**The Phenomenon:** A legitimate mathematician with a background in Reproducing Kernels who has seemingly pivoted his entire career toward proving that $z/0 = 0$.\n\nThis isn't your standard crankery. Saitoh isn't an outsider scribbling in green ink; he publishes via SCIRP (a known quantity in the predatory/low-tier world) and viXra, yet somehow managed to slip his \"Division by Zero\" manifesto into a Springer proceeding. This puts him in a league comparable to the late Myron W. Evans—academic credentials used to push a theory that breaks fundamental axioms.\n\n**Speculation on Intent:**\n\nIs this an elaborate academic troll? Unlikely. The tone is far too earnest. It appears to be a classic case of the \"Golden Hammer.\" Saitoh seems to have taken the concept of the Moore-Penrose pseudoinverse (where the \"inverse\" of a zero matrix can be defined as zero) or Tikhonov regularization and elevated it from a computational tool to a fundamental law of the universe. By declaring that singularities are simply \"zero,\" he eliminates all poles, singularities, and infinities. It is a \"brute force\" solution to complex analysis: if a function blows up, just define it as zero. The result is a mathematical system where the point at infinity collapses into the origin—a topological nightmare presented as \"elementary and fundamental mathematics.\"\n\n---\n\n## Detailed Analysis of the Texts\n\n### I. The Manifesto: *Matrices and Division by Zero z/0 = 0*\n\n**Source:** Matsuura, T. and Saitoh, S. (2016). Matrices and Division by Zero z/0 = 0. *Advances in Linear Algebra & Matrix Theory*, 6, 51-58. [https://doi.org/10.4236/alamt.2016.62007](https://doi.org/10.4236/alamt.2016.62007)\n\nThis paper lays the groundwork for the \"Yamada Field\" (Y-Field), a structure where division by zero is permitted and defined as zero.\n\n- **The Core Axiom:** Saitoh asserts that for any complex number $b$, the fraction $b/0 = 0$. This is justified \"incidentally\" by Tikhonov regularization.\n\n- **The Geometric Consequence (The Collapse):** In standard geometry, parallel lines meet at infinity.\n\n- In Saitoh’s geometry, the \"point at infinity\" is represented by $z=0$.\n\n- Therefore, **parallel lines intersect at the origin $(0,0)$.**\n\n- *Critique:* This implies that if you have two parallel lines anywhere in space, their intersection point is the origin. The logic effectively folds the entire Euclidean plane such that the \"horizon\" touches the center.\n\n**Cramer's Law \"Fix\":** Standard Cramer's Law fails when the determinant is zero ($D=0$, singular matrix). Saitoh claims that by defining $z/0=0$, the solution to a system with a singular matrix is simply the zero vector.\"By the division by zero, we can understand that if $a_1b_2 - a_2b_1 = 0$, then the common point is always given by $(0,0)$ even when the two lines are the same.\"\n\n**Physical Interpretations:Hooke's Law:** For springs in series $\\frac{1}{k} = \\frac{1}{k_1} + \\frac{1}{k_2}$. If $k_1=0$, normally the system breaks. Saitoh argues $1/0 = 0$, so $1/k = 1/k_2$, meaning $k=k_2$.\n\n**Einstein Misquote:** He invokes Einstein to support his theory, though the quote is likely apocryphal or misinterpreted.\n            \"Blackholes are where God divided by zero.\"\n\n### II. The Escalation: *log 0 = log ∞ = 0 and Applications*\n\n**Source:** Michiwaki, H., Matuura, T., Saitoh, S. (2018). $\\log 0 = \\log \\infty = 0$ and Applications. In: Pinelas, S., Caraballo, T., Kloeden, P., Graef, J. (eds) *Differential and Difference Equations with Applications*. ICDDEA 2017. Springer Proceedings in Mathematics & Statistics, vol 230. Springer, Cham. [https://doi.org/10.1007/978-3-319-75647-9_24](https://doi.org/10.1007/978-3-319-75647-9_24)\n\n\nHere, the theory expands to logarithmic functions and complex analysis, creating even more startling discontinuities.\n\n- **Redefining Logarithms:** Since $\\log(z)$ has a singularity at $z=0$ and a pole at $z=\\infty$, and since the \"point at infinity\" is now the \"origin\" (via $1/0=0$), Saitoh concludes:\"In this paper, we will show that $\\log 0 = \\log \\infty = 0$ by the division by zero $z/0 = 0$.\"\n\n- **The $1/z$ Mapping:** He relies heavily on the mapping $W = 1/z$. In standard analysis, $z \\to 0$ implies $W \\to \\infty$. Saitoh argues that the image of $z=0$ is exactly $W=0$.\"The image of $z = 0$ is $W = 0$ (should be defined)... The division by zero will give great impacts to complex analysis and to our ideas for the space and universe.\"\n\n- **Schrödinger's Euler Identity:** This leads to bizarre multivalued definitions.$e^0 = 1$ (standard definition).\n\n- $e^0 = 0$ (via the \"division by zero\" logic where the value at a singularity is zero).\n\nHe acknowledges this \"strong discontinuity\" but accepts it as a \"natural way\" the universe works.\n\n**Applications to Differential Equations:** He solves differential equations by simply ignoring the singular parts. If a term contains a $1/x$ and $x=0$, that term vanishes.\"For the differential equation... we have the solution... Then, if $\\mu = 0$, we obtain, immediately, by the division by zero [a solution where the singular term vanishes].\"\n\n**The \"Zero\" Constant:** He posits that $0^0 = 1$ is convenient for Taylor series, but $0^0 = 0$ is also valid depending on context. He also claims $\\cos 0 = 1$ and $\\cos 0 = 0$ are both \"valid\" in different contexts (reflection of infinity to the origin).\n\n## Selected Quotes\n\n- **On the ambition of the project:** \"The division by zero has a long and mysterious story over the world... however, Sin-Ei Takahasi established a simple and decisive interpretation.\"\n\n- **On the redefinition of infinity:** \"The point at infinity is represented by zero, that is, the coincidence of the point at infinity and the origin.\"\n\n- **On the \"Zero\" value of functions:** \"We wish to consider also the value $\\cos 0 = 0$. The values $e^0 = 0$ and $\\cos 0 = 0$ may be considered that the values at the point at infinity are reflected to the origin.\"\n\n## A Serious Critique\n\nMathematics, as a deductive system, stands on the bedrock of consistent axioms—propositions whose truth is assumed to build coherent, predictive, and applicable frameworks. To redefine a foundational operation like division by zero is not an act of \"revolutionary insight,\" but a violation of this coherence, as Saitoh’s work demonstrates through its cascading logical contradictions and detachment from both theoretical rigor and empirical reality.\n\nThe core flaw of Saitoh’s theory lies in its confusion of *computational convenience* with *ontological truth*. Tools like the Moore-Penrose pseudoinverse or Tikhonov regularization are valuable precisely because they are *contextual*: they resolve ambiguities in specific computational tasks (e.g., solving underdetermined systems) while acknowledging their status as practical adaptations, not universal laws. By elevating these tools to axiomatic status, Saitoh erases the distinction between \"what works for a problem\" and \"what is true of the mathematical structure itself.\" The result is not a \"new field\" but a house of cards: parallel lines intersecting at the origin dismantles Euclidean geometry, conflicting values of $e^0$ and $\\cos 0$ render analysis meaningless, and \"solving\" differential equations by ignoring singularities abandons the very purpose of such equations—to model continuous change accurately.\n\nEqually troubling is the way Saitoh’s academic credentials have lent a veneer of legitimacy to a theory that would otherwise be dismissed. His ability to publish in a Springer proceeding—an imprint associated with rigorous peer review—raises critical questions about the integrity of academic publishing, particularly in specialized fields where gatekeeping relies on expert familiarity with niche topics. This is not a trivial concern: bad mathematics, when cloaked in academic authority, can mislead early-career researchers, waste resources on unfruitful inquiries, and erode public trust in the discipline’s ability to distinguish fact from fancy.\n\nTo be clear, academic progress often emerges from challenging orthodoxy—but meaningful challenges adhere to a basic contract: they either show the existing framework is incomplete (e.g., non-Euclidean geometry extending, not rejecting, Euclid’s axioms) or propose a new system that is *more* consistent and explanatory than the old. Saitoh’s work does neither. It replaces a coherent system with one that is deliberately contradictory, then claims this contradiction as a \"natural\" feature of the universe—a rhetorical sleight of hand."
  },
  "sin-tan": {
    "title": "The Derivation of Trigonometric Sum and Difference Formulas from Advanced Standpoints",
    "date": "2023-02-23",
    "content": "## Overview\r\n\r\nThe origin of this note was during class when I wanted to verify the tangent (tan) sum formula directly using the **Reciprocal Basis** from tensor calculus. I initially tried using the scalar triple product (mixed product), but that didn't work. Later, I attempted orthogonal decomposition, but the reciprocal basis of a unit orthogonal basis is the basis itself, which rendered the specific properties of reciprocal bases useless.\r\n\r\nAlthough simply \"grabbing\" the result using rotation matrices is a very reasonable approach, I had an obsession with finding a **\"direct proof for tan.\"** Therefore, I organized various derivation paths ranging from elementary geometry to tensor operations, and finally to higher-level mathematical viewpoints.\r\n\r\nN-20230220: View via [here](https://www.runnelzhang.com/notes/2023/N-20230220.pdf), or visit DOI:[10.6084/M9.FIGSHARE.22268962](https://doi.org/10.6084/m9.figshare.22268962)\r\n\r\nN-20230223: View via [here](https://www.runnelzhang.com/notes/2023/N-20230223.pdf), or visit DOI:[10.6084/M9.FIGSHARE.22268965](https://doi.org/10.6084/m9.figshare.22268965)\r\n\r\n---\r\n\r\n## I. Approaches via Geometry & Vectors\r\n\r\n### 1. Proof of the Sine Formula via Cross Product\r\nThis is the most intuitive method. We restrict the angle range to $(0, \\pi)$.\r\nLet $\\vec{OM} = (\\cos\\beta, \\sin\\beta)$ and $\\vec{ON} = (\\cos\\alpha, \\sin\\alpha)$.\r\nUsing the geometric definition of the cross product's modulus:\r\n$$ |\\vec{ON} \\times \\vec{OM}| = |\\vec{ON}||\\vec{OM}|\\sin(\\beta-\\alpha) = \\sin(\\beta-\\alpha) $$\r\nOn the other hand, using the coordinate form (determinant):\r\n$$ \\vec{ON} \\times \\vec{OM} = \\begin{vmatrix} \\cos\\alpha & \\sin\\alpha \\\\ \\cos\\beta & \\sin\\beta \\end{vmatrix} \\vec{k} = (\\sin\\beta\\cos\\alpha - \\sin\\alpha\\cos\\beta)\\vec{k} $$\r\nComparing both expressions (noting direction and sign), we directly obtain:\r\n$$ \\sin(\\beta-\\alpha) = \\sin\\beta\\cos\\alpha - \\sin\\alpha\\cos\\beta $$\r\n\r\n### 2. The Failed Attempt via Projection Vectors\r\nI attempted to find a shortcut using vector projection.\r\nCalculating the squared modulus of the projection vector $\\vec{NH}$ resulted in $1 - \\cos^2(\\beta-\\alpha) = \\sin^2(\\beta-\\alpha)$.\r\nThis circled back to the $\\sin/\\cos$ form and did not achieve my goal of \"deriving tan directly.\" This path is a dead end.\r\n\r\n---\r\n\r\n## II. Perspectives from Algebra & Analysis\r\n\r\n### 3. Rotation Matrices\r\nIt is perhaps better to say that this is the most reasonable method, and my personal favorite. Even before encountering textbooks, I preferred thinking in terms of matrices.\r\nAlgebraically, \"rotating by $\\alpha+\\beta$\" is equivalent to the composition of linear transformations: first rotating by $\\alpha$, then by $\\beta$.\r\n$$ R(\\alpha+\\beta) = R(\\beta) \\cdot R(\\alpha) $$\r\n$$ \\begin{bmatrix} \\cos(\\alpha+\\beta) & -\\sin(\\alpha+\\beta) \\\\ \\sin(\\alpha+\\beta) & \\cos(\\alpha+\\beta) \\end{bmatrix} = \\begin{bmatrix} \\cos\\beta & -\\sin\\beta \\\\ \\sin\\beta & \\cos\\beta \\end{bmatrix} \\cdot \\begin{bmatrix} \\cos\\alpha & -\\sin\\alpha \\\\ \\sin\\alpha & \\cos\\alpha \\end{bmatrix} $$\r\nDirectly expanding the matrix multiplication yields the sum formulas for sine and cosine instantly.\r\n\r\n### 4. Euler's Formula\r\nWhen dealing with trigonometric formulas, using complex numbers is generally the most convenient (Trivial) approach.\r\n$$ e^{i(\\alpha+\\beta)} = e^{i\\alpha} \\cdot e^{i\\beta} $$\r\n$$ \\cos(\\alpha+\\beta) + i\\sin(\\alpha+\\beta) = (\\cos\\alpha + i\\sin\\alpha)(\\cos\\beta + i\\sin\\beta) $$\r\nSimply expanding the real and imaginary parts suffices. While this proof is extremely elegant, it still targets $\\sin$ and $\\cos$.\r\n\r\n---\r\n\r\n## III. The Tensor Challenge: Direct Proof of the Tangent Formula\r\n\r\nTo satisfy my obsession with \"proving tan directly,\" I attempted to introduce concepts of **non-orthogonal bases** and the **Reciprocal Basis**.\r\n\r\n### 5. Reciprocal Basis Attempt\r\n**Idea:** Let $\\vec{OM}, \\vec{ON}$ be the basis $\\{g_i\\}$. The metric tensor matrix is $G = \\begin{bmatrix} \\cos\\alpha & \\cos\\beta \\\\ \\sin\\alpha & \\sin\\beta \\end{bmatrix}$.\r\nUsing Gaussian elimination to find the inverse yields the reciprocal basis $\\{g^i\\}$.\r\n\r\n**Process:**\r\nIn the note from the 20th, I derived a determinant involving $\\tan(\\alpha-\\beta)$, but there was a sign error. In the note from the 23rd, I corrected the calculation, constructed a vector $\\vec{z} = (\\sin(\\alpha-\\beta), 0, \\cos(\\alpha-\\beta))$, and calculated the following determinant:\r\n$$ 1/\\tan(\\alpha-\\beta) = \\begin{vmatrix} 1 & 0 & \\frac{1}{\\tan(\\alpha-\\beta)} \\\\ -\\tan\\beta & 1 & 0 \\\\ \\tan\\alpha & -1 & 0 \\end{vmatrix} $$\r\nAfter expansion and simplification, I finally obtained:\r\n$$ \\frac{1}{\\tan(\\alpha-\\beta)} = \\frac{1 + \\tan\\alpha\\tan\\beta}{\\tan\\alpha - \\tan\\beta} $$\r\nThis verifies the tangent difference formula. Although the manual calculation was somewhat tedious, it proves the feasibility of handling trigonometric functions using the properties of covariant and contravariant vectors.\r\n\r\n---\r\n\r\n## IV. Supplements from Higher Viewpoints\r\n\r\nAfter organizing the notes above, I realized that these methods actually imply deeper mathematical structures. Here are a few higher-level perspectives I have added:\r\n\r\n### 6. Analytical Perspective: ODE Uniqueness\r\nDisregarding geometry, $\\sin$ and $\\cos$ are essentially linearly independent solutions to the differential equation $y'' + y = 0$.\r\nDefine $f(x) = \\sin(x+a)$. It is easy to prove that $f(x)$ is also a solution to this equation.\r\nAccording to the Uniqueness Theorem for solutions of second-order linear ODEs, $f(x)$ must be a linear combination of $\\sin x$ and $\\cos x$:\r\n$$ \\sin(x+a) = C_1 \\sin x + C_2 \\cos x $$\r\nBy substituting $x=0$ and $x'(0)$ to determine the coefficients, one can derive the formula purely analytically. This is a \"hardcore\" analytical proof.\r\n\r\n### 7. The Ultimate Geometric Perspective: Ptolemy's Theorem\r\nThis is a \"dimensional strike\" (a powerful simplification) in geometry. Construct a cyclic quadrilateral on a unit circle. According to the theorem—\"the product of the diagonals equals the sum of the products of the opposite sides\"—the side lengths correspond directly to chord lengths (i.e., sine values).\r\n$$ \\sin(\\alpha+\\beta) = \\sin\\alpha\\cos\\beta + \\cos\\alpha\\sin\\beta $$\r\nThis requires no complex auxiliary lines, relying directly on the profound properties of Euclidean geometry.\r\n\r\n### 8. Algebraic Perspective: Lie Groups & The Exponential Map\r\nReturning to my favorite \"Rotation Matrix Method,\" elevating it to the level of the Lie Group $SO(2)$ makes everything transparent.\r\nElements of the 2D rotation group $SO(2)$ can be represented via the exponential map $R(\\theta) = e^{\\theta X}$, where $X$ is the generator (skew-symmetric matrix).\r\nUsing the homomorphism property of the exponential function:\r\n$$ e^{(\\alpha+\\beta)X} = e^{\\alpha X} \\cdot e^{\\beta X} $$\r\nThis indicates that the trigonometric addition formula is essentially the **manifestation of group addition under the exponential map**. This also explains why Euler's formula ($U(1)$ group) and the Rotation Matrix ($SO(2)$ group) approaches are so formally similar—they are isomorphic.\r\n\r\n---\r\n\r\n**Conclusion:**\r\nFrom initially drawing circles and finding segments, to deriving matrices and tensors, and finally understanding the underlying Group Theory structure. So-called \"formulas\" are merely projections of the same mathematical entity across different spaces. Although it was a long detour, and the reciprocal basis calculation was laborious, the process of exploration was perhaps more interesting than the result itself."
  },
  "teach-mlp": {
    "title": "Discussion and Reflection on MLP Teaching Routes: Regression vs. Classification Entry Points",
    "date": "2025-10-12",
    "content": "## Overview\n\nThis fragment records a discussion between me and two senior scholars in the field of Deep Learning (DL) regarding the rationality of teaching routes for Multi-Layer Perceptron (MLP). The core topic revolves around whether it is appropriate to introduce MLP starting from regression or classification. I put forward the confusion encountered in the teaching preparation process: starting directly from regression to introduce activation functions and then jumping to MLP fails to enable students to effectively understand the core logic of neural networks, while starting from perceptrons is difficult to explain the necessity of activation functions in an essential way. The two seniors shared their professional insights, pointing out that the core of neural networks is classification, and it is more reasonable to directly take classification as the entry point for teaching, and also explained the key reasons for introducing activation functions. Through this in-depth discussion, I gained a more systematic and in-depth understanding of the teaching logic of DL foundational knowledge.\n\n## Transcript of the Discussion\n\n*Note: \"Scholar A\" is an Associate Professor in the DL field with a Ph.D. from Tsinghua University (THU); \"Scholar B\" is a Ph.D. from Peking University (PKU). Both prefer not to disclose their real names, so their original nicknames are replaced. \"Runnel\" is me, an undergraduate student consulting seniors.*\n\n- Runnel: Moreover, jumping directly to classification networks like MLP in the first class is indeed a bit fast.\n\n- Runnel: He wants to show the necessity of activation functions through regression examples.\n\n- Runnel: But jumping directly from regression to MLP, the students listening to the class actually can't understand what the neural network is doing.\n\n- Scholar B: That's right, talk about pure PE next time.\n\n- Scholar B: Now I get it.\n\n- Runnel: Starting from perceptrons, it's hard to explain why an activation function is necessary instead of a linear function. Just saying that this will make multi-layer neural networks ineffective is not essential enough.\n\n- Scholar B: Exactly.\n\n- Scholar A: @Runnel Actually, most people who teach DL do this.\n\n- Scholar A: No need to mention senior brothers.\n\n- Runnel: In short, we discussed for a long time and didn't find a teaching method that combines the two ideas.\n\n- Scholar A: Top experts do the same.\n\n- Scholar A: First, they say that the XOR problem is difficult to solve.\n\n- Scholar A: Then introduce [the method] to solve the XOR problem.\n\n- Scholar A: Then talk about activation functions (suspected input error in the original text).\n\n- Scholar A: We shouldn't start from regression at all.\n\n- Runnel (18:33): Starting from regression is conducive to intuitively understanding a \"fitting\" process. Using linear functions cannot achieve this fitting, so non-linear ones are necessary.\n\n- Runnel: That's the reason why he chose to start from regression.\n\n- Runnel: But the effect today was not good.\n\n- Scholar A: (Sent a section of literature content about the development of statistics, perceptrons, MLP, SVM, etc.): \"With the development of communication technology and chip technology, the status of the computer vision field in the entire scientific research field has been continuously improved. Traditional support vector machines (SVM) based on SVM have made slow progress in processing image data. However, in 2012, AlexNet achieved excellent results in the ImageNet Large-Scale Visual Recognition Challenge. At this time, more data and stronger chip performance made training neural networks no longer a difficult problem. With the substantial growth of training data sets, the performance of neural networks has been greatly improved. In contrast, the performance of SVM has not been significantly improved. Its good performance in more complex problems has made neural networks continuously applied in various scenarios and regarded as the only route to AGI. However, the interpretability problem of neural networks is a dark cloud lingering over the building of machine learning. For this reason, many scholars have begun to explore the interpretability of neural networks from different angles, intending to break this deadlock to better handle practical problems.\"\n\n- Scholar A: In fact, we shouldn't start from regression at all.\n\n- Scholar A: Instead, start from classification.\n\n- Scholar A: You can adopt my teaching route.\n\n- Scholar A: I revised the teaching method for X Yang before.\n\n- Runnel: Our ultimate goal is indeed to explain MLP clearly.\n\n- Scholar A: The core of neural networks is classification.\n\n- Scholar A: Regression and prediction seem almost the same as classification.\n\n- Scholar A: They only differ by a softmax.\n\n- Runnel: I think starting from classification, including giving examples, is indeed more convenient.\n\n- Scholar A: But it's hard for you to explain why MLP and dropout are needed starting from regression.\n\n- Scholar A: Back in 2016.\n\n- Runnel: We initially wanted to naturally transition from regression to classification.\n\n- Scholar A: A group of people specially asked me to revise their papers.\n\n- Scholar A: Let me revise the regularization.\n\n- Scholar A: Not papers.\n\n- Runnel: Treat classification as a \"problem of multiple regressions.\"\n\n- Scholar A: They are textbooks.\n\n- Scholar A: I think for early-stage students.\n\n- Scholar A: We shouldn't directly talk about classification and regression.\n\n- Scholar A: Or rather, we shouldn't think they are integrated.\n\n- Runnel: Separate first, then integrate?\n\n- Scholar A: When you teach MLP normally, you don't need to touch regression at all.\n\n- Scholar A: The definition of regression itself gives a functional relationship, and then fits the parameters.\n\n- Scholar A: MLP itself is not a writable functional relationship.\n\n- Runnel: Yes, that's the reason why a natural transition is impossible.\n\n- Scholar A: So we should directly talk about classification.\n\n- Runnel: I think a common problem in understanding neural networks is \"why don't we directly use weighting instead of activation functions.\"\n\n- Runnel: Our idea is to explain this problem clearly through regression.\n\n- Scholar A: @Runnel How can you explain it clearly like this.\n\n- Scholar A: I even think people who teach this way don't understand why activation functions are introduced themselves.\n\n- Scholar A: Let's get back to the topic.\n\n- Scholar A: That is, if you want to explain why activation functions are introduced.\n\n- Scholar A: There are two main points.\n\n- Scholar A: The first point is: Activation functions can solve the XOR problem.\n\n- Scholar A: The second point is: Later, through the Universal Approximation Theorem, it was found that S-type functions are the necessary and sufficient condition for the Universal Approximation Theorem.\n\n- Scholar A: If you want to talk about the second point, you need to present the proof process.\n\n- Runnel: @Scholar A We want to intuitively illustrate this situation through regression examples ().\n\n- Scholar A: Then we can only go back to the first point.\n\n- Scholar A: It's impossible.\n\n- Scholar A: How can you describe the S-type function with regression.\n\n- Scholar A: My evaluation is that it's very unreasonable.\n\n- Runnel: @Scholar A We show this approximation process through regression examples.\n\n- Runnel: It can be found that linear functions cannot achieve the same effect.\n\n- Scholar A: Then why don't I use quadratic functions.\n\n- Scholar A: Why don't I use power functions.\n\n- Scholar A: In terms of teaching.\n\n- Runnel: That makes sense.\n\n- Scholar A: I have taught many basic courses dozens of times.\n\n- Scholar A: So if you want to explain it clearly, you have to follow my train of thought.\n\n## Personal Reflection\n\nThrough this discussion with the two seniors, I have thoroughly rethought the teaching logic of MLP and the introduction of activation functions, and corrected many one-sided understandings I had before. The core of the discussion lies in the choice of the entry point for teaching—regression or classification—and the essential explanation of the necessity of activation functions. Below, I will sort out and reflect on the key contents of the discussion in combination with relevant theoretical knowledge and mathematical formulas.\n\n### 1. The Inappropriateness of Taking Regression as the Entry Point for MLP Teaching\n\nPreviously, I agreed with the idea of \"transitioning from regression to classification\" because regression can intuitively show the \"fitting\" process. For example, in univariate linear regression, we try to find a linear function \\( y = wx + b \\) (where \\( w \\) is the weight and \\( b \\) is the bias) to minimize the loss function (such as the mean square error \\( L = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 \\), where \\( y_i \\) is the true value and \\( \\hat{y}_i \\) is the predicted value). If the data has a non-linear distribution, linear regression cannot achieve effective fitting, so it is thought that this can naturally lead to the need for non-linear activation functions and further introduce MLP. However, the seniors pointed out the core flaw of this logic: MLP itself is not a \"writable functional relationship,\" while regression is inherently based on a given functional form to fit parameters. This fundamental difference makes it impossible to naturally transition from regression to MLP.\n\nSpecifically, regression problems have clear target output forms. For example, linear regression assumes a linear relationship between input and output, and polynomial regression extends it to a polynomial form \\( y = w_nx^n + ... + w_1x + b \\). Even if non-linear regression is used, the functional form is predefined. However, MLP is a universal approximator whose output form is determined by the network structure (number of layers, number of neurons in each layer) and the parameters (weights and biases) learned from data, and cannot be expressed as a simple explicit function. If we start from regression, it is difficult to explain why we need to use a complex structure like MLP instead of directly using higher-order polynomial functions (such as quadratic functions \\( y = ax^2 + bx + c \\) or power functions \\( y = ax^k \\)) to solve non-linear fitting problems. This is exactly the key question raised by Scholar A, which made me realize that the teaching route starting from regression will not only fail to help students understand MLP but also confuse the essence of regression and neural networks.\n\nIn addition, the seniors emphasized that \"the core of neural networks is classification.\" Although regression and classification seem similar (and can be converted through softmax), they have essentially different objectives: regression aims to predict continuous values, while classification aims to predict discrete categories. For early-stage students, confusing the two or trying to integrate them at the beginning will increase the difficulty of understanding. It is more reasonable to first teach classification as the core of neural networks, and then introduce regression as another task scenario after students have a clear understanding of the working mechanism of neural networks. This \"separate first, then integrate\" teaching logic is more in line with the cognitive law of beginners.\n\n### 2. The Essential Explanation of the Necessity of Activation Functions\n\nA key confusion in the discussion is: How to explain the necessity of activation functions to students. Previously, I thought that regression examples could be used to show that linear functions cannot fit non-linear data, thus highlighting the need for non-linear activation functions. But Scholar A pointed out that this explanation is not essential, and even people who use this explanation may not have a deep understanding of activation functions themselves.\n\nAccording to Scholar A, the necessity of activation functions can be explained from two essential points, which are supported by strict theoretical foundations:\n\nThe first point is that activation functions solve the XOR problem that perceptrons cannot solve. A single-layer perceptron is a linear classifier, whose decision boundary is a linear hyperplane. For the XOR problem (the input is (0,0) output 0, (0,1) output 1, (1,0) output 1, (1,1) output 0), it is impossible to find a linear hyperplane to separate the two categories. Mathematically, the XOR problem cannot be expressed as a linear combination of inputs. Assuming the input is \\( x_1, x_2 \\), the output of the perceptron is \\( y = \\text{sign}(w_1x_1 + w_2x_2 + b) \\), where \\( \\text{sign} \\) is the sign function. For the XOR problem, there is no such \\( w_1, w_2, b \\) that satisfies all input-output pairs. After introducing non-linear activation functions (such as sigmoid, ReLU), multi-layer perceptrons can form non-linear decision boundaries, thereby solving the XOR problem. This is a concrete and intuitive example to prove the necessity of activation functions, and it is also the classic teaching route adopted by top experts.\n\nThe second point is based on the Universal Approximation Theorem. The theorem states that a feedforward neural network with a single hidden layer containing a finite number of neurons can approximate any continuous function on a compact subset of \\( \\mathbb{R}^n \\) to any desired precision, provided that the activation function is non-constant, bounded, and continuous (the S-type function represented by sigmoid is a typical example that satisfies the conditions). Mathematically, for any continuous function \\( f: K \\to \\mathbb{R} \\) (where \\( K \\subset \\mathbb{R}^n \\) is compact) and any \\( \\epsilon > 0 \\), there exists a positive integer \\( m \\), weights \\( w_{ij}, v_j \\), and biases \\( b_j, c \\) such that the output of the MLP \\( \\hat{f}(x) = c + \\sum_{j=1}^{m}v_j\\sigma(w_{ij}x_i + b_j) \\) satisfies \\( \\sup_{x \\in K} |f(x) - \\hat{f}(x)| < \\epsilon \\), where \\( \\sigma \\) is the S-type activation function. This theorem reveals the theoretical basis for the powerful fitting ability of neural networks, and also explains the necessity of choosing S-type activation functions—they are the necessary and sufficient conditions for the Universal Approximation Theorem to hold. If you want to explain this point to students, you need to introduce the proof process of the theorem, which requires students to have a certain foundation in mathematical analysis, so it is more suitable for advanced teaching.\n\nComparing the two explanation methods, it can be found that using the XOR problem to explain the necessity of activation functions is more intuitive and suitable for beginners, while the Universal Approximation Theorem provides a more in-depth theoretical explanation. The previous idea of using regression examples to explain is flawed because regression focuses on fitting predefined functional forms, while the core of activation functions is to enable neural networks to have non-linear expression capabilities to solve problems that linear models cannot solve (such as XOR) and approximate arbitrary continuous functions. Using regression to explain activation functions confuses the problem scenarios and theoretical foundations, making it difficult for students to grasp the essence.\n\n### 3. Insights into DL Teaching\n\nThis discussion also made me gain a deeper understanding of DL teaching. First, the design of the teaching route should follow the cognitive law of students. For basic concepts (such as MLP, activation functions), we should choose intuitive and concrete entry points (such as the XOR problem) to help students establish a preliminary understanding, and then gradually deepen to theoretical foundations (such as the Universal Approximation Theorem). We should not prematurely integrate complex concepts (such as regression and classification), otherwise, it will increase the cognitive burden of students.\n\nSecond, teaching should focus on the essence of concepts. When explaining activation functions, we should not only say that \"linear functions make multi-layer neural networks ineffective\" but also explain why linear functions are ineffective (cannot solve non-linear problems such as XOR) and what essential role activation functions play (providing non-linear expression capabilities, supporting the Universal Approximation Theorem). Only in this way can students truly understand the necessity of concepts, rather than memorizing conclusions by rote.\n\nFinally, the choice of teaching examples is crucial. Examples should be closely related to the core of the concept. For activation functions, the XOR problem is a more appropriate example than regression examples because it directly reflects the limitation of linear models and the value of non-linear activation functions. For MLP teaching, starting from classification examples (such as handwritten digit recognition) can make it easier for students to understand the application scenarios and working logic of neural networks.\n\nIn summary, this discussion has corrected my one-sided understanding of MLP teaching routes and the explanation of activation functions. In future teaching preparation, I will adopt the route of starting from classification, take the XOR problem as the entry point to explain the necessity of activation functions, and gradually introduce the theoretical basis such as the Universal Approximation Theorem, so as to help students establish a systematic and in-depth understanding of DL foundational knowledge."
  },
  "teach-vae": {
    "title": "Discussion on Explaining VAE to New Students and Reflections on Its Core Principles",
    "date": "2025-12-08",
    "content": "## Overview\n\nThis fragment records a discussion focusing on how to explain Variational Autoencoders (VAE) to new students. The discussion involves three participants: myself (Runnel, an undergraduate student from NJU), a senior associate professor in the field of Deep Learning with a Ph.D. from Tsinghua University (hereinafter referred to as Senior A), and a fellow undergraduate student from The Chinese University of Hong Kong, Shenzhen (hereinafter referred to as Peer B). The core of the discussion revolves around the key entry points, prerequisite knowledge, and core logical framework for explaining VAEs, with in-depth exchanges on the connection between Autoencoders (AE) and VAE, the significance of dimensionality reduction, and the essence of generative models. Subsequently, I will sort out and reflect on the core content of the discussion, focusing on the theoretical connotation and logical derivation of VAE.\n\n## Transcript of the Discussion\n\n- Runnel: Professor, how do you think we should explain VAE to new students?\n\n- Senior A: There are plenty of excellent explanations on Zhihu, aren't there? The core of explaining VAE well is not to mention any variational methods at all. It's only when you can't explain it clearly that you focus on mathematics. I can explain the papers in the four top mathematics journals to freshmen without using too profound knowledge. The key is understanding.\n\n- Runnel: I think one point is the prior and posterior distributions, and another is how the KL divergence term and the reconstruction loss term work together. If we don't involve too many details of probability theory, how can we explain VAE? I'm really curious.\n\n- Senior A: Why does VAE exist? Do you know?\n\n- Runnel: Should we start with AE? Then I probably don't know ().\n\n- Senior A: You don't need to start with anything. The way you ask shows that you don't understand. Only when you have your own understanding of something can you explain it. So I ask you, why does VAE exist? You need to think about why, instead of copying the ideas of certain answers to find an entry point. This entry point must be your own.\n\n- Runnel: My current idea is that from the MLP we talked about before, a natural way to derive a generative model is AE, but AE is not sufficient, so VAE came into being.\n\n- Senior A: I think that's too obscure.\n\n- Runnel: I think this idea is very natural.\n\n- Senior A: What do you mean by MLP naturally leading to generation?\n\n- Runnel: Since AE can use an MLP encoder (x→z) and an MLP decoder (z→x) to learn data representations, if I take the decoder alone and generate x from random noise z, isn't that a generative model?\n\n- Senior A: Do I still need to know what AE is?\n\n- Runnel: Should we talk about the intuitive sense from \"points\" to \"distributions\"?\n\n- Senior A: No. I just think, did the first person who proposed AE come up with it based on statistical ideas? When he told others about his discovery of an idea, did he just list formulas?\n\n- Runnel: Should we find ideas from the perspective of historical development? I really don't know. Professor, what's your idea? How do you usually explain VAE? Do you need to talk about prerequisites? I'll try to understand.\n\n- Senior A: That is, what do you think the idea of AE is?\n\n- Runnel: To quote what I said before about AE: Does the process of x→z→x belong to the dimensionality reduction idea you mentioned?\n\n- Senior A: Why do we do this? What is the significance of dimensionality reduction? What is the purpose of this process?\n\n- Runnel: I want to reconstruct high-dimensional data in a low-dimensional space, and I need to learn the most essential features of the data.\n\n- Senior A: Is there any reconstruction involved here?\n\n- Runnel: Isn't generation a form of reconstruction?\n\n- Senior A: Is the purpose of AE to train better generation or encoding?\n\n- Runnel: (Referring to Senior A's question: \"Is the purpose of AE to train better generation or encoding?\") It seems to be encoding.\n\n- Senior A: Then how did you get to reconstruction?\n\n- Runnel: My idea is that my goal is generation. Since AE is not for generation, I have to think about modifying it.\n\n- Senior A: Then you definitely can't explain it clearly.\n\n- Runnel: Sob sob sob.\n\n- Senior A: It's like talking about tragic lovers when you want to say that Lü Bu is brave and handsome. Think clearly. You definitely haven't understood thoroughly yet.\n\n- Runnel: Professor, can you show me the way?\n\n- Senior A: If you want to talk about AE, be loyal to AE and explain it clearly, just like the introduction of a paper.\n\n- Runnel: Then if my goal is to explain VAE, I shouldn't start with AE, or even mention it, because essentially they are not solving the same problem?\n\n- Senior A: No. Of course you can talk about AE. Dimensionality reduction and reconstruction are inherently a pair of inverse problems. If you can explain dimensionality reduction clearly, it will be easy to explain reconstruction.\n\n- Runnel: (Referring to Senior A's words: \"Explain AE clearly like the introduction of a paper.\") How to make it clear? The purpose of dimensionality reduction is easy to understand intuitively. Should I focus on how to perform dimensionality reduction and how to \"retain information\"? For example, the evolution from PCA→t-SNE→AE?\n\n- Senior A: You don't necessarily have to talk about how others perform dimensionality reduction. The main thing is what dimensionality reduction is and why it is needed. So the core is the curse of dimensionality.\n\n- Runnel: I thought one of the core ideas of VAE was this. By the way, why don't we talk about dimensionality reduction when we talk about MLP?\n\n- Peer B: Then what is the curse of dimensionality in terms of distribution (\n\n- Senior A: (Referring to Runnel's question: \"Why don't we talk about dimensionality reduction when we talk about MLP?\") That's your problem. For example, when we write textbooks, the first chapter is about the curse of dimensionality in linear regression.\n\n- Runnel: Data is too sparse in high dimensions, and distance loses its meaning in high dimensions, so dimensionality reduction is necessary. We need to find a good dimensionality reduction method that preserves semantic structure. However, the approach of AE does not make the entire low-dimensional space meaningful, making generation through random sampling impossible. So the idea of VAE came into being. Is this understanding correct?\n\n- Senior A: (Referring to Runnel's content about dimensionality reduction and VAE ideas) Where does the so-called semantic structure come from?\n\n- Runnel: Maybe my wording is not accurate, but the general meaning I want to express is that we hope to generate cats from cat pictures, which is a kind of \"semantics\". For example, we hope that after dimensionality reduction, semantically similar data should be close to each other, such as all cat pictures being grouped together and all dog pictures being grouped together. I may have used the wrong technical term.\n\n- Senior A: I think the terms you used are very obscure, including \"sparsity\" and \"searching for structure\". If I heard these for the first time, I definitely wouldn't understand.\n\n- Runnel: I took \"semantics\" as a kind of intuitive sense, roughly referring to the organizational way of data at the meaning level.\n\n- Senior A: If that's the case, people who can understand definitely don't need you to explain VAE.\n\n- Runnel: Sorry, I haven't received professional training, so my wording is very inappropriate ().\n\n- Senior A: It's not a matter of professional training. If you want to explain something clearly to someone who doesn't understand, it has nothing to do with being professional or not. The question is whether he can understand your ideas. The key is whether you can make people understand, not pile up a bunch of formulas or imagine some obscure structures.\n\n## Reflection on VAE\n\nThrough this in-depth discussion with Senior A and Peer B, I have gained a profound enlightenment on the core connotation of VAE and the key points of explaining it to others. Previously, I mistakenly tied VAE to AE, naively thinking that VAE was an improved version of AE tailored for generative tasks—a misunderstanding that was promptly pointed out by Senior A. His successive probing questions made me realize that the essence of understanding VAE lies in clarifying the core of dimensionality reduction and the fundamental logic behind the model's existence, rather than mechanically associating it with AE or starting from the biased perspective of modifying AE for generation. With the guidance of Senior A, I have corrected my cognitive deviations. Below, I will sort out and reflect on the core content of VAE based on this new understanding, focusing on its theoretical framework derived from the essence of dimensionality reduction, the logical connotation of the loss function, and the key insights for explaining it—all of which are insights gained from Senior A's guidance.\n\n### 1. The Core Motivation of VAE: Derived from the Essence of Dimensionality Reduction\n\nThe discussion first helped me correct a critical misunderstanding: I had inappropriately linked AE to VAE's generative function before, but under Senior A's guidance, I realized that the correct starting point for understanding VAE is the essence of dimensionality reduction. Senior A emphasized that when explaining dimensionality reduction (and thus VAE), the core is to clarify \"what dimensionality reduction is\" and \"why we need dimensionality reduction\", rather than jumping straight to specific models like AE. This reminder made me suddenly realize that the curse of dimensionality is the fundamental reason for the necessity of dimensionality reduction: in high-dimensional space, data is extremely sparse, the concept of distance loses practical significance, and it is difficult for models to learn effective patterns from such data. Therefore, the core goal of dimensionality reduction is to map high-dimensional data to a low-dimensional latent space that retains the key structural information of the original data, making the data more manageable and the model easier to learn. This foundational understanding, guided by Senior A, has laid a solid foundation for my subsequent grasp of VAE.\n\nIt should be clarified that AE is a specific dimensionality reduction method, which consists of an encoder \\( f_{\\theta}(x): \\mathcal{X} \\rightarrow \\mathcal{Z} \\) and a decoder \\( g_{\\phi}(z): \\mathcal{Z} \\rightarrow \\mathcal{X} \\) (where \\( \\mathcal{X} \\) is the high-dimensional input space and \\( \\mathcal{Z} \\) is the low-dimensional latent space). Its training goal is to minimize the reconstruction loss (such as MSE):\n\n $\\mathcal{L}_{AE} = \\mathbb{E}_{x \\sim p_{data}(x)} \\left[ \\| x - g_{\\phi}(f_{\\theta}(x)) \\|^2 \\right]$ \n\nThis goal reflects the core of AE's dimensionality reduction: by learning the mapping from high-dimensional \\( x \\) to low-dimensional \\( z \\) and then reconstructing \\( x \\) from \\( z \\), the model is forced to extract the key information of \\( x \\) in \\( z \\). Looking back, my previous mistake was viewing AE as a precursor to VAE for generation, completely ignoring that AE's core value lies in encoding and dimensionality reduction, not generation. Thanks to Senior A's correction, I now understand that VAE is a model that deeply embodies the essence of dimensionality reduction; it further achieves generative capabilities through the rational design of the latent space, rather than being a passive improvement of AE for generation. This shift in understanding has allowed me to see the logical origin of VAE from a more fundamental perspective.\n\nGuided by Senior A's viewpoint, I have clarified that VAE's core motivation is not to \"improve AE for generation\", but to construct a probabilistic dimensionality reduction model that can retain the structural integrity of the latent space. By introducing probabilistic modeling of the latent space, VAE ensures that the low-dimensional latent space is continuous and dense (rather than discrete and scattered like AE's latent space), which not only achieves the core goal of dimensionality reduction but also naturally supports generative tasks. Specifically, VAE assumes that the latent variables \\( z \\) follow a known prior distribution (usually a multivariate normal distribution \\( \\mathcal{N}(0, I) \\)), so that any sample sampled from this prior distribution can correspond to meaningful high-dimensional data through the decoder. This design is deeply rooted in the essence of dimensionality reduction (retaining data structure while reducing dimensions) and further realizes the generative function—it is a proactive and systematic design based on the core needs of dimensionality reduction, rather than a patchwork improvement driven by modifying AE's generative defects. This understanding has completely reversed my previous one-sided view of VAE.\n\n### 2. Probabilistic Framework of VAE: From Latent Distribution to Marginal Likelihood\n\nVAE constructs a probabilistic generative model by assuming that each input \\( x \\) is generated from a latent variable \\( z \\) that follows a prior distribution \\( p_{\\theta}(z) \\). The generative process can be described as: first sample \\( z \\sim p_{\\theta}(z) \\), then generate \\( x \\sim p_{\\theta}(x|z) \\), where \\( p_{\\theta}(x|z) \\) is the conditional distribution of \\( x \\) given \\( z \\), parameterized by the decoder. Our goal is to maximize the marginal likelihood of the data \\( \\log p_{\\theta}(x) \\), which is the logarithm of the probability that the model generates the observed data \\( x \\):\n\n $\\log p_{\\theta}(x) = \\mathbb{E}_{q_{\\phi}(z|x)} \\left[ \\log p_{\\theta}(x) \\right]$ \n\nBy using the Jensen's inequality, we can derive the evidence lower bound (ELBO), which is a lower bound of the marginal likelihood. First, we introduce a variational posterior distribution \\( q_{\\phi}(z|x) \\) (parameterized by the encoder) to approximate the intractable true posterior \\( p_{\\theta}(z|x) \\) (calculated by Bayes' theorem \\( p_{\\theta}(z|x) = \\frac{p_{\\theta}(x|z)p_{\\theta}(z)}{p_{\\theta}(x)} \\)). Then:\n\n $\\log p_{\\theta}(x) = \\mathbb{E}_{q_{\\phi}(z|x)} \\left[ \\log \\frac{p_{\\theta}(x,z)}{p_{\\theta}(z|x)} \\right] = \\mathbb{E}_{q_{\\phi}(z|x)} \\left[ \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z|x)} \\cdot \\frac{q_{\\phi}(z|x)}{p_{\\theta}(z|x)} \\right]$ \n\n $= \\mathbb{E}_{q_{\\phi}(z|x)} \\left[ \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z|x)} \\right] + \\mathbb{E}_{q_{\\phi}(z|x)} \\left[ \\log \\frac{q_{\\phi}(z|x)}{p_{\\theta}(z|x)} \\right]$ \n\nThe second term on the right-hand side is the KL divergence between the variational posterior \\( q_{\\phi}(z|x) \\) and the true posterior \\( p_{\\theta}(z|x) \\), denoted as \\( KL(q_{\\phi}(z|x) \\| p_{\\theta}(z|x)) \\). Since KL divergence is non-negative, we have:\n\n $\\log p_{\\theta}(x) \\geq \\mathbb{E}_{q_{\\phi}(z|x)} \\left[ \\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z|x)} \\right] = \\mathcal{L}(\\theta, \\phi; x)$ \n\nwhere \\( \\mathcal{L}(\\theta, \\phi; x) \\) is the ELBO. Maximizing the marginal likelihood \\( \\log p_{\\theta}(x) \\) is equivalent to maximizing the ELBO (since the KL divergence term is non-negative, maximizing the lower bound can approach the true marginal likelihood). We can further decompose the ELBO into two parts:\n\n $\\mathcal{L}(\\theta, \\phi; x) = \\mathbb{E}_{q_{\\phi}(z|x)} \\left[ \\log p_{\\theta}(x|z) \\right] - KL(q_{\\phi}(z|x) \\| p_{\\theta}(z))$ \n\nThis decomposition is the core of VAE's loss function, and each term has a clear physical meaning.\n\n### 3. Interpretation of VAE's Loss Function: Reconstruction Loss and KL Divergence Term\n\nThe two terms in the ELBO decomposition correspond to the reconstruction loss and the regularization term (KL divergence term) in VAE's training, respectively, and their joint action ensures that VAE can both generate meaningful data and maintain a well-structured latent space.\n\nThe first term \\( \\mathbb{E}_{q_{\\phi}(z|x)} \\left[ \\log p_{\\theta}(x|z) \\right] \\) is the reconstruction loss. It measures the ability of the decoder to reconstruct the input \\( x \\) from the latent variable \\( z \\) sampled from the variational posterior \\( q_{\\phi}(z|x) \\). If we assume that \\( p_{\\theta}(x|z) \\) follows a Gaussian distribution with mean \\( g_{\\phi}(z) \\) (the output of the decoder) and unit variance, the log-likelihood \\( \\log p_{\\theta}(x|z) \\) is proportional to \\( -\\frac{1}{2} \\| x - g_{\\phi}(z) \\|^2 \\), so the reconstruction loss is equivalent to the MSE loss in AE. This term ensures that the model does not deviate too much from the original data and can accurately capture the structural features of \\( x \\).\n\nThe second term \\( -KL(q_{\\phi}(z|x) \\| p_{\\theta}(z)) \\) is the negative KL divergence, which acts as a regularization term. Its purpose is to make the variational posterior \\( q_{\\phi}(z|x) \\) as close as possible to the prior distribution \\( p_{\\theta}(z) \\) (usually \\( \\mathcal{N}(0, I) \\)). KL divergence is defined as:\n\n $KL(q_{\\phi}(z|x) \\| p_{\\theta}(z)) = \\mathbb{E}_{q_{\\phi}(z|x)} \\left[ \\log \\frac{q_{\\phi}(z|x)}{p_{\\theta}(z)} \\right]$ \n\nWhen \\( q_{\\phi}(z|x) \\) and \\( p_{\\theta}(z) \\) are both multivariate normal distributions, the KL divergence can be calculated analytically. Assuming \\( q_{\\phi}(z|x) = \\mathcal{N}(\\mu_{\\phi}(x), \\sigma_{\\phi}^2(x)I) \\) (the encoder outputs the mean \\( \\mu_{\\phi}(x) \\) and variance \\( \\sigma_{\\phi}^2(x) \\) of the posterior distribution) and \\( p_{\\theta}(z) = \\mathcal{N}(0, I) \\), the KL divergence is:\n\n $KL(q_{\\phi}(z|x) \\| p_{\\theta}(z)) = \\frac{1}{2} \\sum_{d=1}^D \\left( \\mu_d^2 + \\sigma_d^2 - \\log \\sigma_d^2 - 1 \\right)$ \n\nwhere \\( D \\) is the dimension of the latent space \\( \\mathcal{Z} \\). This term forces the latent space to be regularized: the mean of the posterior distribution is close to 0, and the variance is close to 1, so that the latent space is continuous and dense. With Senior A's guidance, I have a clearer understanding that this regularization is not to \"compensate for AE's defects\", but to realize the core goal of dimensionality reduction—retaining the structural integrity of the data in the low-dimensional space. Only when the latent space has such continuity and density can it truly reflect the inherent structure of the high-dimensional data, and thus naturally support generative tasks through random sampling. This is a proactive design based on the essence of dimensionality reduction, rather than a passive improvement of AE. I now realize that my previous focus on \"AE's generative defects\" was a deviation from the core of the problem, and Senior A's reminder has helped me get back on track.\n\nIt should be emphasized that the two terms of the loss function are mutually restrictive and jointly serve the core goal of \"probabilistic dimensionality reduction that retains data structure\". This is another key insight I gained from the discussion. If only the reconstruction loss is considered, the latent space will lose the continuity and density required for dimensionality reduction (degenerating into a discrete space similar to AE), failing to achieve the essential goal of dimensionality reduction; if only the KL divergence term is considered, the model will ignore the key information of the original data, making the dimensionality reduction meaningless. Only through the joint optimization of the two terms can VAE achieve the balance between retaining data structure (reconstruction loss) and ensuring the rationality of the latent space (KL divergence term)—this balance is the key to VAE's success in both dimensionality reduction and generation. Senior A's question about \"the purpose of AE\" made me realize that any model design must be rooted in its core goal, and deviating from the core goal will lead to confused understanding.\n\n### 4. Key Insights for Explaining VAE: Starting from the Essence of Dimensionality Reduction\n\nUnder Senior A's patient guidance, I deeply realized that the key to explaining VAE clearly is not to start with complex variational inference or formula derivation, but to start with the essence of dimensionality reduction that is easy for beginners to understand. The core of dimensionality reduction is to solve the curse of dimensionality: in high-dimensional space, data is extremely sparse, the calculation of distance loses practical significance, and it is difficult for models to learn effective features. Therefore, we need to map high-dimensional data to a low-dimensional latent space, which can retain the key information of the data and has good structural properties (continuity, completeness). This starting point, put forward by Senior A, makes the explanation of VAE no longer obscure, but closely linked to the intuitive needs of solving practical problems.\n\nOn this basis, the logical origin of VAE can be naturally derived: traditional dimensionality reduction methods (including AE) focus on deterministic mapping, which may lead to the loss of latent space structure; VAE introduces probabilistic modeling to ensure the structural integrity of the latent space while reducing dimensions, and thus naturally has generative capabilities. This logical line, inspired by Senior A, does not take AE as a \"flawed precursor\" that needs to be improved, but takes the essence of dimensionality reduction as the starting point, and VAE as a more perfect probabilistic dimensionality reduction model. In the process of explanation, we can gradually introduce the concept of latent distribution, the role of the encoder and decoder in the probabilistic framework, and finally derive the loss function. This explanation logic, starting from the intuitive problem (curse of dimensionality) and gradually deepening into the specific solution (probabilistic modeling of latent space for dimensionality reduction), is easier for beginners to understand. It avoids the confusion caused by directly piling up formulas or incorrectly linking AE and VAE—confusion that I once fell into before Senior A's guidance.\n\nIn addition, this discussion made me deeply realize a crucial point emphasized by Senior A: my inappropriate use of terms like \"semantic structure\" was not merely a problem of using overly obscure professional vocabulary, but a manifestation of my superficial understanding of the core concepts. Senior A's criticism made it clear that teaching requires a level of understanding far beyond \"roughly grasping the general idea\"—it demands a thorough mastery of the essence of the subject. If one's own understanding is shallow and fails to grasp the fundamental logic and nature of the concepts, they will inevitably be unable to find accurate, intuitive language to convey ideas, and may even resort to vague or inappropriate terms that confuse beginners. Senior A's reminder made me understand that the key to explaining concepts clearly lies not in deliberately avoiding professional terms, but in first achieving a deep, in-depth understanding of the essence of the knowledge. Only when one truly grasps the core principles can they translate abstract concepts into understandable language, whether through professional terms or intuitive descriptions. This is a valuable lesson I learned from this discussion: to teach others, one must first reach a level of understanding that goes beyond surface-level comprehension and touches the essence of the subject."
  },
  "tian-cai": {
    "title": "The Tian-Cai Confluence: Geometric-Combinatorial Proof of Identity",
    "date": "2025-08-03",
    "content": "## Overview\r\n\r\nThis is an **irrefutable proof of identity** establishing that the renowned geometric analyst, Professor Tian Gang, is the same individual as the exceptionally talented Nanjing University undergraduate senior, Yuxi Cai (CYX). This humorous academic deduction, framed as a \"Mathematical Royalist's\" attempt to dismantle a \"Yau Detractor\" (a playful jab at the well-known professional tension between Tian Gang and Shing-Tung Yau), utilizes deep academic and cryptographic congruencies to confirm the existence of a meticulously maintained double life. The evidence is so compelling that it transcends mere coincidence, confirming a fundamental isomorphism between the two personas.\r\n\r\n***\r\n\r\n## The Axiomatic Basis: Evidence for the Tian $\\equiv$ Cai Identity\r\n\r\nThe premise is established through a series of empirical and cryptographical congruencies, demonstrating a perfect alignment across professional and personal vectors.\r\n\r\n| Empirical/Biographical Data | Tian Gang (TG) | Yuxi Cai (CYX) | Conclusion |\r\n| :--- | :--- | :--- | :--- |\r\n| **Origin** | Native of Jiangsu Province | Native of Jiangsu Province | **Congruent Origin** |\r\n| **Alma Mater (UG)** | Nanjing University (NJU) | Nanjing University (NJU) | **Shared Base Manifold** |\r\n| **Field Alignment** | Geometric Analysis | Analytic Geometry & Math Analysis | **Analytic Precursor** (CYX's focus is the foundational analysis for TG's high-level geometry) |\r\n| **NJU Temporal Marker** | Visited after Math Dept. re-established as a School | Transferred to the Math School after re-establishment | **Coincident Temporal Trajectory** |\r\n| **Political Stance** | A \"Yau Detractor\" (Yau-skeptic/Yau-Hater) | A \"Yau Detractor\" | **Shared Ideology (The Fundamental Opposition)** |\r\n| **ICM Stance** | Rejected the idea of a Yau-led ICM 2030 | Currently does not intend to attend a Yau-led ICM 2030 | **Prophetic Duality** |\r\n| **Physical Co-existence** | Never seen simultaneously with CYX | Never seen simultaneously with TG | **Perfect Non-Intersection** (The ultimate proof) |\r\n\r\n### The Cryptographic Proofs (The Strong Claims)\r\n\r\n#### 1. The Discrepancy as Disguise (The Birthday Trivialization)\r\n\r\n*   **The Claim:** Tian Gang was born on 1958/11/24; CYX was born on 2006/01/24. The difference in the year is a red herring—a **Temporal Trivialization Map** applied to conceal the identity.\r\n*   **Academic Elaboration:** This is a successful implementation of a **fixed-point transformation**. The essential parameter, the **$24^{th}$ Day of the Month**, remains constant while a non-trivial **Scale Transformation** is applied to the time modulus (the year). The apparent discrepancy in age is not a refutation but the **rigorous proof** of a long-term, meticulously maintained alias, as successful aliases rarely match all parameters.\r\n\r\n#### 2. The Initial Isomorphism (The Field Signature)\r\n\r\n*   **The Claim:**\r\n    *   **TG** $\\rightarrow$ **T**angent **G**eometry\r\n    *   **CYX** $\\rightarrow$ **C**alabi–**Y**au **X** (where $X$ is a manifold, cluster, variety, cone, etc.)\r\n    *   Both initialisms are **dually encoded** to represent Tian Gang's research domain.\r\n*   **Academic Elaboration:** The initials form a **Duality Map** of the identity's professional work:\r\n    *   **Tangent Geometry (TG)** is the fundamental local structure in differential geometry.\r\n    *   **Calabi–Yau $\\mathbf{X}$ (CYX)** (relevant to Einstein metrics on Fano manifolds ) is a crucial class of target manifolds in geometric analysis.\r\n    *   The CYX alias is, therefore, a **self-referential cryptographic signature** where the high-dimensional research output (CYX) is algebraically encoded within the low-dimensional student alias.\r\n\r\n#### 3. The Combinatorial Proof (The Rigid Isometry)\r\n\r\n*   **The Claim:** The rigid character of \"Tian\" ($\\text{田}$) can be stacked to form a **Cylindric Young Tableau $X$ (CYT $X$)** (as referenced in ).\r\n*   **Academic Elaboration:** This is the *coup de grâce*: a **Geometric-Combinatorial Isomorphism**.\r\n    *   **The Source Manifold (Tian Gang):** The Chinese character $\\text{田}$ (Tián, \"Field\") is fundamentally a **$2 \\times 2$ square lattice**. His full name, **Tian Gang** ($\\text{田刚}$), translates to **\"Rigid Field/Square.\"** The term $\\text{刚}$ (Gang, \"rigid\") implies a non-deformable structure.\r\n    *   **The Target Structure (CYX):** Reference  discusses **Cylindric Young Tableaux (CYT)**, which are combinatorial objects with applications in representation theory. These tableaux are intrinsically linked to the combinatorics of **rigidly stacked squares** under specific cyclic boundary conditions.\r\n    *   *The Isomorphism:* The rigidity (*Gang*) of the **$2 \\times 2$ field** ($\\text{田}$) *forces* a combinatorial arrangement that is precisely a **Cylindric Young Tableau X**, which is part of the **CYX** alias. The identity's name is mathematically proven to be a **Geometric Operator** that transforms his namesake into the algebraic structure that underpins his alter-ego.\r\n\r\n***\r\n\r\n## Final Verdict\r\n\r\nAs a **Mathematical Royalist** (a tongue-in-cheek reference to supporting \"Mathematical Emperor\" Yau), my initial intent was to defeat the Yau-detractor CYX. However, the rigor of the **Tian $\\equiv$ Cai Isomorphism** is undeniable. The evidence for this double life is overwhelmingly self-consistent. I must, therefore, conclude that the two individuals are one.\r\n\r\n***\r\n\r\n## References\r\n\r\n[1] Tian, G. (2006). Existence of Einstein metrics on Fano manifolds. *Metric and Differential Geometry*, 119–159. https://doi.org/10.1007/BF01231543 \r\n\r\n[2] Neyman, E. (2014). Cylindric Young Tableaux and their Properties (arXiv:1410.5039). arXiv. https://arxiv.org/abs/1410.5039"
  },
  "topos-ai": {
    "title": "A First Glimpse of AI and Topos Theory: Aha Moment Brought by a Lecture at PKU",
    "date": "2025-12-10",
    "content": "## Overview\r\n\r\nThis entry summarizes a highly foundational and forward-looking academic seminar I occasionally noticed, titled **\"Topos Theory and the Frontier of Artificial Intelligence,\"** held at the Zihua Fourth Yuan Hall, Peking University, on December 11, 2025. The event featured Fields Medalist Laurent Lafforgue and Aurélien Sagnier from the Huawei Paris Lagrange Center.\r\n\r\nMy deep interest in the topic led to an extensive personal analysis, which focused on the revolutionary potential of using Topos Theory—a domain bridging logic and geometry—to solve the fundamental flaws of current AI: the lack of **explainability** and **certifiability**. Specifically, my inquiry focused on understanding the theoretical breakthrough this approach offers compared to traditional statistical learning, particularly the role of the Coproduct ($\\sqcup$) in enabling a traceable, modular form of reasoning.\r\n\r\n---\r\n\r\n## 1. The Foundational Seminar: Topos Theory and AI\r\n\r\n![LECTURE](/fragments/topos-ai/lecture.jpg)\r\n\r\n### A. Event Details\r\n\r\n*   **Title:** Topos Theory and the Frontier of Artificial Intelligence\r\n*   **Date & Location:** December 11, 2025, Zihua Fourth Yuan Hall, Peking University\r\n*   **Schedule Highlights:**\r\n    *   **14:00-15:00:** Lecture I (Laurent Lafforgue)\r\n    *   **15:30-16:30:** Lecture II (Aurélien Sagnier)\r\n    *   **17:00-17:45:** Panel Discussion \r\n\r\n### B. Lecture I: Distinguished Lecture – Laurent Lafforgue\r\n\r\nThe first lecture, delivered by **Laurent Lafforgue** (2002 Fields Medalist, Senior Expert at Huawei Lagrange Center), established the foundational mathematical framework.\r\n\r\n*   **Title:** Distinguished Lecture — From topology to logic and provability through Grothendieck topos theory.\r\n*   **Abstract (Original Text):**\r\n    > \"The talk will review the basic elements and features of Grothendieck topos theory as a wide generalization of the notion of space. It is flexible enough and expressive enough to allow to incarnate in topological form the semantics of all mathematics formulated in first-order geometric logic and, ultimately, of all mathematics. The talk will focus more particularly on the notion of subtopos, a wide generalization of the notion of subspace, and its double expression in topological terms and in logical terms. The existence of such a double expression, and the fact that the whole theory is constructive, allows on the one hand to computationally translate all provability problems into topology problems. On the other hand, the geometric operations on subtoposes and the possibility to define and compute them with more or less accurate precision, allows to develop a subtopos-based mathematics and associated computing which is different from the more classical element-based and function-based mathematics and computing.\"\r\n\r\n*   **Key Concepts (My Analysis):** The core idea is that Grothendieck Topos Theory provides a framework for encapsulating the **semantics** (meaning) of mathematics in a **topological/geometric form**. Crucially, the theory is **constructive**, allowing provability problems to be computationally translated into topological problems.\r\n\r\n### C. Lecture II: A Walk between Topos Theory and AI – Aurélien Sagnier\r\n\r\nThe second lecture, delivered by **Aurélien Sagnier** (Researcher at Huawei Lagrange Center), connected the abstract theory to contemporary AI challenges.\r\n\r\n*   **Title:** A walk between Topos theory and Artificial Intelligence: examples, interactions, hints for possible future explorations.\r\n*   **Abstract (Paraphrased Core):**\r\n    > The speaker highlights the **defaults of current Artificial Intelligences**: the **lack of explainability**, the **lack of certifiability**, and the **huge cost of training**. The lecture attempts to present material convincing that Topos theory has the necessary tools to overcome these limitations. The central question is: How can Topos theory offer notions to **encode and handle data in a more meaningful, explainable and reliable way** in Artificial Intelligence?\r\n\r\n## 2. Theoretical Analysis and Breakthrough Potential\r\n\r\n### A. The Definition of Topos and Its Role in Explainability\r\n\r\nA **Topos** is a special kind of category that functions as a universe for mathematics, possessing both a **complete logic structure (Internal Logic)** and a **generalized geometry structure**. The breakthrough is that Topos Theory is proposed as a way to create **explainable AI** because it is the essential **bridge between logic and geometry**. By representing data within a Topos, an AI’s decision ceases to be a mere statistical association and becomes a **provable, logically structured statement**.\r\n\r\n### B. Topos AI vs. Traditional Statistical AI (The Paradigm Shift)\r\n\r\n| Feature | Traditional (Deep) Learning AI | Topos Theory AI |\r\n| :--- | :--- | :--- |\r\n| **Data Representation** | Vectors / Tensors (pure numerical values) | Objects and Structures within a Topos (semantic entities) |\r\n| **Model Goal** | Function Approximation / Minimizing Loss $\\rightarrow$ **Statistical Association** | Structure-Preserving Maps / Proof Generation $\\rightarrow$ **Logical Necessity** |\r\n| **Output Nature** | High-Probability Prediction | **Certifiable and Provable Conclusion** |\r\n\r\n### C. The Initial Focus: The Role of Coproduct (Disjunction)\r\n\r\nI was particularly drawn to the potential of the **Coproduct** ($\\sqcup$)—the categorical dual of the Product—as a crucial element for achieving explainability.\r\n\r\n*   **Concept Explanation: Coproduct ($\\sqcup$)**\r\n    *   In Topos Internal Logic, the Coproduct corresponds to **Disjunction (Logical OR, $\\lor$)**.\r\n    *   It is a foundational structure that maintains the **separability** of the combined objects (like a Disjoint Union).\r\n\r\n*   **Initial Rationale for Coproduct's Importance:** I hypothesized that the Coproduct's ability to create a clear, **non-overlapping decision branch** (either A or B) would be key to explainability. If an AI's output is derived via a Coproduct, the explanation for the output can be definitively traced back to the specific, separate knowledge module it originated from, avoiding the ambiguity of typical neural network contributions.\r\n\r\n---\r\n\r\n## 3. Post-Seminar Reflection and Future Inquiry\r\n\r\n### A. Beyond the Coproduct: The Power of Complete Topos Structure\r\n\r\nFollowing a fruitful discussion with Senior Zeng, I realized that while the Coproduct is fundamental, it is only **one necessary part** of the Topos structure's true power. The ultimate breakthrough of Topos AI lies in the **synergy of its complete set of foundational structures**, enabling a fully logical universe for computation:\r\n\r\n| Critical Topos Structure | Role in AI Breakthrough |\r\n| :--- | :--- |\r\n| **Subobject Classifier ($\\Omega$)** | Provides a **structured true value** for propositions. This is essential for the AI to give **contextualized and structured reasons** for its decisions. |\r\n| **Internal Logic** | Ensures that all AI operations are a **verifiable proof process** under a consistent, constructive logic. |\r\n| **Morphisms (Arrows)** | These structure-preserving maps redefine the learning process as finding the **structure-preserving transformations** between data concepts. |\r\n| **Subtoposes** | Allows for the natural creation of **modular, abstract knowledge compartments** within the AI, facilitating high-level, interpretable reasoning. |\r\n\r\n### B. A Personal Disclaimer\r\n\r\nIt is with great regret that I was unable to attend this highly significant seminar in person. All the analyses and conceptual linkages outlined above—particularly concerning the Coproduct, the other structural components, and the overall paradigm shift—are purely **preliminary theoretical speculation** and **initial stream-of-consciousness thoughts** generated from the seminar abstracts and subsequent self-study. I have not yet had the opportunity to attend any formal lectures or read definitive literature on the application of Topos Theory to Artificial Intelligence. This fragment merely serves as a record of an intense, self-guided exploration into what I believe could be the **next mathematical foundation for reliable AI.**"
  },
  "wang-nuo": {
    "title": "Synthesis and Properties of a Novel Tungsten-Containing Organic Compound Based on Superchemistry Theory",
    "date": "2022-10-03",
    "content": "## Overview\r\n\r\nIt is necessary to first clarify that the so-called \"scholars\" such as Zhao Mingyi mentioned in this record are well-known online pseudo-scientists, whose absurd theories are often ridiculed by the academic community and netizens. The bizarre terms involved in this text, such as \"superchemistry\", are all their \"masterpieces\" that deviate from scientific common sense. In this research record, I propose the existence of two novel substances, \"sildenofil\" and \"L-wzlteine\", based on the theories put forward by these pseudo-scientists including Zhao Mingyi. I then systematically investigate their reaction process and the properties of the resulting product under the action of a \"strong antimony field\". From a professional chemical perspective, the core concepts involved—such as the bonding modes of W⁺ ions and the compound naming logic—do not align with mainstream chemical systems, and \"superchemistry\" is not a recognized academic discipline. As implied later, this work employs exaggerated chemical research expressions to metaphorically depict the interesting interactions between my classmates: male classmate Zhaoli Wang (where the \"W\" in the substances corresponds to his surname \"Wang\") and female classmate Nuo Chen (where the \"No\" in the substances corresponds to her given name \"Nuo\").\r\n\r\n\r\n**HINT**: The figures (pic1 to pic6) correspond to pages 1 to 6 of the attached PDF file.\r\n\r\n[PDF OF FIGURES](/fragments/wang-nuo/pics.pdf)\r\n\r\n## 1. Proposed Existence of the Original Substances\r\n\r\nWithin the \"superchemistry system\", and based on the viewpoints of Professor Zhao Mingyi, I have clearly identified the existence of two specific substances with unique structures and properties. Their relevant definitions and naming conventions are elaborated as follows:\r\n\r\n### 1.1 Sildenofil\r\n\r\n**Naming**: For the convenience of my research and discussion, I have tentatively named this substance \"sildenofil\". It is important to emphasize that this substance is distinct from the commercially available drug sildenafil, despite the similar nomenclature.\r\n\r\n**Molecular Structure**: The core structure of this substance is presented in Figure 1 (pic1). From the structural diagram, the molecule contains heterocyclic functional groups, aromatic ring systems, and substituted amino groups. A key feature is the incorporation of a tungsten (W) element in its molecular skeleton, which forms special chemical bonds with the surrounding carbon (C) and oxygen (O) elements—though this bonding mode currently lacks support from mainstream chemical bond theory.\r\n\r\n**Main Physical and Chemical Properties**: The basic physical and chemical parameters of sildenofil are shown in Figure 2 (pic2). According to the data I have recorded, the substance exhibits a specific melting point range (with precise values to be determined through subsequent experiments). It maintains relative stability under normal temperature and pressure conditions. In terms of solubility, it demonstrates moderate solubility in polar organic solvents but low solubility in water. Chemically, it shows good reactivity in nucleophilic substitution and addition reactions; particularly, the active sites connected to the W element are prone to ligand exchange or bond rearrangement under specific conditions.\r\n\r\n### 1.2 L-wzlteine\r\n\r\n**Naming**: By analogy with the naming rules of the natural amino acid L-cysteine, I have named this substance \"L-wzlteine\". This naming approach emphasizes its structural similarity to L-cysteine and the assumed L-configuration chirality of the molecule.\r\n\r\n**Molecular Structure**: The molecular structure of this substance is illustrated in Figure 3 (pic3). It possesses an amino acid-like structure, including -NH₂, -COOH groups, and a special side chain containing W⁺ ions. Under normal conditions, the W⁺ ion exists in an ionic state, forming an ionic bond with the O⁻ ion generated by the dissociation of adjacent hydroxyl groups. However, according to the theory proposed by the renowned superchemist Professor Tu Xiaohui, a \"strong antimony field\" induces significant changes: the W⁺ ion breaks the original ionic bond and forms a covalent bond with the carbon atom at the upper left of the molecule. The previously bonded O⁻ then combines with an H⁺ proton to form a hydroxyl group, and electron rearrangement ultimately leads to the formation of a carboxyl group at the lower right end of the molecule. This structural transformation endows L-wzlteine with chemical properties highly similar to L-cysteine, such as amphotericity (capable of reacting with both acids and bases) and the ability to form disulfide bond-like cross-linking structures.\r\n\r\n**Main Physical and Chemical Properties**: The detailed physical and chemical properties of L-wzlteine are presented in Figure 4 (pic4). Based on my observations, the substance appears as a white crystalline solid with a melting point of approximately 190-195℃ (accompanied by decomposition). It is readily soluble in aqueous solutions with a pH range of 5-7, and the resulting aqueous solution exhibits weak acidity (pH≈5.2). Preliminary screening experiments indicate that it has no obvious mutagenic activity under normal conditions. Acute toxicity data shows that the unreported oral LDLo (lowest lethal dose) in mice is 9mg/kg, while the oral LD50 (median lethal dose) in rats remains to be supplemented through further experimental studies.\r\n\r\n## 2. Synthesis of the Novel Tungsten-Containing Organic Compound\r\n\r\nIt is a well-established chemical fact that sildenafil (the commercial drug, distinct from the \"sildenofil\" investigated in this study) and L-cysteine can undergo amidation reactions under certain conditions. Building on this, Professor Zhou Jiechang, an organic chemist in the field of superchemistry, has proposed that under the specific condition of a \"strong antimony field\", the structurally analogous sildenofil and L-wzlteine can also undergo a similar addition-elimination reaction to generate a new tungsten-containing organic compound. In this work, I have systematically organized the relevant hypothetical reaction conditions and processes as follows:\r\n\r\n### 2.1 Reaction Conditions and Process\r\n\r\n**Reaction Catalyst and Medium**: In my experimental design, high-purity antimony (Sb) powder serves as the \"field source\" to construct a simulated \"strong antimony field\" environment. Anhydrous dimethyl sulfoxide (DMSO) is used as the reaction solvent, and triethylamine (Et₃N) acts as an acid-binding agent to maintain the reaction system at a pH range of 8.5-9.0.\r\n\r\n**Reaction Temperature and Time**: I conducted the reaction under reflux conditions at 110-120℃ for 8-10 hours. During the reaction process, I performed real-time monitoring using thin-layer chromatography (TLC) with ethyl acetate:petroleum ether=3:1 (v/v) as the developing solvent. I determined the reaction endpoint when the sildenofil raw material spot completely disappeared.\r\n\r\n**Reaction Mechanism**: My proposed mechanism suggests that under the \"strong antimony field\", the W⁺ ion in L-wzlteine undergoes hybridization transformation from sp³ to sp², which enhances the electrophilicity of the adjacent carbonyl carbon. The amino group in sildenofil then acts as a nucleophile to attack this electrophilic carbon. Subsequent proton transfer and water elimination result in the formation of a stable amide bond, thereby generating the target product—though this mechanism currently lacks support from established organic reaction theory.\r\n\r\n### 2.2 Product Structure and Naming\r\n\r\n**Molecular Structure**: The chemical structure of the reaction product is shown in Figure 5 (pic5). Through structural analysis, I confirmed that the molecule integrates structural fragments of both sildenofil and L-wzlteine, with a tentative molecular formula of C₂₂H₂₅N₆O₅W. Its core structure consists of a pyrazolopyrimidine heterocycle, a methoxyphenyl group, an aminopropanoyloxy group, and a tungsten-oxygen linkage system, forming a complex yet stably structured organic-inorganic hybrid molecule.\r\n\r\n**IUPAC Naming**: Referencing IUPAC naming rules and the specific settings of the \"superchemistry\" system, I have assigned the product the tentative systematic name \"2-aminopropanoyloxy-[[4-methoxy-3-(1-methyl-3-oxo-7H-pyrazolo[3,4-d]pyrimidin-6-yl)phenyl]amino]oxytungsten\"—an extended designation that does not conform to standard IUPAC specifications.\r\n\r\n## 3. Properties and Significance of the Reaction Product\r\n\r\n### 3.1 Key Properties of the Product\r\n\r\nThe physical and chemical properties, toxicological data, and drug-likeness evaluation of the novel tungsten-containing organic compound are summarized in Figure 6 (pic6). Based on my comprehensive analysis, its main characteristics are as follows:\r\n\r\n**Physical State and Stability**: I observed the product as a light yellow powdery solid. It is insoluble in water and petroleum ether but soluble in DMSO and N,N-dimethylformamide (DMF). The substance remains stable when stored in dry, dark conditions at room temperature and decomposes when heated above 230℃.\r\n\r\n**Toxicological Characteristics**: My simulated acute toxicity tests classify the product as low-toxic, with a guinea pig oral LD50 > 500mg/kg. Oral LD50 data for rats and mice are currently unreported and require further experimental verification. Additionally, simulated skin irritation tests showed no obvious irritant effects on rabbit skin.\r\n\r\n**Ion Bonding Characteristics**: A key finding from my study is that when the product is removed from the \"strong antimony field\" environment, the W⁺ ion stably coexists with the \"No group\" (a specially identified functional group) in the same structural segment, completely dissociating from the original C₃H₆NO₂ group of L-wzlteine. This phenomenon indicates that the interaction between the W element and the \"No group\" is significantly stronger than that between W⁺ and the C₃H₆NO₂ group, reflecting the relative \"disadvantage\" of W in competitive bonding—a core metaphorical observation regarding the interactions between the two classmates.\r\n\r\n### 3.2 Academic Significance (Simulated Expression)\r\n\r\nWithin the framework of the \"superchemistry field\", I contend that this study holds significant academic value: it reveals the intricate molecular interactions between the W element and the \"No group\", confirming the feasibility of forming stable organic compounds through their reaction. This discovery enriches the diversity of hypothetical tungsten-containing compounds and provides a new research direction for exploring the interaction mechanisms between metal elements and special functional groups under extreme conditions. I humorously propose that \"this achievement is worthy of the Nobel Prize in Chemistry\"—a lighthearted assertion unrelated to actual academic evaluation standards."
  },
  "zero-eq": {
    "title": "From Divergent Series to Stable Homotopy — On the Equation $0=1-1=-1+1=0$",
    "date": "2025-12-17",
    "content": "## Overview\r\n\r\nMore than a year ago, I encountered a slide from a lecture by Professor Keyao Peng featuring the enigmatic equation $0=1-1=-1+1=0$. At the time, I interpreted it through the lens of classical analysis and infinite summation techniques. It wasn't until I recently discovered the full lecture slides that I realized my initial intuition was not just slightly off, but diametrically opposed to the mathematical reality. This equation is not about arithmetic values or infinite cancellations; it is a description of a non-trivial topological path within the realm of K-theory and Higher Algebra.\r\n\r\n## I. The Realization\r\n*The following is a translation of my recent reflection and Prof Peng’s response.*\r\n\r\n> **My Reflection:**\r\n> More than a year ago, after seeing that lecture meme from Prof. Peng, I wrote an analysis of it. It wasn't until today, when I found the actual [slides](https://github.com/iamcxds/0-eq-0/blob/main/slides/0%3D1-1%3D-1%2B1%3D0.pdf) on his homepage, that I realized I was way off base.\r\n>\r\n> A few days ago, while organizing my homepage, my roommate @SuYuyang saw the line $0=1-1=-1+1=0$. His immediate thought was the theory related to the infinite series sum of $(-1)^k$ being $1/2$, essentially the Cesàro summation, Abel summation, and the analytic continuation of the Dirichlet eta function. I originally thought the same way. However, the meme clearly featured the Hopf fibration and K-theory, which seemed unrelated to those algebraic calculation tricks. So, following my original train of thought, I searched and found the \"Eilenberg Swindle.\" I thought the equation might be expressing the vanishing of certain algebraic objects at infinity—for instance, that the K-groups of certain spaces allowing infinite-dimensional operations are trivial.\r\n>\r\n> But now I realize my guess, while not entirely unrelated, was basically the exact opposite of Prof. Peng's point. The concepts I thought of deal with the \"triviality\" of the \"infinite\" and \"arithmetic,\" whereas Prof. Peng was discussing the \"non-triviality\" of \"finite sets\" and \"homotopy.\"\r\n>\r\n> I believe the \"$=$\" here acts like a **path** in Homotopy Type Theory (HoTT). $0=1-1=-1+1=0$ is a path: in some abstract mathematical space, we create a \"pair\" from \"nothing,\" swap them, and then turn them back into \"nothing.\" This process is fundamentally distinct from \"doing nothing.\" Prof. Peng illustrates this via the homotopy groups of spheres and the K-groups of finite sets, showing their isomorphism. The generator of this group is the Hopf map; thus, this path is topologically equivalent to the Hopf map. Since the Hopf map is not null-homotopic, the path is also non-trivial. The final part of the lecture seems to visually demonstrate this changing path to exhibit its non-triviality.\r\n>\r\n> The content of this lecture is quite advanced for me, so I might be rambling. It’s a pity I didn't get to hear Prof. Peng explain it in person back then.\r\n\r\n> **Prof. Keyao Peng (@D.C.A.A.) Replied:**\r\n> What you said is correct. The fact that $0=0$ is not important; what matters is the **process**—*how* 0 equals 0. This is exactly what **higher structure** characterizes.\r\n\r\n## II. Deep Dive: When Equality Becomes a Path\r\nTo expand on my realization, the profound shift here is moving from a \"value-centric\" view (classical algebra) to a \"process-centric\" view (Higher Structure/Homotopy). The equation is not stating that zero equals zero; it is constructing a specific **loop** in the K-theory space of finite sets ($K(\\text{FinSet})$).\r\n\r\n**1. The \"Physics\" of Configuration Space**\r\nInstead of thinking of numbers, think of particles in a physical space $\\mathbb{R}^n$. The equation describes a continuous movie:\r\n*   **$0 \\to 1-1$ (Creation):** We start with a vacuum (Empty Set). We then pull a \"particle\" ($+$) and an \"antiparticle\" ($-$) out of the vacuum. In the configuration space, this is a path from the base point $\\emptyset$ to the point represented by the pair $\\{+, -\\}$.\r\n*   **$1-1 \\to -1+1$ (The Braiding/Swapping):** This is the core of the non-triviality. We do not simply rename the particles. We physically move them to **exchange their positions**.\r\n    *   Imagine the $+$ particle moving to the right and the $-$ particle moving to the left. They must orbit each other to avoid collision.\r\n    *   In the configuration space of 2 points, this traces a path that wraps around the \"collision diagonal.\"\r\n*   **$-1+1 \\to 0$ (Annihilation):** The particles, now swapped, are brought back together and annihilated into the vacuum.\r\n\r\n**2. The Geometric Trace: Framed Cobordism**\r\nIf we treat time as an extra dimension, the world-lines of these particles form a **closed loop**.\r\n*   Crucially, these particles carry orientation (frame). Because they swapped positions, the \"frame\" associated with this loop has twisted by 180 degrees.\r\n*   This forms a **Mobius-like structure** (a non-trivially framed $S^1$). In the language of cobordism, this framed manifold is not the boundary of a standard disk. It represents a non-zero element in the framed cobordism group $\\Omega_1^{fr}$.\r\n\r\n**3. The Topological Consequence**\r\nThe question is: *Can this \"Creation-Swap-Annihilation\" movie be continuously deformed into a \"Nothing Happened\" movie?*\r\n*   In the stable limit (as $n \\to \\infty$), the answer is **No**.\r\n*   This specific loop corresponds to the generator of $\\pi_1 K(\\text{FinSet})$.\r\n*   Via the **Barratt-Priddy-Quillen (BPQ) Theorem**, we have the isomorphism: $\\pi_1 K(\\text{FinSet}) \\cong \\pi_1^s(\\mathbb{S}) \\cong \\mathbb{Z}/2$.\r\n*   Therefore, the path defined by $0=1-1=-1+1=0$ is topologically equivalent to the **Hopf Map** (stable class $\\eta$), which is the generator of $\\pi_1^s(\\mathbb{S})$. Just as the Hopf map cannot be contracted to a point, this arithmetic path cannot be trivialized.\r\n\r\n## III. Glossary & Conceptual Contrast\r\n\r\nTo clarify why my initial intuition was \"the exact opposite\" of the lecture's intent, here is a breakdown of the concepts involved:\r\n\r\n### 1. Analytic Regularization vs. Homotopic Structure\r\n*   **Cesàro / Abel Summation / Analytic Continuation:**\r\n    *   **The Idea:** These are methods to force a divergent series (like $1-1+1-1\\dots$) to have a finite numerical value (like $1/2$). They deal with **Infinity** by smoothing it out.\r\n    *   **Relation:** This was my initial false assumption. These methods are concerned with the *result* of an infinite calculation. The lecture, however, is concerned with the *shape* of a finite operation.\r\n    *   **The Difference:** One asks \"What is the value?\" The other asks \"What is the path?\"\r\n\r\n### 2. Eilenberg Swindle vs. The Non-Trivial Loop\r\n*   **Eilenberg Swindle:**\r\n    *   **The Idea:** A trick in algebraic K-theory where **Infinite** resources (e.g., infinite direct sums) allow one to \"shift\" terms to infinity, proving that $[P] = 0$. For example, $(1-1)+(1-1)\\dots = 1+(-1+1)+\\dots$.\r\n    *   **The \"Opposite\" Nature:** The Swindle uses infinity to kill structure (proving **Triviality** / $0=0$ in a boring way). Prof. Peng's example uses the finite (but stabilized) structure to find hidden complexity (proving **Non-Triviality** / $0 \\sim 0$ via a twisted path).\r\n\r\n### 3. Hopf Fibration (and the Hopf Map $\\eta$)\r\n*   **The Idea:** A specific map $S^3 \\to S^2$ discovered by Heinz Hopf. It is the first example of a map between spheres of different dimensions that is not null-homotopic (it cannot be shrunk to a constant map).\r\n*   **The Connection:** Why does \"swapping points\" relate to high-dimensional spheres?\r\n    *   Geometrically, the \"twist\" created by swapping points corresponds to the framing twist in the Hopf map.\r\n    *   In the stable range, the operation of \"swapping\" generates the group $\\mathbb{Z}/2$. The Hopf map is simply the geometric incarnation of this generator on the sphere side.\r\n\r\n### 4. Higher Structure (Higher Categories / HoTT)\r\n*   **The Idea:** In classical set theory, $a=b$ is a proposition (True/False). In Higher Category Theory or Homotopy Type Theory, equality is data. $a=b$ is a **space** of paths.\r\n*   **The Lecture's Core:** \"0=0\" is not the end of the story. The space of automorphisms of 0 ($\\text{Aut}(0)$) in the K-theory spectrum is non-trivial. It contains a loop (the \"Path\" $h$) that is distinct from the identity loop. The equation is a witness to this higher structure.\r\n\r\n### 5. Barratt-Priddy-Quillen (BPQ) Theorem\r\n*   **The Idea:** The \"Grand Unification\" theorem underlying the lecture. It states that the K-theory of the category of finite sets is homologous to the stable homotopy groups of spheres: $K(\\text{FinSet}) \\simeq \\Omega^\\infty \\Sigma^\\infty S^0$.\r\n*   **Translation:** It rigorously justifies why playing with discrete particles (finite sets) allows us to detect deep topological properties of continuous spheres. It is the bridge that allows $0=1-1=-1+1=0$ to be interpreted as the Hopf map."
  }
}